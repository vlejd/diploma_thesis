{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import logging\n",
    "import json\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import linear_model\n",
    "import scipy.sparse as sps\n",
    "from sklearn.model_selection import KFold\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "import nltk\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from nltk.corpus import stopwords\n",
    "import gc\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = \"data/train.csv\"\n",
    "data = pd.read_csv(fname, header=0)\n",
    "head = data.head().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:100000\n",
      "INFO:root:200000\n",
      "INFO:root:300000\n",
      "INFO:root:400000\n",
      "INFO:root:500000\n",
      "INFO:root:600000\n",
      "INFO:root:700000\n",
      "INFO:root:800000\n"
     ]
    }
   ],
   "source": [
    "data.question1 = data.question1.apply(normalize)\n",
    "data.question2 = data.question2.apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_pickle(\"cdata/train_cleaned.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"cdata/train_cleaned.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemed_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "progress = 0\n",
    "def stem_list(x):\n",
    "    global progress\n",
    "    progress+=1\n",
    "    if not progress%100000:\n",
    "        print (progress)\n",
    "    return list(map(stemer.stem, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "120000\n",
      "140000\n",
      "160000\n",
      "180000\n",
      "200000\n",
      "220000\n",
      "240000\n",
      "260000\n",
      "280000\n",
      "300000\n",
      "320000\n",
      "340000\n",
      "360000\n",
      "380000\n",
      "400000\n",
      "420000\n",
      "440000\n",
      "460000\n",
      "480000\n",
      "500000\n",
      "520000\n",
      "540000\n",
      "560000\n",
      "580000\n",
      "600000\n",
      "620000\n",
      "640000\n",
      "660000\n",
      "680000\n",
      "700000\n",
      "720000\n",
      "740000\n",
      "760000\n",
      "780000\n",
      "800000\n"
     ]
    }
   ],
   "source": [
    "stemed_data.question1 = stemed_data.question1.apply(stem_list)\n",
    "stemed_data.question2 = stemed_data.question2.apply(stem_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemed_data.to_pickle(\"cdata/train_cleaned_stemed.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"cdata/train_cleaned.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "def kill_stop(x):\n",
    "    return [y for y in x if y not in stop]\n",
    "\n",
    "nostop_data = data\n",
    "nostop_data.question1 = nostop_data.question1.apply(kill_stop)\n",
    "nostop_data.question2 = nostop_data.question2.apply(kill_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_pickle(\"cdata/train_cleaned_stemed_nostop.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"cdata/train_cleaned_stemed_nostop.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[step, step, guide, invest, share, market, india]</td>\n",
       "      <td>[step, step, guide, invest, share, market]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[story, kohinoor, (, koh, noor, ), diamond]</td>\n",
       "      <td>[would, happen, indian, government, stole, koh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>[increase, speed, internet, connection, using,...</td>\n",
       "      <td>[internet, speed, increased, hacking, dns]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>[mentally, lonely, solve]</td>\n",
       "      <td>[find, remainder, [, math, ], 23, ^, {, quoted...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>[one, dissolve, water, quickly, sugar, salt, m...</td>\n",
       "      <td>[fish, would, survive, salt, water]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  [step, step, guide, invest, share, market, india]   \n",
       "1   1     3     4        [story, kohinoor, (, koh, noor, ), diamond]   \n",
       "2   2     5     6  [increase, speed, internet, connection, using,...   \n",
       "3   3     7     8                          [mentally, lonely, solve]   \n",
       "4   4     9    10  [one, dissolve, water, quickly, sugar, salt, m...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0         [step, step, guide, invest, share, market]             0  \n",
       "1  [would, happen, indian, government, stole, koh...             0  \n",
       "2         [internet, speed, increased, hacking, dns]             0  \n",
       "3  [find, remainder, [, math, ], 23, ^, {, quoted...             0  \n",
       "4                [fish, would, survive, salt, water]             0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = data.is_duplicate.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO:gensim.corpora.dictionary:adding document #10000 to Dictionary(11626 unique tokens: ['msm8916', 'army', 'analogue', 'drugs', 'voltmeter']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #20000 to Dictionary(16700 unique tokens: ['msm8916', 'accomplished', 'army', 'waters', 'analogue']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #30000 to Dictionary(20468 unique tokens: ['msm8916', 'accomplished', 'army', 'waters', 'analogue']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #40000 to Dictionary(23509 unique tokens: ['msm8916', '999', 'clindamycin', '2400kms', 'truckers']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #50000 to Dictionary(26383 unique tokens: ['msm8916', '999', 'timesheets', 'clindamycin', '2400kms']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #60000 to Dictionary(28779 unique tokens: ['msm8916', '999', 'timesheets', 'clindamycin', '2400kms']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #70000 to Dictionary(30935 unique tokens: ['msm8916', '999', 'timesheets', 'clindamycin', '2400kms']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #80000 to Dictionary(32802 unique tokens: ['msm8916', '999', 'timesheets', 'clindamycin', '2400kms']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #90000 to Dictionary(34604 unique tokens: ['msm8916', '999', 'timesheets', 'clindamycin', '2400kms']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #100000 to Dictionary(36344 unique tokens: ['msm8916', '999', 'timesheets', 'clindamycin', '2400kms']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #110000 to Dictionary(37945 unique tokens: ['msm8916', '999', 'timesheets', 'clindamycin', '2400kms']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #120000 to Dictionary(39464 unique tokens: ['msm8916', 'nbh', '999', 'timesheets', 'clindamycin']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #130000 to Dictionary(40954 unique tokens: ['msm8916', 'nbh', '999', 'timesheets', 'clindamycin']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #140000 to Dictionary(42330 unique tokens: ['msm8916', 'nbh', '999', 'timesheets', 'clindamycin']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #150000 to Dictionary(43717 unique tokens: ['msm8916', '2400kms', 'magzin', 'alsatian', 'purge']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #160000 to Dictionary(45043 unique tokens: ['msm8916', '2400kms', 'magzin', 'alsatian', 'purge']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #170000 to Dictionary(46300 unique tokens: ['msm8916', '2400kms', 'magzin', 'alsatian', 'purge']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #180000 to Dictionary(47554 unique tokens: ['msm8916', 'antifreeze', '2400kms', 'magzin', 'alsatian']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #190000 to Dictionary(48711 unique tokens: ['msm8916', 'antifreeze', '2400kms', 'magzin', 'alsatian']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #200000 to Dictionary(49874 unique tokens: ['msm8916', 'antifreeze', 'muscletech', '2400kms', 'magzin']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #210000 to Dictionary(50969 unique tokens: ['msm8916', 'antifreeze', 'muscletech', '2400kms', 'magzin']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #220000 to Dictionary(52009 unique tokens: ['msm8916', 'antifreeze', 'muscletech', '2400kms', 'magzin']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #230000 to Dictionary(53073 unique tokens: ['msm8916', 'antifreeze', 'muscletech', '2400kms', 'magzin']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #240000 to Dictionary(54071 unique tokens: ['msm8916', 'antifreeze', 'muscletech', '2400kms', 'magzin']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #250000 to Dictionary(55053 unique tokens: ['msm8916', 'antifreeze', 'muscletech', '2400kms', 'magzin']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #260000 to Dictionary(56070 unique tokens: ['msm8916', 'antifreeze', 'muscletech', '2400kms', 'magzin']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #270000 to Dictionary(57010 unique tokens: ['msm8916', 'antifreeze', 'muscletech', '2400kms', 'magzin']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #280000 to Dictionary(57919 unique tokens: ['msm8916', 'antifreeze', 'muscletech', '2400kms', 'magzin']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #290000 to Dictionary(58827 unique tokens: ['msm8916', 'antifreeze', 'muscletech', '2400kms', 'magzin']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #300000 to Dictionary(59725 unique tokens: ['msm8916', 'antifreeze', 'muscletech', '2400kms', 'magzin']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #310000 to Dictionary(60604 unique tokens: ['msm8916', 'antifreeze', 'muscletech', '2400kms', 'magzin']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #320000 to Dictionary(61463 unique tokens: ['msm8916', 'antifreeze', 'muscletech', '2400kms', 'magzin']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #330000 to Dictionary(62337 unique tokens: ['msm8916', 'antifreeze', 'muscletech', 'suis', '2400kms']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #340000 to Dictionary(63123 unique tokens: ['msm8916', 'antifreeze', 'muscletech', 'suis', '2400kms']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #350000 to Dictionary(63867 unique tokens: ['msm8916', 'antifreeze', 'muscletech', 'suis', '2400kms']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #360000 to Dictionary(64609 unique tokens: ['msm8916', 'antifreeze', 'muscletech', 'suis', '2400kms']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #370000 to Dictionary(65379 unique tokens: ['msm8916', 'antifreeze', 'muscletech', 'suis', '2400kms']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #380000 to Dictionary(66147 unique tokens: ['msm8916', 'antifreeze', 'muscletech', 'suis', '2400kms']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #390000 to Dictionary(66926 unique tokens: ['msm8916', 'antifreeze', 'muscletech', 'suis', '2400kms']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #400000 to Dictionary(67638 unique tokens: ['msm8916', 'msil', 'antifreeze', 'muscletech', 'suis']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #410000 to Dictionary(68294 unique tokens: ['msm8916', 'msil', 'antifreeze', 'muscletech', 'suis']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #420000 to Dictionary(68847 unique tokens: ['msm8916', 'msil', 'antifreeze', 'muscletech', 'suis']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #430000 to Dictionary(69456 unique tokens: ['msm8916', 'msil', 'antifreeze', 'muscletech', 'suis']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #440000 to Dictionary(69958 unique tokens: ['msm8916', 'msil', 'antifreeze', 'muscletech', 'suis']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #450000 to Dictionary(70469 unique tokens: ['msm8916', 'msil', 'antifreeze', 'muscletech', 'suis']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #460000 to Dictionary(70978 unique tokens: ['msm8916', 'msil', 'antifreeze', 'muscletech', 'suis']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #470000 to Dictionary(71513 unique tokens: ['msm8916', 'msil', 'antifreeze', 'muscletech', 'suis']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #480000 to Dictionary(72060 unique tokens: ['msm8916', 'msil', 'antifreeze', 'muscletech', 'suis']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #490000 to Dictionary(72564 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #500000 to Dictionary(73070 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #510000 to Dictionary(73554 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #520000 to Dictionary(74018 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #530000 to Dictionary(74471 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #540000 to Dictionary(74997 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #550000 to Dictionary(75493 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #560000 to Dictionary(75994 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #570000 to Dictionary(76458 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #580000 to Dictionary(76925 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #590000 to Dictionary(77378 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #600000 to Dictionary(77785 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #610000 to Dictionary(78232 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #620000 to Dictionary(78657 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #630000 to Dictionary(79156 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #640000 to Dictionary(79591 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #650000 to Dictionary(80057 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #660000 to Dictionary(80531 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #670000 to Dictionary(80969 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #680000 to Dictionary(81415 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #690000 to Dictionary(81821 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #700000 to Dictionary(82241 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #710000 to Dictionary(82665 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #720000 to Dictionary(83092 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #730000 to Dictionary(83488 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #740000 to Dictionary(83888 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #750000 to Dictionary(84302 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #760000 to Dictionary(84701 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #770000 to Dictionary(85137 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #780000 to Dictionary(85528 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #790000 to Dictionary(85950 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:adding document #800000 to Dictionary(86336 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...)\n",
      "INFO:gensim.corpora.dictionary:built Dictionary(86691 unique tokens: ['msm8916', 'msil', 'chedule', 'antifreeze', 'muscletech']...) from 808580 documents (total 4726582 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "all_tokens = (list(data.question1.values) + list(data.question2.values))\n",
    "vectorizer = Dictionary(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.dictionary:discarding 56727 tokens: [('tiago', 4), ('motorolla', 1), ('dcx3400', 2), ('biprism', 1), ('slits', 4), ('fresnel', 4), ('aoa', 2), ('rexnord', 1), ('israil', 1), ('sincerity', 1)]...\n",
      "INFO:gensim.corpora.dictionary:keeping 29964 tokens which were in no less than 5 and no more than 80858 (=10.0%) documents\n",
      "INFO:gensim.corpora.dictionary:resulting dictionary: Dictionary(29964 unique tokens: ['xiaoping', 'antifreeze', 'graviton', 'tomcat', 'purge']...)\n"
     ]
    }
   ],
   "source": [
    "vectorizer.filter_extremes(no_below=5, no_above=0.1)\n",
    "vocab_size = len(vectorizer.dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions = list(map(vectorizer.doc2bow, list(data.question1.values) + list(data.question2.values)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.01\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 3.324026060364313e-05\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamulticore:running online LDA training, 100 topics, 1 passes over the supplied corpus of 808580 documents, updating every 4000 documents, evaluating every ~40000 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO:gensim.models.ldamulticore:training LDA model using 2 processes\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #0 = documents up to #2000/808580, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #1 = documents up to #4000/808580, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #2 = documents up to #6000/808580, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #3 = documents up to #8000/808580, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #4 = documents up to #10000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #5 = documents up to #12000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #6 = documents up to #14000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #52 (0.010): 0.035*\"get\" + 0.020*\"my\" + 0.016*\"or\" + 0.014*\"if\" + 0.013*\".\" + 0.013*\"best\" + 0.012*\"you\" + 0.012*\"have\" + 0.012*\"job\" + 0.009*\"should\"\n",
      "INFO:gensim.models.ldamodel:topic #53 (0.010): 0.026*\"get\" + 0.019*\"your\" + 0.017*\"you\" + 0.016*\"without\" + 0.014*\"on\" + 0.014*\"my\" + 0.011*\"from\" + 0.011*\".\" + 0.011*\"not\" + 0.010*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic #72 (0.010): 0.019*\"should\" + 0.017*\"you\" + 0.016*\".\" + 0.015*\"my\" + 0.014*\"it\" + 0.012*\"if\" + 0.011*\"this\" + 0.011*\"new\" + 0.011*\"we\" + 0.011*\"have\"\n",
      "INFO:gensim.models.ldamodel:topic #79 (0.010): 0.031*\"best\" + 0.019*\"should\" + 0.015*\"be\" + 0.012*\"does\" + 0.012*\"which\" + 0.009*\"way\" + 0.009*\"learn\" + 0.009*\"between\" + 0.009*\"with\" + 0.009*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #25 (0.010): 0.029*\"it\" + 0.016*\"you\" + 0.016*\"girl\" + 0.015*\"have\" + 0.014*\".\" + 0.014*\"like\" + 0.013*\"who\" + 0.011*\"get\" + 0.011*\"eat\" + 0.011*\"\"\"\n",
      "INFO:gensim.models.ldamodel:topic diff=99.860146, rho=1.000000\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #7 = documents up to #16000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #8 = documents up to #18000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #85 (0.010): 0.024*\"you\" + 0.022*\".\" + 0.019*\"my\" + 0.012*\"that\" + 0.012*\"get\" + 0.012*\"or\" + 0.010*\"should\" + 0.010*\"people\" + 0.008*\"did\" + 0.008*\"think\"\n",
      "INFO:gensim.models.ldamodel:topic #34 (0.010): 0.016*\".\" + 0.016*\"best\" + 0.014*\"\"\" + 0.013*\"between\" + 0.011*\"one\" + 0.011*\"your\" + 0.010*\"get\" + 0.010*\"difference\" + 0.010*\"be\" + 0.009*\"my\"\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.010): 0.036*\"or\" + 0.032*\"my\" + 0.019*\"should\" + 0.018*\"if\" + 0.017*\"not\" + 0.013*\"any\" + 0.013*\".\" + 0.013*\"there\" + 0.012*\"as\" + 0.009*\"facebook\"\n",
      "INFO:gensim.models.ldamodel:topic #54 (0.010): 0.037*\"you\" + 0.019*\"have\" + 0.017*\"did\" + 0.014*\"that\" + 0.012*\"it\" + 0.010*\"know\" + 0.010*\"which\" + 0.010*\"best\" + 0.009*\"time\" + 0.009*\"with\"\n",
      "INFO:gensim.models.ldamodel:topic #88 (0.010): 0.026*\"does\" + 0.021*\"not\" + 0.013*\".\" + 0.012*\"with\" + 0.012*\"as\" + 0.011*\"will\" + 0.011*\"you\" + 0.011*\"if\" + 0.010*\"on\" + 0.010*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.785026, rho=0.577350\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #9 = documents up to #20000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #10 = documents up to #22000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #31 (0.010): 0.020*\"some\" + 0.020*\"notes\" + 0.019*\"1000\" + 0.017*\"500\" + 0.017*\"on\" + 0.016*\"with\" + 0.012*\"rs\" + 0.012*\"will\" + 0.012*\"anyone\" + 0.011*\".\"\n",
      "INFO:gensim.models.ldamodel:topic #89 (0.010): 0.016*\"my\" + 0.015*\"software\" + 0.015*\".\" + 0.014*\"get\" + 0.014*\"like\" + 0.012*\"best\" + 0.010*\"where\" + 0.010*\"an\" + 0.010*\"on\" + 0.009*\"some\"\n",
      "INFO:gensim.models.ldamodel:topic #24 (0.010): 0.024*\"best\" + 0.021*\"quoted_item\" + 0.019*\"which\" + 0.017*\"does\" + 0.016*\".\" + 0.016*\"or\" + 0.015*\":\" + 0.014*\"(\" + 0.014*\")\" + 0.013*\"better\"\n",
      "INFO:gensim.models.ldamodel:topic #57 (0.010): 0.045*\"\"\" + 0.026*\"some\" + 0.016*\".\" + 0.014*\"best\" + 0.013*\"you\" + 0.011*\"examples\" + 0.010*\"it\" + 0.009*\"important\" + 0.008*\"which\" + 0.008*\"people\"\n",
      "INFO:gensim.models.ldamodel:topic #22 (0.010): 0.026*\"does\" + 0.017*\"on\" + 0.014*\"it\" + 0.014*\"instagram\" + 0.013*\"my\" + 0.013*\"she\" + 0.010*\"hair\" + 0.010*\"if\" + 0.010*\"when\" + 0.010*\"most\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.578678, rho=0.447214\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #11 = documents up to #24000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #12 = documents up to #26000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #58 (0.010): 0.018*\"good\" + 0.016*\"life\" + 0.012*\"you\" + 0.011*\"it\" + 0.010*\"which\" + 0.010*\"or\" + 0.010*\"at\" + 0.009*\"an\" + 0.009*\"most\" + 0.009*\"be\"\n",
      "INFO:gensim.models.ldamodel:topic #84 (0.010): 0.029*\"best\" + 0.022*\".\" + 0.021*\"you\" + 0.016*\"on\" + 0.014*\"which\" + 0.012*\"has\" + 0.012*\"my\" + 0.009*\"'\" + 0.009*\"name\" + 0.008*\"x\"\n",
      "INFO:gensim.models.ldamodel:topic #67 (0.010): 0.020*\"from\" + 0.019*\"process\" + 0.016*\"it\" + 0.015*\"on\" + 0.015*\"money\" + 0.014*\"mechanical\" + 0.014*\"out\" + 0.013*\"2017\" + 0.013*\"without\" + 0.012*\"2016\"\n",
      "INFO:gensim.models.ldamodel:topic #85 (0.010): 0.036*\".\" + 0.027*\"my\" + 0.019*\"you\" + 0.016*\"me\" + 0.015*\"get\" + 0.014*\"should\" + 0.012*\"well\" + 0.012*\"or\" + 0.011*\"that\" + 0.010*\"com\"\n",
      "INFO:gensim.models.ldamodel:topic #31 (0.010): 0.026*\"some\" + 0.025*\"notes\" + 0.025*\"1000\" + 0.021*\"500\" + 0.017*\"rs\" + 0.016*\"money\" + 0.015*\"banning\" + 0.014*\"with\" + 0.013*\"will\" + 0.013*\"who\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.367323, rho=0.377964\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #13 = documents up to #28000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #14 = documents up to #30000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #94 (0.010): 0.063*\"\"\" + 0.031*\"'\" + 0.015*\"if\" + 0.014*\"on\" + 0.014*\"or\" + 0.013*\"there\" + 0.012*\"india\" + 0.012*\"get\" + 0.012*\"be\" + 0.012*\"energy\"\n",
      "INFO:gensim.models.ldamodel:topic #67 (0.010): 0.020*\"from\" + 0.019*\"process\" + 0.018*\"on\" + 0.017*\"it\" + 0.015*\"prepare\" + 0.014*\"money\" + 0.013*\"you\" + 0.012*\"without\" + 0.012*\"at\" + 0.012*\"2017\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.031*\"get\" + 0.024*\"on\" + 0.023*\"be\" + 0.021*\"best\" + 0.012*\"will\" + 0.011*\"it\" + 0.011*\"art\" + 0.010*\"india\" + 0.010*\".\" + 0.010*\"twitter\"\n",
      "INFO:gensim.models.ldamodel:topic #47 (0.010): 0.024*\"does\" + 0.019*\"that\" + 0.018*\"on\" + 0.016*\"it\" + 0.013*\"you\" + 0.012*\":\" + 0.011*\"have\" + 0.011*\"/\" + 0.010*\"too\" + 0.010*\"after\"\n",
      "INFO:gensim.models.ldamodel:topic #64 (0.010): 0.020*\"get\" + 0.018*\"you\" + 0.018*\".\" + 0.018*\"on\" + 0.017*\"does\" + 0.015*\"if\" + 0.012*\"your\" + 0.011*\"would\" + 0.010*\"much\" + 0.009*\"best\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.258968, rho=0.333333\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #15 = documents up to #32000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #16 = documents up to #34000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #99 (0.010): 0.033*\"google\" + 0.024*\"on\" + 0.016*\"someone\" + 0.015*\"have\" + 0.014*\"they\" + 0.013*\".\" + 0.013*\"quora\" + 0.011*\"facebook\" + 0.010*\"get\" + 0.010*\"when\"\n",
      "INFO:gensim.models.ldamodel:topic #16 (0.010): 0.034*\"that\" + 0.026*\"you\" + 0.021*\"was\" + 0.014*\"on\" + 0.014*\"when\" + 0.013*\"chinese\" + 0.012*\"it\" + 0.012*\"some\" + 0.012*\"most\" + 0.011*\"your\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.016*\"or\" + 0.015*\"have\" + 0.014*\"things\" + 0.014*\"some\" + 0.014*\"america\" + 0.014*\"real\" + 0.013*\"average\" + 0.013*\"you\" + 0.012*\"ones\" + 0.011*\"child\"\n",
      "INFO:gensim.models.ldamodel:topic #51 (0.010): 0.071*\"between\" + 0.068*\"difference\" + 0.023*\"your\" + 0.020*\"movie\" + 0.016*\"'\" + 0.011*\"there\" + 0.011*\"review\" + 0.011*\"life\" + 0.009*\"would\" + 0.009*\"school\"\n",
      "INFO:gensim.models.ldamodel:topic #95 (0.010): 0.017*\"at\" + 0.015*\"be\" + 0.014*\"this\" + 0.014*\"have\" + 0.013*\"should\" + 0.013*\"positions\" + 0.013*\"does\" + 0.011*\"surgical\" + 0.011*\"balance\" + 0.011*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.206816, rho=0.301511\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #17 = documents up to #36000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #18 = documents up to #38000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #94 (0.010): 0.091*\"\"\" + 0.034*\"'\" + 0.025*\"energy\" + 0.017*\"if\" + 0.013*\"or\" + 0.013*\"meaning\" + 0.013*\"on\" + 0.013*\"there\" + 0.012*\"be\" + 0.012*\"india\"\n",
      "INFO:gensim.models.ldamodel:topic #46 (0.010): 0.021*\")\" + 0.021*\"(\" + 0.019*\"or\" + 0.017*\"my\" + 0.013*\"an\" + 0.011*\"uber\" + 0.011*\".\" + 0.010*\"if\" + 0.010*\"fail\" + 0.010*\"between\"\n",
      "INFO:gensim.models.ldamodel:topic #31 (0.010): 0.050*\"1000\" + 0.047*\"500\" + 0.046*\"notes\" + 0.029*\"rs\" + 0.024*\"will\" + 0.024*\"money\" + 0.022*\"black\" + 0.019*\"some\" + 0.017*\"rupee\" + 0.016*\"banning\"\n",
      "INFO:gensim.models.ldamodel:topic #74 (0.010): 0.033*\".\" + 0.030*\"does\" + 0.022*\":\" + 0.018*\"it\" + 0.013*\"or\" + 0.012*\"get\" + 0.012*\"which\" + 0.012*\"star\" + 0.010*\"india\" + 0.010*\"from\"\n",
      "INFO:gensim.models.ldamodel:topic #36 (0.010): 0.033*\"it\" + 0.024*\"an\" + 0.016*\"true\" + 0.015*\"old\" + 0.015*\"worth\" + 0.013*\"year\" + 0.013*\"\"\" + 0.013*\"does\" + 0.012*\"effective\" + 0.012*\"types\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.170297, rho=0.277350\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #19 = documents up to #40000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #20 = documents up to #42000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #49 (0.010): 0.020*\"have\" + 0.015*\"on\" + 0.012*\"science\" + 0.012*\"computer\" + 0.011*\"does\" + 0.011*\"about\" + 0.011*\"laws\" + 0.011*\"if\" + 0.011*\"both\" + 0.011*\"from\"\n",
      "INFO:gensim.models.ldamodel:topic #76 (0.010): 0.032*\"you\" + 0.017*\"best\" + 0.016*\"seen\" + 0.016*\"have\" + 0.014*\"years\" + 0.014*\"(\" + 0.014*\")\" + 0.013*\"watch\" + 0.013*\"which\" + 0.013*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #25 (0.010): 0.029*\"girl\" + 0.027*\"it\" + 0.024*\"not\" + 0.021*\"you\" + 0.020*\"that\" + 0.019*\"friends\" + 0.016*\"eat\" + 0.015*\"get\" + 0.015*\"people\" + 0.014*\"have\"\n",
      "INFO:gensim.models.ldamodel:topic #99 (0.010): 0.040*\"google\" + 0.028*\"on\" + 0.015*\"they\" + 0.015*\"quora\" + 0.013*\".\" + 0.013*\"get\" + 0.013*\"have\" + 0.013*\"just\" + 0.012*\"someone\" + 0.012*\"here\"\n",
      "INFO:gensim.models.ldamodel:topic #89 (0.010): 0.040*\"software\" + 0.017*\".\" + 0.016*\"battle\" + 0.016*\"get\" + 0.014*\"company\" + 0.013*\"actually\" + 0.013*\"where\" + 0.012*\"like\" + 0.012*\"term\" + 0.011*\"find\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.169100, rho=0.258199\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #21 = documents up to #44000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #22 = documents up to #46000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #91 (0.010): 0.033*\"with\" + 0.027*\"deal\" + 0.023*\"best\" + 0.015*\"my\" + 0.015*\"pictures\" + 0.015*\"does\" + 0.014*\"even\" + 0.013*\"on\" + 0.012*\"people\" + 0.012*\"days\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.089*\"my\" + 0.059*\"improve\" + 0.059*\"english\" + 0.026*\"should\" + 0.023*\"you\" + 0.018*\".\" + 0.017*\"speaking\" + 0.011*\"am\" + 0.009*\"who\" + 0.009*\"communication\"\n",
      "INFO:gensim.models.ldamodel:topic #15 (0.010): 0.029*\"made\" + 0.028*\"our\" + 0.026*\"women\" + 0.022*\"men\" + 0.022*\"happens\" + 0.021*\"say\" + 0.020*\"code\" + 0.019*\"china\" + 0.019*\"does\" + 0.019*\"we\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.038*\"get\" + 0.030*\"on\" + 0.028*\"best\" + 0.021*\"be\" + 0.019*\"daily\" + 0.019*\"face\" + 0.013*\"done\" + 0.013*\"art\" + 0.012*\"online\" + 0.012*\"twitter\"\n",
      "INFO:gensim.models.ldamodel:topic #95 (0.010): 0.025*\"at\" + 0.023*\"vote\" + 0.022*\"this\" + 0.020*\"does\" + 0.018*\"videos\" + 0.018*\"across\" + 0.018*\"good\" + 0.017*\"life\" + 0.017*\"have\" + 0.017*\"positions\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.134620, rho=0.242536\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #23 = documents up to #48000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #24 = documents up to #50000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.042*\"bing\" + 0.024*\"\"\" + 0.016*\"(\" + 0.016*\")\" + 0.016*\"y\" + 0.015*\"]\" + 0.015*\"[\" + 0.015*\"math\" + 0.014*\"over\" + 0.013*\"structure\"\n",
      "INFO:gensim.models.ldamodel:topic #64 (0.010): 0.021*\"does\" + 0.020*\"you\" + 0.020*\"get\" + 0.016*\"meet\" + 0.016*\"if\" + 0.016*\"on\" + 0.013*\"would\" + 0.012*\"need\" + 0.012*\".\" + 0.011*\"much\"\n",
      "INFO:gensim.models.ldamodel:topic #60 (0.010): 0.097*\"trump\" + 0.060*\"donald\" + 0.032*\"president\" + 0.027*\"clinton\" + 0.024*\"would\" + 0.023*\"will\" + 0.023*\"it\" + 0.022*\"you\" + 0.019*\"if\" + 0.018*\"hillary\"\n",
      "INFO:gensim.models.ldamodel:topic #42 (0.010): 0.024*\"songs\" + 0.023*\"help\" + 0.022*\"culture\" + 0.021*\"that\" + 0.017*\"white\" + 0.015*\"best\" + 0.014*\"other\" + 0.014*\"gain\" + 0.014*\"corporate\" + 0.014*\"you\"\n",
      "INFO:gensim.models.ldamodel:topic #78 (0.010): 0.062*\"earn\" + 0.051*\"money\" + 0.032*\"online\" + 0.029*\"best\" + 0.022*\"which\" + 0.018*\"with\" + 0.017*\"india\" + 0.014*\"colleges\" + 0.013*\"from\" + 0.012*\"does\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.129839, rho=0.229416\n",
      "INFO:gensim.models.ldamodel:-10.531 per-word bound, 1479.1 perplexity estimate based on a held-out corpus of 2000 documents with 15518 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #25 = documents up to #52000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #92 (0.010): 0.039*\"become\" + 0.025*\"use\" + 0.025*\"drive\" + 0.023*\"jobs\" + 0.021*\"create\" + 0.019*\"it\" + 0.017*\"be\" + 0.016*\"cell\" + 0.014*\"from\" + 0.013*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #31 (0.010): 0.073*\"notes\" + 0.070*\"500\" + 0.070*\"1000\" + 0.046*\"rs\" + 0.038*\"will\" + 0.037*\"black\" + 0.027*\"money\" + 0.027*\"rupee\" + 0.018*\".\" + 0.018*\"banning\"\n",
      "INFO:gensim.models.ldamodel:topic #93 (0.010): 0.026*\"people\" + 0.023*\"you\" + 0.022*\"be\" + 0.020*\"not\" + 0.017*\"share\" + 0.015*\"listen\" + 0.015*\"reading\" + 0.014*\"should\" + 0.014*\"on\" + 0.013*\".\"\n",
      "INFO:gensim.models.ldamodel:topic #72 (0.010): 0.051*\"things\" + 0.043*\"should\" + 0.040*\"first\" + 0.038*\"day\" + 0.035*\"know\" + 0.033*\"some\" + 0.033*\"going\" + 0.029*\"into\" + 0.029*\"their\" + 0.027*\"new\"\n",
      "INFO:gensim.models.ldamodel:topic #19 (0.010): 0.027*\".\" + 0.022*\"drug\" + 0.021*\"center\" + 0.020*\"alcohol\" + 0.018*\"myself\" + 0.017*\"it\" + 0.016*\"near\" + 0.016*\"county\" + 0.015*\"value\" + 0.015*\"he\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.130168, rho=0.218218\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #26 = documents up to #54000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #27 = documents up to #56000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #28 = documents up to #58000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.099*\"non_ascii_word\" + 0.039*\".\" + 0.032*\"delhi\" + 0.027*\"(\" + 0.026*\")\" + 0.020*\"does\" + 0.019*\"\"\" + 0.016*\"it\" + 0.014*\"oil\" + 0.013*\"developed\"\n",
      "INFO:gensim.models.ldamodel:topic #60 (0.010): 0.102*\"trump\" + 0.063*\"donald\" + 0.039*\"president\" + 0.031*\"will\" + 0.030*\"clinton\" + 0.024*\"it\" + 0.023*\"would\" + 0.022*\"hillary\" + 0.021*\"you\" + 0.021*\"take\"\n",
      "INFO:gensim.models.ldamodel:topic #30 (0.010): 0.073*\"make\" + 0.057*\"money\" + 0.021*\"does\" + 0.018*\"from\" + 0.016*\"degree\" + 0.016*\"much\" + 0.015*\"current\" + 0.014*\"that\" + 0.014*\"full\" + 0.013*\"happened\"\n",
      "INFO:gensim.models.ldamodel:topic #97 (0.010): 0.037*\"you\" + 0.029*\"study\" + 0.025*\"be\" + 0.025*\"more\" + 0.016*\"give\" + 0.016*\"germany\" + 0.016*\"modern\" + 0.015*\"which\" + 0.014*\"please\" + 0.013*\"(\"\n",
      "INFO:gensim.models.ldamodel:topic #51 (0.010): 0.153*\"between\" + 0.140*\"difference\" + 0.032*\"movie\" + 0.025*\"your\" + 0.023*\"review\" + 0.018*\"brain\" + 0.016*\"city\" + 0.015*\"'\" + 0.013*\"there\" + 0.011*\"three\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.121923, rho=0.208514\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #29 = documents up to #60000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #30 = documents up to #62000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #21 (0.010): 0.052*\"math\" + 0.043*\"]\" + 0.043*\"[\" + 0.036*\"/\" + 0.028*\"exam\" + 0.027*\"x\" + 0.022*\"messages\" + 0.020*\"games\" + 0.020*\"^\" + 0.018*\"gate\"\n",
      "INFO:gensim.models.ldamodel:topic #37 (0.010): 0.033*\"apple\" + 0.030*\"who\" + 0.029*\"next\" + 0.022*\"americans\" + 0.021*\"does\" + 0.018*\"penis\" + 0.017*\"when\" + 0.016*\"been\" + 0.014*\"be\" + 0.014*\"will\"\n",
      "INFO:gensim.models.ldamodel:topic #34 (0.010): 0.026*\"legal\" + 0.017*\"product\" + 0.017*\"where\" + 0.015*\"written\" + 0.015*\"happy\" + 0.015*\"passport\" + 0.014*\"one\" + 0.014*\"expect\" + 0.014*\"find\" + 0.013*\"be\"\n",
      "INFO:gensim.models.ldamodel:topic #48 (0.010): 0.055*\"india\" + 0.028*\"government\" + 0.020*\"female\" + 0.017*\"each\" + 0.016*\"other\" + 0.014*\"preparing\" + 0.014*\"numbers\" + 0.014*\"politics\" + 0.014*\"network\" + 0.014*\"not\"\n",
      "INFO:gensim.models.ldamodel:topic #63 (0.010): 0.064*\"sex\" + 0.057*\"you\" + 0.029*\"have\" + 0.026*\"it\" + 0.021*\"if\" + 0.020*\"earth\" + 0.020*\"like\" + 0.020*\"life\" + 0.017*\"purpose\" + 0.015*\"does\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.116820, rho=0.200000\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #31 = documents up to #64000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #32 = documents up to #66000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #58 (0.010): 0.038*\"java\" + 0.034*\"life\" + 0.029*\"development\" + 0.029*\"web\" + 0.027*\"living\" + 0.024*\"app\" + 0.022*\"android\" + 0.021*\"best\" + 0.021*\"search\" + 0.021*\"game\"\n",
      "INFO:gensim.models.ldamodel:topic #67 (0.010): 0.027*\"from\" + 0.026*\"prepare\" + 0.024*\"process\" + 0.023*\"mechanical\" + 0.021*\"england\" + 0.021*\"bank\" + 0.017*\"2017\" + 0.017*\"invest\" + 0.017*\"it\" + 0.016*\"cat\"\n",
      "INFO:gensim.models.ldamodel:topic #18 (0.010): 0.069*\"business\" + 0.032*\"time\" + 0.024*\"start\" + 0.021*\"my\" + 0.016*\"it\" + 0.016*\"with\" + 0.015*\"you\" + 0.014*\"get\" + 0.014*\"negative\" + 0.014*\"physics\"\n",
      "INFO:gensim.models.ldamodel:topic #52 (0.010): 0.030*\"career\" + 0.026*\"house\" + 0.025*\"options\" + 0.020*\"after\" + 0.018*\"opinion\" + 0.017*\"get\" + 0.016*\"possible\" + 0.015*\"humans\" + 0.015*\"your\" + 0.014*\"animals\"\n",
      "INFO:gensim.models.ldamodel:topic #42 (0.010): 0.041*\"help\" + 0.031*\"songs\" + 0.030*\"culture\" + 0.025*\"white\" + 0.019*\"gain\" + 0.019*\"that\" + 0.016*\"self\" + 0.016*\"companies\" + 0.015*\"best\" + 0.014*\"other\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.103741, rho=0.192450\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #33 = documents up to #68000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #34 = documents up to #70000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #33 (0.010): 0.037*\"you\" + 0.032*\"music\" + 0.032*\"management\" + 0.025*\"your\" + 0.023*\"move\" + 0.023*\"determine\" + 0.020*\"2017\" + 0.018*\"new\" + 0.018*\"offer\" + 0.018*\"year\"\n",
      "INFO:gensim.models.ldamodel:topic #59 (0.010): 0.081*\"\"\" + 0.027*\"amazon\" + 0.025*\"you\" + 0.024*\"on\" + 0.020*\"send\" + 0.016*\"if\" + 0.016*\"not\" + 0.014*\"was\" + 0.014*\"did\" + 0.013*\"saved\"\n",
      "INFO:gensim.models.ldamodel:topic #82 (0.010): 0.048*\"you\" + 0.023*\"game\" + 0.022*\"have\" + 0.020*\"bad\" + 0.017*\"fix\" + 0.017*\"that\" + 0.017*\"prove\" + 0.016*\"technologies\" + 0.015*\"not\" + 0.014*\"when\"\n",
      "INFO:gensim.models.ldamodel:topic #19 (0.010): 0.036*\"myself\" + 0.025*\".\" + 0.023*\"near\" + 0.023*\"alcohol\" + 0.022*\"drug\" + 0.021*\"value\" + 0.021*\"center\" + 0.017*\"mass\" + 0.016*\"county\" + 0.016*\"note\"\n",
      "INFO:gensim.models.ldamodel:topic #70 (0.010): 0.133*\"quora\" + 0.084*\"on\" + 0.051*\"questions\" + 0.042*\"question\" + 0.025*\"ask\" + 0.023*\"you\" + 0.019*\"as\" + 0.018*\"such\" + 0.017*\"answer\" + 0.017*\"my\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.094899, rho=0.185695\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #35 = documents up to #72000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #36 = documents up to #74000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #32 (0.010): 0.045*\"exist\" + 0.037*\"hate\" + 0.029*\"you\" + 0.027*\"does\" + 0.020*\"once\" + 0.016*\"really\" + 0.015*\"an\" + 0.015*\"there\" + 0.015*\"amount\" + 0.014*\"teeth\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.010): 0.073*\"find\" + 0.039*\"where\" + 0.033*\"support\" + 0.020*\"times\" + 0.019*\"religion\" + 0.019*\"sim\" + 0.016*\"use\" + 0.015*\"number\" + 0.015*\"phone\" + 0.014*\"quickly\"\n",
      "INFO:gensim.models.ldamodel:topic #20 (0.010): 0.053*\"place\" + 0.044*\"best\" + 0.037*\"usa\" + 0.024*\"india\" + 0.021*\"which\" + 0.018*\"visit\" + 0.016*\"where\" + 0.016*\"interested\" + 0.015*\"estate\" + 0.015*\"real\"\n",
      "INFO:gensim.models.ldamodel:topic #38 (0.010): 0.039*\"looking\" + 0.038*\"play\" + 0.037*\"universities\" + 0.035*\"from\" + 0.033*\"they\" + 0.030*\"does\" + 0.028*\"new\" + 0.021*\"national\" + 0.021*\"recruit\" + 0.020*\"never\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.085*\"your\" + 0.047*\"favorite\" + 0.023*\"high\" + 0.018*\"easy\" + 0.017*\"you\" + 0.016*\"school\" + 0.015*\"understand\" + 0.014*\"join\" + 0.013*\"experiences\" + 0.013*\"that\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.092923, rho=0.179605\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #37 = documents up to #76000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #38 = documents up to #78000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.089*\"your\" + 0.049*\"favorite\" + 0.023*\"high\" + 0.019*\"easy\" + 0.018*\"you\" + 0.018*\"school\" + 0.015*\"understand\" + 0.015*\"join\" + 0.014*\"experiences\" + 0.013*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic #60 (0.010): 0.104*\"trump\" + 0.062*\"donald\" + 0.041*\"president\" + 0.039*\"will\" + 0.033*\"take\" + 0.032*\"clinton\" + 0.027*\"hillary\" + 0.025*\"it\" + 0.023*\"would\" + 0.022*\"win\"\n",
      "INFO:gensim.models.ldamodel:topic #62 (0.010): 0.039*\"getting\" + 0.035*\".\" + 0.028*\"engineering\" + 0.022*\"university\" + 0.021*\"mumbai\" + 0.020*\"civil\" + 0.020*\"file\" + 0.020*\"etc\" + 0.019*\"an\" + 0.019*\"post\"\n",
      "INFO:gensim.models.ldamodel:topic #86 (0.010): 0.066*\"you\" + 0.063*\"read\" + 0.059*\"books\" + 0.049*\"your\" + 0.033*\"best\" + 0.027*\"have\" + 0.025*\"life\" + 0.021*\"fat\" + 0.020*\"which\" + 0.020*\"very\"\n",
      "INFO:gensim.models.ldamodel:topic #84 (0.010): 0.054*\"book\" + 0.051*\"name\" + 0.042*\"best\" + 0.030*\"which\" + 0.023*\"series\" + 0.019*\"tv\" + 0.017*\"hire\" + 0.016*\"ias\" + 0.015*\".\" + 0.015*\"left\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.098099, rho=0.174078\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #39 = documents up to #80000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #40 = documents up to #82000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #16 (0.010): 0.044*\"that\" + 0.043*\"college\" + 0.036*\"chinese\" + 0.033*\"major\" + 0.026*\"you\" + 0.026*\"was\" + 0.025*\"reason\" + 0.019*\"when\" + 0.016*\"away\" + 0.015*\"changed\"\n",
      "INFO:gensim.models.ldamodel:topic #88 (0.010): 0.040*\"years\" + 0.038*\"many\" + 0.031*\"dollar\" + 0.023*\"20\" + 0.020*\"5\" + 0.018*\"price\" + 0.017*\"go\" + 0.017*\"does\" + 0.016*\"hours\" + 0.016*\"there\"\n",
      "INFO:gensim.models.ldamodel:topic #56 (0.010): 0.046*\"about\" + 0.040*\"some\" + 0.033*\"facts\" + 0.028*\"based\" + 0.025*\"known\" + 0.025*\"model\" + 0.022*\"india\" + 0.022*\"australia\" + 0.021*\"interesting\" + 0.019*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.010): 0.091*\"find\" + 0.042*\"where\" + 0.038*\"support\" + 0.023*\"times\" + 0.019*\"sim\" + 0.017*\"number\" + 0.016*\"religion\" + 0.016*\"phone\" + 0.015*\"jio\" + 0.014*\"use\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.053*\"get\" + 0.037*\"on\" + 0.034*\"rid\" + 0.032*\"face\" + 0.029*\"best\" + 0.025*\"daily\" + 0.023*\"impact\" + 0.022*\"be\" + 0.021*\"ways\" + 0.019*\"twitter\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.084240, rho=0.169031\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #41 = documents up to #84000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #42 = documents up to #86000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #72 (0.010): 0.075*\"things\" + 0.068*\"first\" + 0.068*\"day\" + 0.053*\"know\" + 0.050*\"going\" + 0.047*\"into\" + 0.047*\"should\" + 0.041*\"some\" + 0.040*\"their\" + 0.038*\"new\"\n",
      "INFO:gensim.models.ldamodel:topic #33 (0.010): 0.035*\"you\" + 0.035*\"music\" + 0.034*\"management\" + 0.028*\"2017\" + 0.026*\"power\" + 0.025*\"your\" + 0.025*\"move\" + 0.022*\"new\" + 0.022*\"determine\" + 0.021*\"year\"\n",
      "INFO:gensim.models.ldamodel:topic #43 (0.010): 0.069*\"job\" + 0.057*\"through\" + 0.054*\"interview\" + 0.042*\"making\" + 0.040*\"learning\" + 0.040*\"some\" + 0.039*\"tips\" + 0.035*\"it\" + 0.031*\"machine\" + 0.029*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #57 (0.010): 0.340*\"\"\" + 0.055*\"examples\" + 0.050*\"some\" + 0.045*\"important\" + 0.022*\"word\" + 0.019*\"mean\" + 0.018*\"side\" + 0.016*\"does\" + 0.011*\"you\" + 0.008*\"quoted_item\"\n",
      "INFO:gensim.models.ldamodel:topic #99 (0.010): 0.108*\"google\" + 0.024*\"on\" + 0.024*\"speak\" + 0.019*\"just\" + 0.019*\"view\" + 0.017*\"here\" + 0.016*\"they\" + 0.015*\"specific\" + 0.015*\"sbi\" + 0.014*\"get\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.079528, rho=0.164399\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #43 = documents up to #88000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #44 = documents up to #90000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #87 (0.010): 0.048*\"parents\" + 0.032*\"date\" + 0.026*\"knowledge\" + 0.024*\"you\" + 0.019*\"land\" + 0.018*\"with\" + 0.017*\"my\" + 0.015*\"have\" + 0.014*\"or\" + 0.013*\"performance\"\n",
      "INFO:gensim.models.ldamodel:topic #10 (0.010): 0.066*\"buy\" + 0.046*\"phone\" + 0.039*\"best\" + 0.037*\"under\" + 0.031*\"which\" + 0.024*\"benefits\" + 0.019*\"6\" + 0.017*\"financial\" + 0.016*\"studies\" + 0.015*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #15 (0.010): 0.057*\"women\" + 0.046*\"made\" + 0.046*\"men\" + 0.045*\"our\" + 0.042*\"china\" + 0.037*\"happens\" + 0.033*\"we\" + 0.029*\"say\" + 0.026*\"now\" + 0.020*\"code\"\n",
      "INFO:gensim.models.ldamodel:topic #54 (0.010): 0.079*\"lose\" + 0.065*\"weight\" + 0.045*\"you\" + 0.035*\"man\" + 0.032*\"being\" + 0.030*\"die\" + 0.026*\"websites\" + 0.023*\"best\" + 0.023*\"way\" + 0.018*\"porn\"\n",
      "INFO:gensim.models.ldamodel:topic #36 (0.010): 0.061*\"old\" + 0.055*\"it\" + 0.042*\"year\" + 0.036*\"worth\" + 0.035*\"true\" + 0.029*\"salary\" + 0.028*\"an\" + 0.028*\"fast\" + 0.023*\"effective\" + 0.020*\"application\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.082083, rho=0.160128\n",
      "INFO:gensim.models.ldamodel:-9.026 per-word bound, 521.3 perplexity estimate based on a held-out corpus of 2000 documents with 15169 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #45 = documents up to #92000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.010): 0.066*\"if\" + 0.063*\"would\" + 0.060*\"happen\" + 0.034*\"light\" + 0.026*\"car\" + 0.025*\"will\" + 0.022*\"design\" + 0.020*\"faster\" + 0.017*\"speed\" + 0.015*\"rank\"\n",
      "INFO:gensim.models.ldamodel:topic #75 (0.010): 0.039*\"wrong\" + 0.036*\"internet\" + 0.024*\"part\" + 0.024*\"studying\" + 0.023*\"professional\" + 0.022*\"modi\" + 0.021*\"speed\" + 0.020*\"best\" + 0.018*\"final\" + 0.015*\"where\"\n",
      "INFO:gensim.models.ldamodel:topic #93 (0.010): 0.029*\"share\" + 0.026*\"reading\" + 0.024*\"free\" + 0.024*\"be\" + 0.023*\"also\" + 0.021*\"not\" + 0.021*\"allowed\" + 0.018*\"people\" + 0.017*\"attack\" + 0.015*\"you\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.010): 0.047*\"skills\" + 0.041*\"writing\" + 0.034*\"show\" + 0.030*\"stay\" + 0.028*\"causes\" + 0.024*\"wear\" + 0.021*\"pro\" + 0.021*\"go\" + 0.021*\"pokemon\" + 0.019*\"team\"\n",
      "INFO:gensim.models.ldamodel:topic #56 (0.010): 0.045*\"about\" + 0.042*\"some\" + 0.035*\"facts\" + 0.030*\"australia\" + 0.027*\"based\" + 0.027*\"known\" + 0.026*\"japanese\" + 0.024*\"model\" + 0.024*\"interesting\" + 0.023*\"india\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.075591, rho=0.156174\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #46 = documents up to #94000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #47 = documents up to #96000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #48 = documents up to #98000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #47 (0.010): 0.068*\"does\" + 0.062*\"mean\" + 0.043*\"it\" + 0.029*\"too\" + 0.028*\"when\" + 0.028*\"call\" + 0.017*\"that\" + 0.016*\"plan\" + 0.016*\"by\" + 0.016*\"you\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.068*\"get\" + 0.051*\"rid\" + 0.037*\"on\" + 0.035*\"face\" + 0.030*\"best\" + 0.027*\"ways\" + 0.025*\"daily\" + 0.021*\"my\" + 0.019*\"impact\" + 0.019*\"twitter\"\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.010): 0.084*\"my\" + 0.059*\"facebook\" + 0.032*\"password\" + 0.032*\"email\" + 0.031*\"account\" + 0.031*\"gmail\" + 0.028*\"number\" + 0.025*\"recover\" + 0.019*\"if\" + 0.018*\"deleted\"\n",
      "INFO:gensim.models.ldamodel:topic #76 (0.010): 0.045*\"watch\" + 0.045*\"you\" + 0.031*\"seen\" + 0.031*\"something\" + 0.030*\"have\" + 0.022*\"best\" + 0.015*\"which\" + 0.015*\"tax\" + 0.014*\"season\" + 0.013*\"interest\"\n",
      "INFO:gensim.models.ldamodel:topic #43 (0.010): 0.088*\"job\" + 0.059*\"through\" + 0.058*\"interview\" + 0.052*\"learning\" + 0.045*\"making\" + 0.041*\"tips\" + 0.040*\"some\" + 0.035*\"it\" + 0.030*\"affect\" + 0.030*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.075335, rho=0.152499\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #49 = documents up to #100000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #50 = documents up to #102000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #34 (0.010): 0.036*\"product\" + 0.034*\"legal\" + 0.028*\"happy\" + 0.023*\"passport\" + 0.023*\"expect\" + 0.022*\"written\" + 0.019*\"core\" + 0.018*\"be\" + 0.015*\"programs\" + 0.014*\"various\"\n",
      "INFO:gensim.models.ldamodel:topic #52 (0.010): 0.042*\"career\" + 0.028*\"house\" + 0.026*\"options\" + 0.025*\"humans\" + 0.024*\"possible\" + 0.023*\"chemical\" + 0.022*\"travel\" + 0.021*\"after\" + 0.019*\"opinion\" + 0.017*\"taking\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.071*\"get\" + 0.052*\"rid\" + 0.036*\"on\" + 0.034*\"face\" + 0.029*\"ways\" + 0.029*\"best\" + 0.026*\"daily\" + 0.022*\"my\" + 0.020*\"impact\" + 0.019*\"twitter\"\n",
      "INFO:gensim.models.ldamodel:topic #18 (0.010): 0.072*\"business\" + 0.053*\"time\" + 0.025*\"back\" + 0.022*\"my\" + 0.020*\"12\" + 0.019*\"it\" + 0.019*\"start\" + 0.019*\"physics\" + 0.018*\"instead\" + 0.017*\"method\"\n",
      "INFO:gensim.models.ldamodel:topic #84 (0.010): 0.065*\"book\" + 0.060*\"name\" + 0.041*\"best\" + 0.033*\"which\" + 0.024*\"series\" + 0.023*\"left\" + 0.022*\"tv\" + 0.021*\"hire\" + 0.019*\"ias\" + 0.018*\"should\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.070665, rho=0.149071\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #51 = documents up to #104000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #52 = documents up to #106000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #31 (0.010): 0.084*\"500\" + 0.084*\"notes\" + 0.083*\"1000\" + 0.060*\"black\" + 0.059*\"rs\" + 0.044*\"will\" + 0.035*\"rupee\" + 0.032*\"great\" + 0.032*\"indian\" + 0.031*\"anyone\"\n",
      "INFO:gensim.models.ldamodel:topic #59 (0.010): 0.032*\"amazon\" + 0.031*\"\"\" + 0.028*\"you\" + 0.028*\"on\" + 0.025*\"still\" + 0.024*\"send\" + 0.019*\"was\" + 0.018*\"not\" + 0.018*\"did\" + 0.015*\"whole\"\n",
      "INFO:gensim.models.ldamodel:topic #79 (0.010): 0.056*\"kind\" + 0.043*\"overcome\" + 0.025*\"fear\" + 0.023*\"beginner\" + 0.022*\"best\" + 0.019*\"expected\" + 0.017*\"cutoff\" + 0.017*\"cut\" + 0.016*\"designer\" + 0.014*\"you\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.055*\"real\" + 0.041*\"average\" + 0.040*\"america\" + 0.039*\"food\" + 0.022*\"marriage\" + 0.022*\"non\" + 0.021*\"age\" + 0.021*\"there\" + 0.020*\"child\" + 0.019*\"married\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.010): 0.083*\"my\" + 0.066*\"increase\" + 0.033*\"height\" + 0.031*\"get\" + 0.030*\"traffic\" + 0.025*\"called\" + 0.025*\"dog\" + 0.023*\"does\" + 0.022*\"it\" + 0.021*\"function\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.071230, rho=0.145865\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #53 = documents up to #108000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #54 = documents up to #110000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.056*\"real\" + 0.044*\"food\" + 0.042*\"average\" + 0.040*\"america\" + 0.023*\"marriage\" + 0.022*\"non\" + 0.021*\"child\" + 0.020*\"age\" + 0.020*\"there\" + 0.019*\"100\"\n",
      "INFO:gensim.models.ldamodel:topic #93 (0.010): 0.031*\"free\" + 0.031*\"also\" + 0.026*\"reading\" + 0.025*\"be\" + 0.024*\"share\" + 0.024*\"allowed\" + 0.021*\"not\" + 0.019*\"attack\" + 0.019*\"people\" + 0.015*\"should\"\n",
      "INFO:gensim.models.ldamodel:topic #25 (0.010): 0.042*\"girl\" + 0.039*\"not\" + 0.034*\"that\" + 0.033*\"eat\" + 0.029*\"guy\" + 0.027*\"friends\" + 0.026*\"common\" + 0.026*\"woman\" + 0.023*\"it\" + 0.022*\"you\"\n",
      "INFO:gensim.models.ldamodel:topic #51 (0.010): 0.238*\"between\" + 0.177*\"difference\" + 0.055*\"movie\" + 0.025*\"review\" + 0.023*\"your\" + 0.022*\"city\" + 0.021*\"law\" + 0.019*\"brain\" + 0.018*\"kill\" + 0.014*\"three\"\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.010): 0.090*\"my\" + 0.063*\"facebook\" + 0.037*\"email\" + 0.037*\"account\" + 0.036*\"password\" + 0.030*\"gmail\" + 0.028*\"number\" + 0.025*\"recover\" + 0.019*\"if\" + 0.018*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.070364, rho=0.142857\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #55 = documents up to #112000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #56 = documents up to #114000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #12 (0.010): 0.165*\".\" + 0.045*\"girls\" + 0.041*\"u\" + 0.038*\"answers\" + 0.033*\"b\" + 0.025*\"guys\" + 0.020*\"30\" + 0.019*\"japan\" + 0.018*\"rate\" + 0.017*\"like\"\n",
      "INFO:gensim.models.ldamodel:topic #93 (0.010): 0.031*\"free\" + 0.028*\"also\" + 0.028*\"be\" + 0.026*\"reading\" + 0.023*\"allowed\" + 0.022*\"not\" + 0.022*\"people\" + 0.021*\"share\" + 0.020*\"attack\" + 0.018*\"should\"\n",
      "INFO:gensim.models.ldamodel:topic #16 (0.010): 0.072*\"college\" + 0.045*\"chinese\" + 0.041*\"that\" + 0.037*\"major\" + 0.031*\"reason\" + 0.023*\"was\" + 0.022*\"away\" + 0.021*\"percentage\" + 0.020*\"changed\" + 0.020*\"you\"\n",
      "INFO:gensim.models.ldamodel:topic #58 (0.010): 0.073*\"app\" + 0.045*\"java\" + 0.043*\"web\" + 0.037*\"development\" + 0.035*\"living\" + 0.030*\"android\" + 0.025*\"life\" + 0.024*\"best\" + 0.022*\"an\" + 0.021*\"search\"\n",
      "INFO:gensim.models.ldamodel:topic #94 (0.010): 0.214*\"'\" + 0.056*\"meaning\" + 0.037*\"energy\" + 0.031*\"\"\" + 0.025*\"universe\" + 0.024*\"pakistan\" + 0.016*\"minimum\" + 0.015*\"hindi\" + 0.014*\"india\" + 0.013*\"be\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.070919, rho=0.140028\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #57 = documents up to #116000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #58 = documents up to #118000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #56 (0.010): 0.050*\"some\" + 0.038*\"about\" + 0.035*\"based\" + 0.034*\"facts\" + 0.033*\"australia\" + 0.032*\"interesting\" + 0.027*\"known\" + 0.024*\"japanese\" + 0.023*\"people\" + 0.022*\"india\"\n",
      "INFO:gensim.models.ldamodel:topic #84 (0.010): 0.070*\"name\" + 0.068*\"book\" + 0.038*\"best\" + 0.033*\"series\" + 0.031*\"which\" + 0.029*\"tv\" + 0.024*\"left\" + 0.021*\"hire\" + 0.021*\"my\" + 0.020*\"ias\"\n",
      "INFO:gensim.models.ldamodel:topic #98 (0.010): 0.042*\"site\" + 0.039*\"less\" + 0.039*\"form\" + 0.035*\"download\" + 0.031*\"its\" + 0.029*\"best\" + 0.024*\"develop\" + 0.022*\"office\" + 0.021*\"which\" + 0.020*\"charge\"\n",
      "INFO:gensim.models.ldamodel:topic #85 (0.010): 0.114*\".\" + 0.068*\"me\" + 0.059*\"my\" + 0.033*\"he\" + 0.032*\"her\" + 0.026*\"am\" + 0.025*\"not\" + 0.024*\"should\" + 0.023*\"if\" + 0.023*\"she\"\n",
      "INFO:gensim.models.ldamodel:topic #66 (0.010): 0.055*\"done\" + 0.046*\"ever\" + 0.046*\"best\" + 0.036*\"space\" + 0.032*\"have\" + 0.029*\"coaching\" + 0.026*\"some\" + 0.026*\"you\" + 0.026*\"which\" + 0.025*\"institute\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.066974, rho=0.137361\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #59 = documents up to #120000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #60 = documents up to #122000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #52 (0.010): 0.048*\"career\" + 0.037*\"possible\" + 0.030*\"house\" + 0.028*\"travel\" + 0.028*\"humans\" + 0.024*\"after\" + 0.023*\"chemical\" + 0.022*\"it\" + 0.021*\"options\" + 0.020*\"opinion\"\n",
      "INFO:gensim.models.ldamodel:topic #35 (0.010): 0.046*\"movies\" + 0.042*\"some\" + 0.030*\"down\" + 0.029*\"iit\" + 0.027*\"jee\" + 0.027*\"project\" + 0.025*\"topics\" + 0.024*\"good\" + 0.021*\"put\" + 0.021*\"russia\"\n",
      "INFO:gensim.models.ldamodel:topic #61 (0.010): 0.092*\"thing\" + 0.066*\"you\" + 0.032*\"have\" + 0.030*\"that\" + 0.029*\"most\" + 0.029*\"demonetization\" + 0.023*\"ever\" + 0.022*\"given\" + 0.021*\"advantages\" + 0.021*\"second\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.144*\"english\" + 0.135*\"my\" + 0.117*\"improve\" + 0.028*\"should\" + 0.027*\"7\" + 0.026*\"month\" + 0.025*\"communication\" + 0.023*\"speaking\" + 0.016*\"mother\" + 0.014*\"am\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.123*\"non_ascii_word\" + 0.057*\"delhi\" + 0.029*\"oil\" + 0.027*\"does\" + 0.025*\".\" + 0.025*\"related\" + 0.020*\"asian\" + 0.020*\"everyone\" + 0.018*\"attractive\" + 0.016*\"east\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.062235, rho=0.134840\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #61 = documents up to #124000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #62 = documents up to #126000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #81 (0.010): 0.043*\"windows\" + 0.042*\"10\" + 0.042*\"problem\" + 0.029*\"it\" + 0.024*\"solve\" + 0.023*\"words\" + 0.019*\"memory\" + 0.019*\"does\" + 0.019*\"status\" + 0.019*\"explain\"\n",
      "INFO:gensim.models.ldamodel:topic #70 (0.010): 0.155*\"quora\" + 0.098*\"on\" + 0.065*\"questions\" + 0.046*\"question\" + 0.035*\"ask\" + 0.027*\"answer\" + 0.024*\"you\" + 0.022*\"my\" + 0.022*\"people\" + 0.020*\"effects\"\n",
      "INFO:gensim.models.ldamodel:topic #35 (0.010): 0.047*\"movies\" + 0.042*\"some\" + 0.031*\"project\" + 0.031*\"down\" + 0.029*\"iit\" + 0.026*\"jee\" + 0.023*\"good\" + 0.022*\"topics\" + 0.021*\"put\" + 0.019*\"children\"\n",
      "INFO:gensim.models.ldamodel:topic #40 (0.010): 0.064*\"live\" + 0.061*\"much\" + 0.056*\"during\" + 0.043*\"it\" + 0.041*\"cost\" + 0.034*\"does\" + 0.029*\"behind\" + 0.029*\"future\" + 0.020*\"god\" + 0.020*\"story\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.061*\"real\" + 0.047*\"america\" + 0.047*\"food\" + 0.042*\"average\" + 0.032*\"non\" + 0.023*\"child\" + 0.022*\"there\" + 0.021*\"able\" + 0.020*\"age\" + 0.019*\"marriage\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.070254, rho=0.132453\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #63 = documents up to #128000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #64 = documents up to #130000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #47 (0.010): 0.086*\"does\" + 0.085*\"mean\" + 0.053*\"it\" + 0.037*\"when\" + 0.036*\"too\" + 0.025*\"call\" + 0.018*\"line\" + 0.018*\"you\" + 0.017*\"says\" + 0.017*\"that\"\n",
      "INFO:gensim.models.ldamodel:topic #17 (0.010): 0.041*\"actually\" + 0.038*\"believe\" + 0.032*\"dark\" + 0.031*\"created\" + 0.029*\"energy\" + 0.029*\"it\" + 0.028*\"if\" + 0.025*\"that\" + 0.024*\"or\" + 0.022*\"infinite\"\n",
      "INFO:gensim.models.ldamodel:topic #42 (0.010): 0.085*\"help\" + 0.047*\"companies\" + 0.039*\"white\" + 0.034*\"songs\" + 0.033*\"self\" + 0.029*\"culture\" + 0.027*\"gain\" + 0.025*\"different\" + 0.019*\"other\" + 0.018*\"like\"\n",
      "INFO:gensim.models.ldamodel:topic #81 (0.010): 0.043*\"windows\" + 0.042*\"10\" + 0.041*\"problem\" + 0.027*\"it\" + 0.025*\"solve\" + 0.022*\"words\" + 0.020*\"status\" + 0.020*\"does\" + 0.019*\"memory\" + 0.019*\"explain\"\n",
      "INFO:gensim.models.ldamodel:topic #51 (0.010): 0.248*\"between\" + 0.185*\"difference\" + 0.063*\"movie\" + 0.026*\"review\" + 0.024*\"your\" + 0.024*\"law\" + 0.021*\"city\" + 0.020*\"brain\" + 0.019*\"kill\" + 0.013*\"three\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.068360, rho=0.130189\n",
      "INFO:gensim.models.ldamodel:-8.710 per-word bound, 418.7 perplexity estimate based on a held-out corpus of 2000 documents with 15404 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #65 = documents up to #132000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #95 (0.010): 0.100*\"work\" + 0.050*\"does\" + 0.032*\"at\" + 0.031*\"apply\" + 0.028*\"videos\" + 0.028*\"differ\" + 0.025*\"4\" + 0.025*\"bangalore\" + 0.025*\"vote\" + 0.022*\"have\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.010): 0.049*\"skills\" + 0.040*\"writing\" + 0.040*\"show\" + 0.031*\"stay\" + 0.030*\"wear\" + 0.029*\"go\" + 0.029*\"causes\" + 0.026*\"pro\" + 0.023*\"macbook\" + 0.022*\"team\"\n",
      "INFO:gensim.models.ldamodel:topic #52 (0.010): 0.049*\"career\" + 0.047*\"possible\" + 0.032*\"house\" + 0.030*\"travel\" + 0.025*\"humans\" + 0.025*\"it\" + 0.023*\"chemical\" + 0.022*\"after\" + 0.020*\"options\" + 0.019*\"opinion\"\n",
      "INFO:gensim.models.ldamodel:topic #85 (0.010): 0.114*\".\" + 0.068*\"me\" + 0.059*\"my\" + 0.034*\"he\" + 0.030*\"am\" + 0.030*\"her\" + 0.029*\"his\" + 0.028*\"not\" + 0.026*\"want\" + 0.025*\"should\"\n",
      "INFO:gensim.models.ldamodel:topic #78 (0.010): 0.146*\"money\" + 0.137*\"online\" + 0.069*\"earn\" + 0.030*\"best\" + 0.026*\"available\" + 0.024*\"from\" + 0.022*\"colleges\" + 0.020*\"way\" + 0.018*\"much\" + 0.018*\"with\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.065652, rho=0.128037\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #66 = documents up to #134000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #67 = documents up to #136000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #68 = documents up to #138000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #75 (0.010): 0.047*\"internet\" + 0.034*\"wrong\" + 0.032*\"part\" + 0.032*\"modi\" + 0.026*\"studying\" + 0.022*\"where\" + 0.022*\"sydney\" + 0.021*\"best\" + 0.021*\"final\" + 0.020*\"professional\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.169*\"your\" + 0.050*\"school\" + 0.045*\"favorite\" + 0.044*\"high\" + 0.030*\"you\" + 0.027*\"join\" + 0.017*\"easy\" + 0.017*\"understand\" + 0.016*\"life\" + 0.015*\"best\"\n",
      "INFO:gensim.models.ldamodel:topic #64 (0.010): 0.037*\"keep\" + 0.037*\"cause\" + 0.032*\"up\" + 0.025*\"meet\" + 0.025*\"get\" + 0.023*\"muslim\" + 0.020*\"does\" + 0.019*\"early\" + 0.019*\"need\" + 0.018*\"you\"\n",
      "INFO:gensim.models.ldamodel:topic #37 (0.010): 0.051*\"been\" + 0.045*\"has\" + 0.043*\"apple\" + 0.036*\"next\" + 0.028*\"often\" + 0.026*\"set\" + 0.026*\"quality\" + 0.023*\"americans\" + 0.023*\"smartphone\" + 0.020*\"penis\"\n",
      "INFO:gensim.models.ldamodel:topic #92 (0.010): 0.126*\"become\" + 0.042*\"come\" + 0.036*\"create\" + 0.030*\"jobs\" + 0.025*\"an\" + 0.022*\"from\" + 0.021*\"sleep\" + 0.021*\"does\" + 0.020*\"drive\" + 0.020*\"cell\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.065322, rho=0.125988\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #69 = documents up to #140000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #70 = documents up to #142000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #29 (0.010): 0.047*\"build\" + 0.038*\"death\" + 0.037*\"suicide\" + 0.031*\"security\" + 0.027*\"least\" + 0.025*\"dogs\" + 0.024*\"run\" + 0.022*\"people\" + 0.022*\"flat\" + 0.022*\"commit\"\n",
      "INFO:gensim.models.ldamodel:topic #72 (0.010): 0.087*\"first\" + 0.074*\"day\" + 0.073*\"things\" + 0.067*\"into\" + 0.064*\"know\" + 0.057*\"going\" + 0.050*\"their\" + 0.046*\"should\" + 0.040*\"some\" + 0.039*\"new\"\n",
      "INFO:gensim.models.ldamodel:topic #99 (0.010): 0.142*\"google\" + 0.042*\"just\" + 0.034*\"speak\" + 0.030*\"view\" + 0.025*\"on\" + 0.022*\"here\" + 0.020*\"they\" + 0.015*\"specific\" + 0.014*\"sbi\" + 0.013*\"get\"\n",
      "INFO:gensim.models.ldamodel:topic #17 (0.010): 0.039*\"actually\" + 0.037*\"believe\" + 0.033*\"energy\" + 0.032*\"if\" + 0.032*\"created\" + 0.031*\"it\" + 0.031*\"dark\" + 0.025*\"that\" + 0.022*\"or\" + 0.019*\"infinite\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.059*\"real\" + 0.051*\"america\" + 0.045*\"food\" + 0.042*\"average\" + 0.037*\"non\" + 0.027*\"child\" + 0.023*\"there\" + 0.022*\"able\" + 0.022*\"age\" + 0.020*\"picture\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.066708, rho=0.124035\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #71 = documents up to #144000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #72 = documents up to #146000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #48 (0.010): 0.059*\"government\" + 0.044*\"india\" + 0.041*\"other\" + 0.037*\"against\" + 0.037*\"each\" + 0.025*\"female\" + 0.025*\"numbers\" + 0.020*\"products\" + 0.019*\"network\" + 0.018*\"not\"\n",
      "INFO:gensim.models.ldamodel:topic #50 (0.010): 0.117*\"love\" + 0.101*\"used\" + 0.039*\"makes\" + 0.032*\"by\" + 0.029*\"on\" + 0.029*\"fall\" + 0.029*\"safety\" + 0.027*\"you\" + 0.025*\"proposed\" + 0.023*\"sentence\"\n",
      "INFO:gensim.models.ldamodel:topic #56 (0.010): 0.060*\"some\" + 0.042*\"about\" + 0.035*\"facts\" + 0.034*\"interesting\" + 0.034*\"based\" + 0.028*\"australia\" + 0.028*\"known\" + 0.023*\"model\" + 0.023*\"india\" + 0.022*\"japanese\"\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.010): 0.062*\"look\" + 0.037*\"note\" + 0.036*\"currency\" + 0.034*\"ban\" + 0.033*\"does\" + 0.030*\"my\" + 0.025*\"address\" + 0.024*\"like\" + 0.023*\"corruption\" + 0.020*\"forgot\"\n",
      "INFO:gensim.models.ldamodel:topic #31 (0.010): 0.082*\"notes\" + 0.081*\"500\" + 0.074*\"1000\" + 0.064*\"black\" + 0.056*\"rs\" + 0.048*\"indian\" + 0.039*\"will\" + 0.036*\"anyone\" + 0.034*\"rupee\" + 0.031*\"great\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.056614, rho=0.122169\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #73 = documents up to #148000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #74 = documents up to #150000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #56 (0.010): 0.061*\"some\" + 0.044*\"about\" + 0.037*\"facts\" + 0.037*\"based\" + 0.036*\"interesting\" + 0.028*\"known\" + 0.027*\"australia\" + 0.025*\"india\" + 0.024*\"model\" + 0.021*\"people\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.010): 0.045*\"skills\" + 0.040*\"writing\" + 0.039*\"go\" + 0.036*\"show\" + 0.030*\"wear\" + 0.029*\"causes\" + 0.028*\"stay\" + 0.027*\"pro\" + 0.022*\"letter\" + 0.021*\"macbook\"\n",
      "INFO:gensim.models.ldamodel:topic #58 (0.010): 0.088*\"app\" + 0.058*\"web\" + 0.045*\"java\" + 0.042*\"development\" + 0.036*\"living\" + 0.030*\"search\" + 0.029*\"android\" + 0.028*\"best\" + 0.026*\"developer\" + 0.022*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #86 (0.010): 0.080*\"books\" + 0.058*\"you\" + 0.056*\"read\" + 0.045*\"your\" + 0.044*\"best\" + 0.036*\"very\" + 0.033*\"fat\" + 0.030*\"life\" + 0.028*\"have\" + 0.021*\"theory\"\n",
      "INFO:gensim.models.ldamodel:topic #63 (0.010): 0.071*\"sex\" + 0.060*\"feel\" + 0.047*\"it\" + 0.039*\"earth\" + 0.039*\"does\" + 0.038*\"like\" + 0.037*\"you\" + 0.029*\"have\" + 0.027*\"life\" + 0.025*\"purpose\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.062669, rho=0.120386\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #75 = documents up to #152000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #76 = documents up to #154000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #90 (0.010): 0.096*\"2\" + 0.081*\"+\" + 0.076*\"c\" + 0.061*\"home\" + 0.034*\"foreign\" + 0.026*\".\" + 0.023*\"n\" + 0.020*\"d\" + 0.020*\"good\" + 0.019*\"bring\"\n",
      "INFO:gensim.models.ldamodel:topic #10 (0.010): 0.098*\"phone\" + 0.091*\"buy\" + 0.045*\"under\" + 0.041*\"best\" + 0.030*\"which\" + 0.024*\"benefits\" + 0.021*\"should\" + 0.020*\"problems\" + 0.020*\"6\" + 0.017*\"iq\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.152*\"english\" + 0.144*\"my\" + 0.113*\"improve\" + 0.033*\"7\" + 0.028*\"month\" + 0.026*\"communication\" + 0.023*\"speaking\" + 0.022*\"should\" + 0.016*\"mother\" + 0.014*\"am\"\n",
      "INFO:gensim.models.ldamodel:topic #67 (0.010): 0.061*\"prepare\" + 0.042*\"bank\" + 0.039*\"water\" + 0.031*\"mechanical\" + 0.029*\"cat\" + 0.028*\"education\" + 0.026*\"england\" + 0.022*\"should\" + 0.021*\"from\" + 0.021*\"invest\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.090*\"over\" + 0.060*\"bing\" + 0.037*\"class\" + 0.032*\"before\" + 0.031*\"short\" + 0.030*\"correct\" + 0.025*\"because\" + 0.024*\"structure\" + 0.023*\"red\" + 0.018*\"get\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.068702, rho=0.118678\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #77 = documents up to #156000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #78 = documents up to #158000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #75 (0.010): 0.048*\"internet\" + 0.039*\"part\" + 0.035*\"wrong\" + 0.034*\"modi\" + 0.028*\"studying\" + 0.025*\"sydney\" + 0.024*\"where\" + 0.024*\"best\" + 0.022*\"doing\" + 0.021*\"final\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.212*\"your\" + 0.050*\"school\" + 0.046*\"high\" + 0.043*\"you\" + 0.040*\"favorite\" + 0.024*\"life\" + 0.024*\"join\" + 0.015*\"best\" + 0.014*\"easy\" + 0.014*\"understand\"\n",
      "INFO:gensim.models.ldamodel:topic #86 (0.010): 0.079*\"books\" + 0.056*\"read\" + 0.055*\"you\" + 0.046*\"best\" + 0.044*\"your\" + 0.039*\"very\" + 0.034*\"fat\" + 0.030*\"life\" + 0.027*\"have\" + 0.021*\"which\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.010): 0.038*\"someone\" + 0.037*\"you\" + 0.037*\"not\" + 0.034*\"on\" + 0.031*\"but\" + 0.030*\"when\" + 0.030*\"my\" + 0.028*\"it\" + 0.026*\"they\" + 0.026*\"snapchat\"\n",
      "INFO:gensim.models.ldamodel:topic #97 (0.010): 0.123*\"more\" + 0.068*\"than\" + 0.066*\"study\" + 0.053*\"give\" + 0.021*\"you\" + 0.020*\"exams\" + 0.019*\"germany\" + 0.017*\"please\" + 0.017*\"or\" + 0.017*\"/\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.070013, rho=0.117041\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #79 = documents up to #160000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #80 = documents up to #162000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #50 (0.010): 0.129*\"love\" + 0.103*\"used\" + 0.041*\"makes\" + 0.034*\"by\" + 0.031*\"on\" + 0.030*\"fall\" + 0.029*\"safety\" + 0.028*\"proposed\" + 0.027*\"you\" + 0.024*\"handling\"\n",
      "INFO:gensim.models.ldamodel:topic #83 (0.010): 0.050*\"experience\" + 0.039*\"sites\" + 0.035*\"preparation\" + 0.033*\"level\" + 0.025*\"photos\" + 0.024*\"dating\" + 0.023*\"am\" + 0.022*\".\" + 0.021*\"it\" + 0.019*\"planning\"\n",
      "INFO:gensim.models.ldamodel:topic #55 (0.010): 0.075*\"number\" + 0.047*\"tech\" + 0.044*\"list\" + 0.036*\"remove\" + 0.032*\"m\" + 0.031*\"from\" + 0.028*\"exactly\" + 0.020*\"after\" + 0.020*\"does\" + 0.018*\"father\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.161*\"english\" + 0.144*\"my\" + 0.110*\"improve\" + 0.035*\"7\" + 0.031*\"month\" + 0.024*\"communication\" + 0.022*\"should\" + 0.022*\"speaking\" + 0.017*\"mother\" + 0.012*\"am\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.091*\"over\" + 0.063*\"bing\" + 0.036*\"before\" + 0.035*\"class\" + 0.033*\"short\" + 0.029*\"correct\" + 0.026*\"red\" + 0.023*\"because\" + 0.022*\"structure\" + 0.018*\"get\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.064486, rho=0.115470\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #81 = documents up to #164000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #82 = documents up to #166000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #46 (0.010): 0.046*\"air\" + 0.045*\"apps\" + 0.038*\"family\" + 0.038*\"reduce\" + 0.033*\"uber\" + 0.027*\"or\" + 0.023*\"special\" + 0.022*\"my\" + 0.016*\"an\" + 0.015*\"devices\"\n",
      "INFO:gensim.models.ldamodel:topic #73 (0.010): 0.071*\"safe\" + 0.053*\"police\" + 0.053*\"service\" + 0.051*\"hotel\" + 0.031*\"be\" + 0.029*\"without\" + 0.026*\"would\" + 0.023*\"moral\" + 0.022*\"unmarried\" + 0.021*\"screen\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.010): 0.155*\"find\" + 0.096*\"where\" + 0.044*\"support\" + 0.030*\"times\" + 0.018*\"religion\" + 0.018*\"number\" + 0.017*\"my\" + 0.017*\"quickly\" + 0.017*\"sim\" + 0.016*\"get\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.010): 0.050*\"go\" + 0.043*\"skills\" + 0.041*\"writing\" + 0.038*\"show\" + 0.032*\"causes\" + 0.031*\"wear\" + 0.029*\"stay\" + 0.026*\"pro\" + 0.024*\"letter\" + 0.020*\"required\"\n",
      "INFO:gensim.models.ldamodel:topic #68 (0.010): 0.098*\"language\" + 0.082*\"programming\" + 0.079*\"website\" + 0.039*\"best\" + 0.034*\"open\" + 0.033*\"learn\" + 0.030*\"hack\" + 0.026*\"cons\" + 0.026*\"pros\" + 0.024*\"low\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.068368, rho=0.113961\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #83 = documents up to #168000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #84 = documents up to #170000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #30 (0.010): 0.258*\"make\" + 0.039*\"money\" + 0.034*\"happened\" + 0.033*\"current\" + 0.029*\"degree\" + 0.025*\"full\" + 0.023*\"does\" + 0.021*\"obama\" + 0.019*\"master\" + 0.017*\"you\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.071*\"get\" + 0.070*\"ways\" + 0.053*\"rid\" + 0.035*\"on\" + 0.032*\"some\" + 0.031*\"face\" + 0.026*\"daily\" + 0.026*\"best\" + 0.024*\"my\" + 0.023*\"impact\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.137*\"non_ascii_word\" + 0.062*\"delhi\" + 0.029*\"related\" + 0.029*\"oil\" + 0.028*\"everyone\" + 0.023*\"does\" + 0.020*\".\" + 0.017*\"asian\" + 0.016*\"attractive\" + 0.016*\"developed\"\n",
      "INFO:gensim.models.ldamodel:topic #68 (0.010): 0.095*\"language\" + 0.082*\"programming\" + 0.080*\"website\" + 0.039*\"best\" + 0.034*\"open\" + 0.031*\"learn\" + 0.031*\"hack\" + 0.028*\"cons\" + 0.027*\"pros\" + 0.026*\"low\"\n",
      "INFO:gensim.models.ldamodel:topic #78 (0.010): 0.155*\"money\" + 0.147*\"online\" + 0.071*\"earn\" + 0.029*\"available\" + 0.025*\"best\" + 0.025*\"from\" + 0.021*\"colleges\" + 0.020*\"way\" + 0.018*\"much\" + 0.017*\"break\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.069253, rho=0.112509\n",
      "INFO:gensim.models.ldamodel:-8.569 per-word bound, 379.7 perplexity estimate based on a held-out corpus of 2000 documents with 15547 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #85 = documents up to #172000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #48 (0.010): 0.053*\"government\" + 0.053*\"other\" + 0.044*\"india\" + 0.041*\"against\" + 0.038*\"each\" + 0.026*\"numbers\" + 0.022*\"female\" + 0.022*\"products\" + 0.021*\"network\" + 0.020*\"natural\"\n",
      "INFO:gensim.models.ldamodel:topic #40 (0.010): 0.110*\"much\" + 0.062*\"live\" + 0.057*\"during\" + 0.050*\"it\" + 0.040*\"cost\" + 0.038*\"does\" + 0.035*\"future\" + 0.029*\"behind\" + 0.020*\"small\" + 0.019*\"story\"\n",
      "INFO:gensim.models.ldamodel:topic #53 (0.010): 0.136*\"system\" + 0.045*\"biggest\" + 0.041*\"operating\" + 0.035*\"similar\" + 0.031*\"personal\" + 0.029*\"fake\" + 0.028*\"pain\" + 0.023*\"device\" + 0.017*\"buying\" + 0.015*\"location\"\n",
      "INFO:gensim.models.ldamodel:topic #98 (0.010): 0.073*\"its\" + 0.054*\"download\" + 0.040*\"less\" + 0.040*\"site\" + 0.034*\"form\" + 0.027*\"best\" + 0.025*\"develop\" + 0.024*\"office\" + 0.018*\"charge\" + 0.016*\"procedure\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.010): 0.048*\"someone\" + 0.039*\"you\" + 0.038*\"not\" + 0.034*\"on\" + 0.034*\"but\" + 0.032*\"when\" + 0.029*\"my\" + 0.028*\"it\" + 0.027*\"they\" + 0.025*\"snapchat\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.065192, rho=0.111111\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #86 = documents up to #174000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #87 = documents up to #176000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #88 = documents up to #178000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #22 (0.010): 0.080*\"instagram\" + 0.078*\"see\" + 0.054*\"on\" + 0.051*\"hair\" + 0.043*\"youtube\" + 0.034*\"my\" + 0.023*\"who\" + 0.022*\"beautiful\" + 0.019*\"you\" + 0.016*\"does\"\n",
      "INFO:gensim.models.ldamodel:topic #69 (0.010): 0.237*\"which\" + 0.208*\"best\" + 0.042*\"country\" + 0.037*\"india\" + 0.032*\"laptop\" + 0.026*\"test\" + 0.026*\"marketing\" + 0.025*\"market\" + 0.023*\"course\" + 0.021*\"digital\"\n",
      "INFO:gensim.models.ldamodel:topic #72 (0.010): 0.090*\"first\" + 0.079*\"day\" + 0.075*\"things\" + 0.072*\"know\" + 0.066*\"into\" + 0.063*\"their\" + 0.054*\"going\" + 0.049*\"should\" + 0.042*\"some\" + 0.038*\"new\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.243*\"your\" + 0.056*\"you\" + 0.052*\"school\" + 0.047*\"high\" + 0.038*\"favorite\" + 0.026*\"life\" + 0.022*\"join\" + 0.015*\"best\" + 0.013*\"easy\" + 0.012*\"understand\"\n",
      "INFO:gensim.models.ldamodel:topic #12 (0.010): 0.268*\".\" + 0.038*\"b\" + 0.037*\"girls\" + 0.036*\"u\" + 0.033*\"answers\" + 0.019*\"rate\" + 0.018*\"guys\" + 0.018*\"japan\" + 0.016*\"30\" + 0.014*\"not\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.070971, rho=0.109764\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #89 = documents up to #180000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #90 = documents up to #182000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #79 (0.010): 0.058*\"kind\" + 0.050*\"overcome\" + 0.030*\"fear\" + 0.027*\"expected\" + 0.027*\"cut\" + 0.024*\"beginner\" + 0.020*\"2016\" + 0.019*\"cutoff\" + 0.017*\"designer\" + 0.015*\"best\"\n",
      "INFO:gensim.models.ldamodel:topic #31 (0.010): 0.079*\"notes\" + 0.079*\"1000\" + 0.079*\"500\" + 0.064*\"black\" + 0.059*\"rs\" + 0.056*\"indian\" + 0.043*\"will\" + 0.040*\"anyone\" + 0.031*\"rupee\" + 0.030*\"money\"\n",
      "INFO:gensim.models.ldamodel:topic #66 (0.010): 0.102*\"ever\" + 0.054*\"done\" + 0.046*\"best\" + 0.041*\"have\" + 0.039*\"space\" + 0.037*\"you\" + 0.028*\"training\" + 0.027*\"institute\" + 0.023*\"coaching\" + 0.022*\"which\"\n",
      "INFO:gensim.models.ldamodel:topic #41 (0.010): 0.059*\"human\" + 0.054*\"state\" + 0.049*\"video\" + 0.042*\"considered\" + 0.037*\"terms\" + 0.033*\"point\" + 0.029*\"worst\" + 0.026*\"at\" + 0.025*\"matter\" + 0.023*\"majors\"\n",
      "INFO:gensim.models.ldamodel:topic #69 (0.010): 0.245*\"which\" + 0.210*\"best\" + 0.041*\"country\" + 0.036*\"india\" + 0.031*\"laptop\" + 0.028*\"marketing\" + 0.025*\"test\" + 0.024*\"course\" + 0.023*\"market\" + 0.020*\"digital\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.065110, rho=0.108465\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #91 = documents up to #184000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #92 = documents up to #186000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #38 (0.010): 0.059*\"play\" + 0.052*\"looking\" + 0.049*\"universities\" + 0.042*\"they\" + 0.041*\"from\" + 0.041*\"never\" + 0.039*\"does\" + 0.034*\"new\" + 0.025*\"recruit\" + 0.024*\"majors\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.095*\"over\" + 0.060*\"bing\" + 0.057*\"before\" + 0.034*\"class\" + 0.030*\"correct\" + 0.029*\"red\" + 0.028*\"short\" + 0.024*\"because\" + 0.021*\"get\" + 0.020*\"structure\"\n",
      "INFO:gensim.models.ldamodel:topic #35 (0.010): 0.058*\"movies\" + 0.044*\"some\" + 0.033*\"down\" + 0.029*\"jee\" + 0.029*\"iit\" + 0.028*\"put\" + 0.028*\"project\" + 0.027*\"topics\" + 0.024*\"russia\" + 0.023*\"effect\"\n",
      "INFO:gensim.models.ldamodel:topic #55 (0.010): 0.073*\"number\" + 0.049*\"list\" + 0.048*\"tech\" + 0.040*\"remove\" + 0.034*\"exactly\" + 0.031*\"from\" + 0.029*\"m\" + 0.020*\"does\" + 0.018*\"after\" + 0.017*\"acid\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.010): 0.062*\"go\" + 0.046*\"skills\" + 0.040*\"writing\" + 0.037*\"show\" + 0.032*\"wear\" + 0.031*\"causes\" + 0.028*\"stay\" + 0.027*\"pro\" + 0.025*\"required\" + 0.021*\"team\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.074728, rho=0.107211\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #93 = documents up to #188000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #94 = documents up to #190000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.010): 0.139*\"would\" + 0.097*\"if\" + 0.056*\"happen\" + 0.037*\"be\" + 0.036*\"car\" + 0.031*\"will\" + 0.025*\"light\" + 0.020*\"speed\" + 0.019*\"design\" + 0.015*\"faster\"\n",
      "INFO:gensim.models.ldamodel:topic #37 (0.010): 0.071*\"has\" + 0.061*\"been\" + 0.042*\"next\" + 0.038*\"apple\" + 0.028*\"size\" + 0.025*\"set\" + 0.024*\"often\" + 0.023*\"penis\" + 0.023*\"americans\" + 0.021*\"quality\"\n",
      "INFO:gensim.models.ldamodel:topic #32 (0.010): 0.122*\"really\" + 0.062*\"exist\" + 0.041*\"does\" + 0.039*\"hate\" + 0.024*\"once\" + 0.024*\"there\" + 0.019*\"people\" + 0.018*\"evidence\" + 0.018*\"you\" + 0.018*\"amount\"\n",
      "INFO:gensim.models.ldamodel:topic #49 (0.010): 0.083*\"computer\" + 0.072*\"science\" + 0.065*\"data\" + 0.043*\"history\" + 0.029*\"canada\" + 0.027*\"both\" + 0.025*\"others\" + 0.018*\"from\" + 0.017*\"difficult\" + 0.015*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic #39 (0.010): 0.094*\"top\" + 0.062*\"own\" + 0.038*\"normal\" + 0.036*\"green\" + 0.035*\"my\" + 0.034*\"on\" + 0.028*\"bollywood\" + 0.024*\"page\" + 0.024*\"who\" + 0.020*\"viewed\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.069661, rho=0.106000\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #95 = documents up to #192000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #96 = documents up to #194000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #56 (0.010): 0.058*\"some\" + 0.046*\"about\" + 0.045*\"interesting\" + 0.040*\"facts\" + 0.038*\"based\" + 0.037*\"known\" + 0.025*\"japanese\" + 0.025*\"australia\" + 0.022*\"india\" + 0.020*\"model\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.061*\"real\" + 0.053*\"america\" + 0.046*\"food\" + 0.046*\"average\" + 0.043*\"non\" + 0.037*\"age\" + 0.023*\"there\" + 0.023*\"child\" + 0.022*\"able\" + 0.021*\"100\"\n",
      "INFO:gensim.models.ldamodel:topic #78 (0.010): 0.164*\"money\" + 0.152*\"online\" + 0.071*\"earn\" + 0.032*\"available\" + 0.026*\"best\" + 0.026*\"from\" + 0.023*\"colleges\" + 0.022*\"way\" + 0.017*\"break\" + 0.015*\"save\"\n",
      "INFO:gensim.models.ldamodel:topic #95 (0.010): 0.146*\"work\" + 0.062*\"does\" + 0.034*\"at\" + 0.032*\"apply\" + 0.026*\"differ\" + 0.025*\"vote\" + 0.025*\"videos\" + 0.025*\"4\" + 0.023*\"bangalore\" + 0.021*\"have\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.100*\"over\" + 0.060*\"bing\" + 0.058*\"before\" + 0.035*\"class\" + 0.030*\"red\" + 0.029*\"correct\" + 0.028*\"short\" + 0.022*\"because\" + 0.021*\"get\" + 0.019*\"structure\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.071005, rho=0.104828\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #97 = documents up to #196000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #98 = documents up to #198000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #31 (0.010): 0.082*\"notes\" + 0.080*\"1000\" + 0.076*\"500\" + 0.064*\"black\" + 0.063*\"indian\" + 0.056*\"rs\" + 0.045*\"will\" + 0.041*\"anyone\" + 0.034*\"rupee\" + 0.030*\"great\"\n",
      "INFO:gensim.models.ldamodel:topic #53 (0.010): 0.137*\"system\" + 0.049*\"biggest\" + 0.041*\"operating\" + 0.032*\"similar\" + 0.031*\"personal\" + 0.026*\"fake\" + 0.026*\"pain\" + 0.025*\"device\" + 0.020*\"location\" + 0.019*\"buying\"\n",
      "INFO:gensim.models.ldamodel:topic #24 (0.010): 0.198*\")\" + 0.196*\"(\" + 0.069*\"better\" + 0.061*\"or\" + 0.053*\":\" + 0.039*\"which\" + 0.036*\"long\" + 0.021*\"quoted_item\" + 0.017*\"mba\" + 0.013*\"main\"\n",
      "INFO:gensim.models.ldamodel:topic #49 (0.010): 0.086*\"computer\" + 0.073*\"science\" + 0.063*\"data\" + 0.045*\"history\" + 0.028*\"canada\" + 0.027*\"both\" + 0.026*\"others\" + 0.021*\"from\" + 0.017*\"difficult\" + 0.016*\"laws\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.010): 0.145*\"would\" + 0.099*\"if\" + 0.055*\"happen\" + 0.040*\"be\" + 0.037*\"car\" + 0.030*\"will\" + 0.024*\"light\" + 0.020*\"speed\" + 0.019*\"design\" + 0.016*\"then\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.067115, rho=0.103695\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #99 = documents up to #200000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #100 = documents up to #202000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #33 (0.010): 0.053*\"2017\" + 0.052*\"power\" + 0.045*\"music\" + 0.037*\"management\" + 0.035*\"move\" + 0.031*\"new\" + 0.029*\"you\" + 0.029*\"your\" + 0.028*\"field\" + 0.028*\"year\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.164*\"english\" + 0.156*\"my\" + 0.119*\"improve\" + 0.041*\"7\" + 0.034*\"month\" + 0.025*\"should\" + 0.025*\"communication\" + 0.023*\"speaking\" + 0.017*\"mother\" + 0.012*\"material\"\n",
      "INFO:gensim.models.ldamodel:topic #81 (0.010): 0.052*\"10\" + 0.040*\"windows\" + 0.036*\"problem\" + 0.028*\"words\" + 0.027*\"it\" + 0.026*\"solve\" + 0.021*\"explain\" + 0.021*\"memory\" + 0.020*\"does\" + 0.019*\"status\"\n",
      "INFO:gensim.models.ldamodel:topic #37 (0.010): 0.078*\"has\" + 0.060*\"been\" + 0.046*\"next\" + 0.037*\"apple\" + 0.031*\"size\" + 0.027*\"set\" + 0.024*\"often\" + 0.024*\"americans\" + 0.023*\"quality\" + 0.021*\"penis\"\n",
      "INFO:gensim.models.ldamodel:topic #13 (0.010): 0.048*\"control\" + 0.036*\"song\" + 0.035*\"solar\" + 0.035*\"california\" + 0.033*\"ca\" + 0.031*\"research\" + 0.030*\"provider\" + 0.028*\"installation\" + 0.026*\"good\" + 0.026*\"panel\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.070794, rho=0.102598\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #101 = documents up to #204000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #102 = documents up to #206000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #15 (0.010): 0.059*\"women\" + 0.050*\"men\" + 0.049*\"we\" + 0.048*\"our\" + 0.048*\"made\" + 0.046*\"china\" + 0.046*\"say\" + 0.041*\"now\" + 0.036*\"happens\" + 0.034*\"right\"\n",
      "INFO:gensim.models.ldamodel:topic #61 (0.010): 0.095*\"thing\" + 0.076*\"you\" + 0.033*\"most\" + 0.033*\"demonetization\" + 0.032*\"advantages\" + 0.029*\"that\" + 0.029*\"have\" + 0.028*\"given\" + 0.025*\"disadvantages\" + 0.024*\"calculate\"\n",
      "INFO:gensim.models.ldamodel:topic #33 (0.010): 0.053*\"power\" + 0.052*\"2017\" + 0.045*\"music\" + 0.039*\"management\" + 0.035*\"move\" + 0.031*\"new\" + 0.029*\"you\" + 0.027*\"your\" + 0.026*\"compared\" + 0.026*\"field\"\n",
      "INFO:gensim.models.ldamodel:topic #66 (0.010): 0.115*\"ever\" + 0.056*\"done\" + 0.054*\"best\" + 0.049*\"have\" + 0.042*\"you\" + 0.037*\"space\" + 0.026*\"coaching\" + 0.025*\"training\" + 0.025*\"institute\" + 0.021*\"some\"\n",
      "INFO:gensim.models.ldamodel:topic #21 (0.010): 0.065*\"/\" + 0.065*\"math\" + 0.056*\"[\" + 0.056*\"]\" + 0.055*\"exam\" + 0.037*\"games\" + 0.037*\"\\\" + 0.036*\"1\" + 0.036*\"x\" + 0.027*\"=\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.067239, rho=0.101535\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #103 = documents up to #208000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #104 = documents up to #210000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #79 (0.010): 0.061*\"kind\" + 0.046*\"overcome\" + 0.028*\"cut\" + 0.027*\"fear\" + 0.026*\"expected\" + 0.024*\"beginner\" + 0.023*\"2016\" + 0.019*\"cutoff\" + 0.018*\"off\" + 0.016*\"designer\"\n",
      "INFO:gensim.models.ldamodel:topic #36 (0.010): 0.094*\"year\" + 0.086*\"old\" + 0.064*\"it\" + 0.055*\"true\" + 0.037*\"salary\" + 0.035*\"worth\" + 0.029*\"that\" + 0.026*\"fast\" + 0.023*\"an\" + 0.023*\"must\"\n",
      "INFO:gensim.models.ldamodel:topic #91 (0.010): 0.061*\"even\" + 0.057*\"days\" + 0.054*\"with\" + 0.041*\"deal\" + 0.038*\"period\" + 0.033*\"pregnant\" + 0.027*\"get\" + 0.026*\"my\" + 0.021*\"you\" + 0.020*\"depression\"\n",
      "INFO:gensim.models.ldamodel:topic #52 (0.010): 0.108*\"possible\" + 0.059*\"it\" + 0.055*\"career\" + 0.036*\"travel\" + 0.030*\"humans\" + 0.030*\"house\" + 0.026*\"options\" + 0.021*\"after\" + 0.021*\"animals\" + 0.020*\"check\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.010): 0.077*\"someone\" + 0.044*\"but\" + 0.044*\"you\" + 0.040*\"not\" + 0.039*\"them\" + 0.034*\"when\" + 0.034*\"on\" + 0.029*\"if\" + 0.028*\"they\" + 0.026*\"my\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.071300, rho=0.100504\n",
      "INFO:gensim.models.ldamodel:-8.528 per-word bound, 369.3 perplexity estimate based on a held-out corpus of 2000 documents with 14992 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #105 = documents up to #212000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #90 (0.010): 0.117*\"2\" + 0.095*\"+\" + 0.090*\"c\" + 0.060*\"home\" + 0.034*\"foreign\" + 0.024*\"d\" + 0.022*\"n\" + 0.020*\"at\" + 0.019*\"bring\" + 0.018*\"good\"\n",
      "INFO:gensim.models.ldamodel:topic #58 (0.010): 0.090*\"app\" + 0.061*\"web\" + 0.050*\"java\" + 0.041*\"living\" + 0.040*\"development\" + 0.037*\"search\" + 0.028*\"best\" + 0.026*\"developer\" + 0.025*\"android\" + 0.021*\"net\"\n",
      "INFO:gensim.models.ldamodel:topic #97 (0.010): 0.144*\"more\" + 0.099*\"than\" + 0.063*\"study\" + 0.057*\"give\" + 0.020*\"or\" + 0.019*\"you\" + 0.018*\"2015\" + 0.018*\"exams\" + 0.017*\"germany\" + 0.017*\"/\"\n",
      "INFO:gensim.models.ldamodel:topic #59 (0.010): 0.089*\"still\" + 0.082*\"were\" + 0.037*\"amazon\" + 0.034*\"send\" + 0.028*\"on\" + 0.024*\"you\" + 0.019*\"was\" + 0.018*\"if\" + 0.017*\"did\" + 0.017*\"touch\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.010): 0.154*\"where\" + 0.148*\"find\" + 0.038*\"support\" + 0.025*\"get\" + 0.021*\"my\" + 0.021*\"sim\" + 0.020*\"times\" + 0.018*\"religion\" + 0.016*\"quickly\" + 0.016*\"number\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.069621, rho=0.099504\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #106 = documents up to #214000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #107 = documents up to #216000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #108 = documents up to #218000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #54 (0.010): 0.105*\"weight\" + 0.098*\"lose\" + 0.098*\"being\" + 0.048*\"man\" + 0.037*\"die\" + 0.034*\"websites\" + 0.027*\"you\" + 0.027*\"best\" + 0.025*\"way\" + 0.020*\"easiest\"\n",
      "INFO:gensim.models.ldamodel:topic #53 (0.010): 0.150*\"system\" + 0.047*\"biggest\" + 0.042*\"operating\" + 0.036*\"similar\" + 0.031*\"personal\" + 0.026*\"device\" + 0.024*\"pain\" + 0.024*\"fake\" + 0.018*\"buying\" + 0.017*\"recent\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.095*\"over\" + 0.075*\"before\" + 0.062*\"bing\" + 0.034*\"class\" + 0.030*\"correct\" + 0.029*\"short\" + 0.029*\"red\" + 0.023*\"structure\" + 0.022*\"because\" + 0.020*\"get\"\n",
      "INFO:gensim.models.ldamodel:topic #79 (0.010): 0.060*\"kind\" + 0.050*\"overcome\" + 0.028*\"fear\" + 0.028*\"cut\" + 0.025*\"expected\" + 0.024*\"beginner\" + 0.023*\"2016\" + 0.018*\"cutoff\" + 0.016*\"designer\" + 0.016*\"off\"\n",
      "INFO:gensim.models.ldamodel:topic #72 (0.010): 0.092*\"first\" + 0.079*\"day\" + 0.079*\"their\" + 0.078*\"things\" + 0.067*\"know\" + 0.066*\"into\" + 0.052*\"going\" + 0.046*\"should\" + 0.041*\"some\" + 0.039*\"new\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.070682, rho=0.098533\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #109 = documents up to #220000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #110 = documents up to #222000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.086*\"ways\" + 0.070*\"get\" + 0.050*\"rid\" + 0.038*\"some\" + 0.037*\"face\" + 0.031*\"best\" + 0.029*\"on\" + 0.024*\"my\" + 0.024*\"daily\" + 0.023*\"impact\"\n",
      "INFO:gensim.models.ldamodel:topic #79 (0.010): 0.058*\"kind\" + 0.051*\"overcome\" + 0.028*\"cut\" + 0.027*\"beginner\" + 0.027*\"fear\" + 0.025*\"expected\" + 0.022*\"2016\" + 0.017*\"cutoff\" + 0.016*\"designer\" + 0.016*\"off\"\n",
      "INFO:gensim.models.ldamodel:topic #98 (0.010): 0.085*\"its\" + 0.055*\"download\" + 0.043*\"site\" + 0.036*\"less\" + 0.034*\"form\" + 0.026*\"office\" + 0.024*\"develop\" + 0.024*\"best\" + 0.019*\"charge\" + 0.017*\"born\"\n",
      "INFO:gensim.models.ldamodel:topic #73 (0.010): 0.078*\"safe\" + 0.057*\"service\" + 0.050*\"police\" + 0.044*\"hotel\" + 0.031*\"be\" + 0.031*\"without\" + 0.028*\"screen\" + 0.023*\"would\" + 0.021*\"couples\" + 0.021*\"moral\"\n",
      "INFO:gensim.models.ldamodel:topic #42 (0.010): 0.081*\"help\" + 0.081*\"different\" + 0.062*\"companies\" + 0.042*\"culture\" + 0.041*\"white\" + 0.038*\"self\" + 0.036*\"songs\" + 0.031*\"gain\" + 0.022*\"some\" + 0.022*\"like\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.070167, rho=0.097590\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #111 = documents up to #224000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #112 = documents up to #226000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #92 (0.010): 0.133*\"become\" + 0.049*\"come\" + 0.034*\"create\" + 0.032*\"jobs\" + 0.030*\"an\" + 0.029*\"from\" + 0.027*\"sleep\" + 0.026*\"drive\" + 0.022*\"does\" + 0.019*\"did\"\n",
      "INFO:gensim.models.ldamodel:topic #74 (0.010): 0.040*\"does\" + 0.040*\"industry\" + 0.037*\"moon\" + 0.036*\"star\" + 0.031*\"option\" + 0.030*\"sun\" + 0.025*\"wars\" + 0.024*\"sound\" + 0.023*\"gravity\" + 0.019*\"stand\"\n",
      "INFO:gensim.models.ldamodel:topic #87 (0.010): 0.059*\"parents\" + 0.051*\"date\" + 0.030*\"knowledge\" + 0.025*\"land\" + 0.021*\"kids\" + 0.021*\"with\" + 0.016*\"my\" + 0.016*\"you\" + 0.015*\"their\" + 0.015*\"performance\"\n",
      "INFO:gensim.models.ldamodel:topic #31 (0.010): 0.083*\"1000\" + 0.081*\"notes\" + 0.079*\"500\" + 0.072*\"indian\" + 0.061*\"black\" + 0.057*\"rs\" + 0.044*\"anyone\" + 0.043*\"will\" + 0.032*\"rupee\" + 0.028*\"great\"\n",
      "INFO:gensim.models.ldamodel:topic #59 (0.010): 0.096*\"were\" + 0.091*\"still\" + 0.035*\"amazon\" + 0.031*\"send\" + 0.027*\"on\" + 0.027*\"you\" + 0.019*\"who\" + 0.018*\"touch\" + 0.018*\"did\" + 0.017*\"not\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.066011, rho=0.096674\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #113 = documents up to #228000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #114 = documents up to #230000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #48 (0.010): 0.092*\"other\" + 0.057*\"government\" + 0.044*\"india\" + 0.039*\"against\" + 0.039*\"each\" + 0.022*\"female\" + 0.021*\"network\" + 0.021*\"products\" + 0.021*\"natural\" + 0.020*\"text\"\n",
      "INFO:gensim.models.ldamodel:topic #10 (0.010): 0.133*\"phone\" + 0.090*\"buy\" + 0.041*\"under\" + 0.028*\"benefits\" + 0.028*\"best\" + 0.025*\"should\" + 0.025*\"6\" + 0.023*\"problems\" + 0.020*\"iq\" + 0.020*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.092*\"over\" + 0.079*\"before\" + 0.064*\"bing\" + 0.034*\"class\" + 0.033*\"short\" + 0.030*\"red\" + 0.029*\"correct\" + 0.023*\"because\" + 0.022*\"structure\" + 0.020*\"get\"\n",
      "INFO:gensim.models.ldamodel:topic #44 (0.010): 0.175*\"you\" + 0.168*\"about\" + 0.109*\"think\" + 0.048*\"stop\" + 0.037*\"people\" + 0.021*\"know\" + 0.019*\"if\" + 0.018*\"that\" + 0.018*\"yourself\" + 0.017*\"indians\"\n",
      "INFO:gensim.models.ldamodel:topic #24 (0.010): 0.203*\")\" + 0.202*\"(\" + 0.068*\"better\" + 0.064*\"or\" + 0.062*\":\" + 0.037*\"which\" + 0.035*\"long\" + 0.020*\"quoted_item\" + 0.016*\"mba\" + 0.015*\"main\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.070784, rho=0.095783\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #115 = documents up to #232000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #116 = documents up to #234000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #62 (0.010): 0.091*\"engineering\" + 0.050*\"student\" + 0.049*\"getting\" + 0.049*\"university\" + 0.034*\"an\" + 0.031*\"students\" + 0.029*\"civil\" + 0.027*\".\" + 0.026*\"post\" + 0.023*\"etc\"\n",
      "INFO:gensim.models.ldamodel:topic #44 (0.010): 0.174*\"you\" + 0.168*\"about\" + 0.110*\"think\" + 0.048*\"stop\" + 0.038*\"people\" + 0.022*\"know\" + 0.019*\"if\" + 0.018*\"that\" + 0.018*\"last\" + 0.018*\"yourself\"\n",
      "INFO:gensim.models.ldamodel:topic #77 (0.010): 0.109*\"change\" + 0.051*\"around\" + 0.043*\"popular\" + 0.031*\"views\" + 0.024*\"decision\" + 0.023*\"news\" + 0.023*\"it\" + 0.022*\"let\" + 0.022*\"personality\" + 0.021*\"!\"\n",
      "INFO:gensim.models.ldamodel:topic #43 (0.010): 0.127*\"job\" + 0.067*\"through\" + 0.058*\"interview\" + 0.055*\"learning\" + 0.044*\"some\" + 0.043*\"tips\" + 0.043*\"process\" + 0.042*\"making\" + 0.041*\"affect\" + 0.040*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.010): 0.092*\"someone\" + 0.052*\"but\" + 0.050*\"them\" + 0.048*\"you\" + 0.041*\"not\" + 0.033*\"on\" + 0.031*\"if\" + 0.031*\"when\" + 0.028*\"they\" + 0.025*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.070068, rho=0.094916\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #117 = documents up to #236000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #118 = documents up to #238000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #85 (0.010): 0.106*\".\" + 0.071*\"me\" + 0.064*\"my\" + 0.052*\"am\" + 0.038*\"want\" + 0.033*\"he\" + 0.031*\"not\" + 0.031*\"his\" + 0.029*\"her\" + 0.028*\"should\"\n",
      "INFO:gensim.models.ldamodel:topic #98 (0.010): 0.091*\"its\" + 0.055*\"download\" + 0.044*\"site\" + 0.037*\"less\" + 0.034*\"form\" + 0.026*\"office\" + 0.022*\"develop\" + 0.021*\"best\" + 0.019*\"charge\" + 0.018*\"*\"\n",
      "INFO:gensim.models.ldamodel:topic #54 (0.010): 0.107*\"weight\" + 0.099*\"lose\" + 0.097*\"being\" + 0.052*\"man\" + 0.038*\"websites\" + 0.038*\"die\" + 0.026*\"you\" + 0.025*\"way\" + 0.024*\"best\" + 0.020*\"easiest\"\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.010): 0.081*\"look\" + 0.050*\"note\" + 0.048*\"ban\" + 0.042*\"does\" + 0.036*\"currency\" + 0.032*\"like\" + 0.027*\"address\" + 0.026*\"corruption\" + 0.020*\"my\" + 0.019*\"hp\"\n",
      "INFO:gensim.models.ldamodel:topic #81 (0.010): 0.056*\"10\" + 0.048*\"windows\" + 0.040*\"problem\" + 0.026*\"solve\" + 0.025*\"words\" + 0.025*\"it\" + 0.022*\"memory\" + 0.021*\"following\" + 0.020*\"explain\" + 0.018*\"status\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.072128, rho=0.094072\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #119 = documents up to #240000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #120 = documents up to #242000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #12 (0.010): 0.361*\".\" + 0.039*\"b\" + 0.036*\"girls\" + 0.029*\"u\" + 0.029*\"answers\" + 0.016*\"have\" + 0.016*\"not\" + 0.015*\"guys\" + 0.014*\"japan\" + 0.014*\"rate\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.162*\"non_ascii_word\" + 0.064*\"delhi\" + 0.033*\"everyone\" + 0.033*\"related\" + 0.023*\"oil\" + 0.021*\"does\" + 0.020*\"seo\" + 0.020*\"attractive\" + 0.019*\"developed\" + 0.018*\"/\"\n",
      "INFO:gensim.models.ldamodel:topic #59 (0.010): 0.103*\"were\" + 0.100*\"still\" + 0.035*\"amazon\" + 0.034*\"send\" + 0.026*\"you\" + 0.025*\"on\" + 0.021*\"did\" + 0.018*\"who\" + 0.017*\"was\" + 0.017*\"not\"\n",
      "INFO:gensim.models.ldamodel:topic #25 (0.010): 0.053*\"girl\" + 0.037*\"that\" + 0.036*\"guy\" + 0.036*\"friends\" + 0.035*\"tell\" + 0.034*\"eat\" + 0.034*\"not\" + 0.030*\"common\" + 0.029*\"woman\" + 0.028*\"mind\"\n",
      "INFO:gensim.models.ldamodel:topic #44 (0.010): 0.173*\"you\" + 0.172*\"about\" + 0.109*\"think\" + 0.048*\"stop\" + 0.037*\"people\" + 0.023*\"know\" + 0.019*\"that\" + 0.019*\"yourself\" + 0.018*\"last\" + 0.018*\"if\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.067926, rho=0.093250\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #121 = documents up to #244000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #122 = documents up to #246000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #12 (0.010): 0.362*\".\" + 0.039*\"b\" + 0.036*\"girls\" + 0.028*\"u\" + 0.028*\"answers\" + 0.016*\"have\" + 0.015*\"not\" + 0.015*\"guys\" + 0.014*\"rate\" + 0.014*\"japan\"\n",
      "INFO:gensim.models.ldamodel:topic #51 (0.010): 0.295*\"between\" + 0.204*\"difference\" + 0.061*\"movie\" + 0.029*\"review\" + 0.024*\"law\" + 0.024*\"city\" + 0.020*\"kill\" + 0.018*\"brain\" + 0.017*\"three\" + 0.014*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.092*\"over\" + 0.079*\"before\" + 0.069*\"bing\" + 0.033*\"class\" + 0.031*\"short\" + 0.028*\"red\" + 0.027*\"correct\" + 0.024*\"structure\" + 0.021*\"because\" + 0.021*\"get\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.093*\"ways\" + 0.069*\"get\" + 0.051*\"rid\" + 0.042*\"some\" + 0.033*\"face\" + 0.032*\"best\" + 0.031*\"on\" + 0.026*\"my\" + 0.025*\"impact\" + 0.025*\"daily\"\n",
      "INFO:gensim.models.ldamodel:topic #86 (0.010): 0.097*\"books\" + 0.072*\"read\" + 0.051*\"very\" + 0.050*\"you\" + 0.047*\"best\" + 0.039*\"fat\" + 0.025*\"some\" + 0.025*\"theory\" + 0.022*\"have\" + 0.019*\"most\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.066497, rho=0.092450\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #123 = documents up to #248000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #124 = documents up to #250000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #18 (0.010): 0.159*\"time\" + 0.080*\"business\" + 0.045*\"back\" + 0.031*\"same\" + 0.028*\"it\" + 0.023*\"physics\" + 0.023*\"instead\" + 0.021*\"my\" + 0.018*\"at\" + 0.015*\"method\"\n",
      "INFO:gensim.models.ldamodel:topic #29 (0.010): 0.050*\"build\" + 0.044*\"run\" + 0.038*\"death\" + 0.037*\"security\" + 0.037*\"suicide\" + 0.028*\"dogs\" + 0.024*\"flat\" + 0.023*\"least\" + 0.023*\"commit\" + 0.020*\"people\"\n",
      "INFO:gensim.models.ldamodel:topic #23 (0.010): 0.147*\"world\" + 0.065*\"war\" + 0.058*\"3\" + 0.043*\"mobile\" + 0.041*\"countries\" + 0.036*\"off\" + 0.024*\"successful\" + 0.018*\"who\" + 0.017*\"likely\" + 0.017*\"british\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.010): 0.089*\"my\" + 0.078*\"increase\" + 0.037*\"type\" + 0.035*\"get\" + 0.034*\"dog\" + 0.033*\"traffic\" + 0.032*\"height\" + 0.027*\"called\" + 0.025*\"does\" + 0.024*\"function\"\n",
      "INFO:gensim.models.ldamodel:topic #22 (0.010): 0.083*\"instagram\" + 0.082*\"see\" + 0.058*\"hair\" + 0.057*\"on\" + 0.044*\"youtube\" + 0.034*\"my\" + 0.027*\"who\" + 0.026*\"beautiful\" + 0.018*\"you\" + 0.016*\"currently\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.066324, rho=0.091670\n",
      "INFO:gensim.models.ldamodel:-8.417 per-word bound, 341.8 perplexity estimate based on a held-out corpus of 2000 documents with 15399 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #125 = documents up to #252000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #60 (0.010): 0.100*\"trump\" + 0.069*\"take\" + 0.060*\"donald\" + 0.055*\"will\" + 0.043*\"president\" + 0.041*\"clinton\" + 0.038*\"hillary\" + 0.032*\"win\" + 0.031*\"who\" + 0.030*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic #73 (0.010): 0.071*\"safe\" + 0.056*\"service\" + 0.053*\"police\" + 0.051*\"hotel\" + 0.036*\"without\" + 0.030*\"be\" + 0.028*\"screen\" + 0.024*\"moral\" + 0.022*\"couples\" + 0.022*\"would\"\n",
      "INFO:gensim.models.ldamodel:topic #44 (0.010): 0.175*\"you\" + 0.173*\"about\" + 0.110*\"think\" + 0.050*\"stop\" + 0.038*\"people\" + 0.025*\"know\" + 0.019*\"that\" + 0.018*\"last\" + 0.018*\"if\" + 0.018*\"yourself\"\n",
      "INFO:gensim.models.ldamodel:topic #68 (0.010): 0.102*\"language\" + 0.094*\"programming\" + 0.086*\"website\" + 0.044*\"best\" + 0.038*\"learn\" + 0.035*\"hack\" + 0.035*\"open\" + 0.028*\"pros\" + 0.028*\"cons\" + 0.025*\"low\"\n",
      "INFO:gensim.models.ldamodel:topic #46 (0.010): 0.052*\"apps\" + 0.048*\"air\" + 0.042*\"reduce\" + 0.041*\"family\" + 0.033*\"uber\" + 0.028*\"or\" + 0.025*\"my\" + 0.025*\"special\" + 0.019*\"convince\" + 0.017*\"devices\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.063667, rho=0.090909\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #126 = documents up to #254000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #127 = documents up to #256000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #128 = documents up to #258000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #40 (0.010): 0.149*\"much\" + 0.059*\"live\" + 0.058*\"during\" + 0.049*\"it\" + 0.049*\"does\" + 0.043*\"cost\" + 0.037*\"future\" + 0.029*\"behind\" + 0.023*\"so\" + 0.020*\"small\"\n",
      "INFO:gensim.models.ldamodel:topic #52 (0.010): 0.114*\"possible\" + 0.073*\"it\" + 0.057*\"career\" + 0.039*\"travel\" + 0.029*\"house\" + 0.028*\"humans\" + 0.024*\"options\" + 0.022*\"check\" + 0.021*\"taking\" + 0.021*\"chemical\"\n",
      "INFO:gensim.models.ldamodel:topic #41 (0.010): 0.062*\"human\" + 0.060*\"state\" + 0.049*\"video\" + 0.046*\"considered\" + 0.039*\"point\" + 0.036*\"terms\" + 0.032*\"matter\" + 0.031*\"worst\" + 0.028*\"at\" + 0.024*\"store\"\n",
      "INFO:gensim.models.ldamodel:topic #43 (0.010): 0.129*\"job\" + 0.068*\"through\" + 0.058*\"learning\" + 0.057*\"interview\" + 0.046*\"process\" + 0.046*\"tips\" + 0.043*\"some\" + 0.041*\"making\" + 0.041*\"affect\" + 0.040*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic #36 (0.010): 0.100*\"year\" + 0.090*\"old\" + 0.061*\"it\" + 0.052*\"true\" + 0.039*\"worth\" + 0.036*\"salary\" + 0.031*\"that\" + 0.026*\"application\" + 0.024*\"must\" + 0.023*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.066741, rho=0.090167\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #129 = documents up to #260000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #130 = documents up to #262000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.176*\"my\" + 0.167*\"english\" + 0.123*\"improve\" + 0.042*\"7\" + 0.033*\"month\" + 0.025*\"should\" + 0.022*\"speaking\" + 0.021*\"communication\" + 0.019*\"mother\" + 0.012*\"pronunciation\"\n",
      "INFO:gensim.models.ldamodel:topic #53 (0.010): 0.147*\"system\" + 0.045*\"operating\" + 0.045*\"biggest\" + 0.040*\"similar\" + 0.033*\"personal\" + 0.026*\"pain\" + 0.024*\"fake\" + 0.022*\"buying\" + 0.022*\"device\" + 0.016*\"location\"\n",
      "INFO:gensim.models.ldamodel:topic #45 (0.010): 0.052*\"percent\" + 0.051*\"hard\" + 0.036*\"choose\" + 0.036*\"single\" + 0.034*\"group\" + 0.025*\"paper\" + 0.024*\"eating\" + 0.024*\"grow\" + 0.021*\"it\" + 0.020*\"loss\"\n",
      "INFO:gensim.models.ldamodel:topic #32 (0.010): 0.129*\"really\" + 0.057*\"exist\" + 0.041*\"does\" + 0.034*\"hate\" + 0.025*\"that\" + 0.024*\"there\" + 0.023*\"once\" + 0.019*\"evidence\" + 0.017*\"any\" + 0.017*\"secret\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.010): 0.094*\"go\" + 0.044*\"skills\" + 0.041*\"writing\" + 0.038*\"show\" + 0.032*\"causes\" + 0.030*\"wear\" + 0.028*\"stay\" + 0.027*\"required\" + 0.026*\"pro\" + 0.022*\"macbook\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.064500, rho=0.089443\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #131 = documents up to #264000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #132 = documents up to #266000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #68 (0.010): 0.103*\"language\" + 0.093*\"programming\" + 0.085*\"website\" + 0.046*\"best\" + 0.040*\"learn\" + 0.036*\"hack\" + 0.036*\"open\" + 0.027*\"pros\" + 0.026*\"cons\" + 0.025*\"languages\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.010): 0.197*\"where\" + 0.149*\"find\" + 0.035*\"support\" + 0.030*\"get\" + 0.022*\"times\" + 0.019*\"my\" + 0.018*\"sim\" + 0.018*\"religion\" + 0.015*\"you\" + 0.015*\"quickly\"\n",
      "INFO:gensim.models.ldamodel:topic #52 (0.010): 0.118*\"possible\" + 0.076*\"it\" + 0.058*\"career\" + 0.039*\"travel\" + 0.028*\"house\" + 0.027*\"humans\" + 0.022*\"check\" + 0.022*\"chemical\" + 0.022*\"options\" + 0.021*\"taking\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.010): 0.089*\"my\" + 0.076*\"increase\" + 0.041*\"type\" + 0.035*\"traffic\" + 0.035*\"get\" + 0.033*\"height\" + 0.031*\"dog\" + 0.026*\"called\" + 0.026*\"does\" + 0.023*\"function\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.059*\"real\" + 0.056*\"average\" + 0.049*\"america\" + 0.048*\"food\" + 0.042*\"age\" + 0.040*\"non\" + 0.028*\"able\" + 0.025*\"child\" + 0.024*\"there\" + 0.023*\"100\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.064590, rho=0.088736\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #133 = documents up to #268000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #134 = documents up to #270000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #33 (0.010): 0.055*\"power\" + 0.054*\"2017\" + 0.050*\"music\" + 0.042*\"management\" + 0.036*\"move\" + 0.032*\"you\" + 0.030*\"compared\" + 0.030*\"new\" + 0.027*\"gold\" + 0.027*\"field\"\n",
      "INFO:gensim.models.ldamodel:topic #68 (0.010): 0.103*\"language\" + 0.093*\"programming\" + 0.086*\"website\" + 0.045*\"best\" + 0.038*\"learn\" + 0.036*\"hack\" + 0.035*\"open\" + 0.029*\"pros\" + 0.028*\"cons\" + 0.024*\"languages\"\n",
      "INFO:gensim.models.ldamodel:topic #61 (0.010): 0.104*\"thing\" + 0.076*\"you\" + 0.035*\"demonetization\" + 0.034*\"most\" + 0.034*\"advantages\" + 0.029*\"that\" + 0.029*\"given\" + 0.028*\"have\" + 0.023*\"disadvantages\" + 0.022*\"second\"\n",
      "INFO:gensim.models.ldamodel:topic #66 (0.010): 0.139*\"ever\" + 0.058*\"have\" + 0.054*\"done\" + 0.053*\"you\" + 0.052*\"best\" + 0.038*\"space\" + 0.031*\"coaching\" + 0.027*\"institute\" + 0.022*\"training\" + 0.019*\"tools\"\n",
      "INFO:gensim.models.ldamodel:topic #70 (0.010): 0.163*\"quora\" + 0.104*\"on\" + 0.065*\"questions\" + 0.048*\"question\" + 0.041*\"ask\" + 0.029*\"people\" + 0.027*\"answer\" + 0.025*\"effects\" + 0.023*\"my\" + 0.020*\"as\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.061829, rho=0.088045\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #135 = documents up to #272000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #136 = documents up to #274000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #56 (0.010): 0.062*\"some\" + 0.043*\"about\" + 0.041*\"interesting\" + 0.037*\"based\" + 0.036*\"known\" + 0.036*\"facts\" + 0.031*\"australia\" + 0.025*\"model\" + 0.025*\"japanese\" + 0.024*\"india\"\n",
      "INFO:gensim.models.ldamodel:topic #18 (0.010): 0.166*\"time\" + 0.080*\"business\" + 0.045*\"back\" + 0.037*\"same\" + 0.029*\"it\" + 0.023*\"instead\" + 0.021*\"physics\" + 0.021*\"my\" + 0.018*\"12\" + 0.017*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #51 (0.010): 0.294*\"between\" + 0.206*\"difference\" + 0.066*\"movie\" + 0.028*\"law\" + 0.028*\"review\" + 0.023*\"city\" + 0.020*\"kill\" + 0.018*\"brain\" + 0.017*\"three\" + 0.013*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.318*\"your\" + 0.109*\"you\" + 0.050*\"life\" + 0.042*\"school\" + 0.037*\"high\" + 0.030*\"favorite\" + 0.019*\"join\" + 0.014*\"best\" + 0.012*\"did\" + 0.011*\"easy\"\n",
      "INFO:gensim.models.ldamodel:topic #40 (0.010): 0.158*\"much\" + 0.061*\"live\" + 0.054*\"during\" + 0.050*\"does\" + 0.048*\"it\" + 0.045*\"cost\" + 0.037*\"future\" + 0.029*\"behind\" + 0.023*\"so\" + 0.022*\"small\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.064523, rho=0.087370\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #137 = documents up to #276000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #138 = documents up to #278000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #44 (0.010): 0.178*\"about\" + 0.172*\"you\" + 0.113*\"think\" + 0.053*\"stop\" + 0.038*\"people\" + 0.028*\"know\" + 0.020*\"last\" + 0.020*\"that\" + 0.018*\"indians\" + 0.018*\"yourself\"\n",
      "INFO:gensim.models.ldamodel:topic #95 (0.010): 0.162*\"work\" + 0.066*\"does\" + 0.034*\"at\" + 0.031*\"bangalore\" + 0.029*\"apply\" + 0.029*\"differ\" + 0.025*\"vote\" + 0.024*\"videos\" + 0.024*\"4\" + 0.022*\"have\"\n",
      "INFO:gensim.models.ldamodel:topic #51 (0.010): 0.293*\"between\" + 0.203*\"difference\" + 0.066*\"movie\" + 0.028*\"review\" + 0.028*\"law\" + 0.022*\"city\" + 0.021*\"kill\" + 0.018*\"brain\" + 0.017*\"three\" + 0.013*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #46 (0.010): 0.050*\"apps\" + 0.050*\"air\" + 0.048*\"reduce\" + 0.048*\"family\" + 0.034*\"uber\" + 0.028*\"or\" + 0.028*\"my\" + 0.026*\"special\" + 0.019*\"convince\" + 0.016*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #69 (0.010): 0.279*\"which\" + 0.269*\"best\" + 0.036*\"india\" + 0.036*\"country\" + 0.035*\"way\" + 0.025*\"laptop\" + 0.023*\"test\" + 0.020*\"marketing\" + 0.020*\"course\" + 0.019*\"market\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.062974, rho=0.086711\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #139 = documents up to #280000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #140 = documents up to #282000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #77 (0.010): 0.118*\"change\" + 0.053*\"around\" + 0.042*\"popular\" + 0.033*\"views\" + 0.028*\"decision\" + 0.024*\"let\" + 0.023*\"news\" + 0.023*\"!\" + 0.022*\"it\" + 0.021*\"personality\"\n",
      "INFO:gensim.models.ldamodel:topic #65 (0.010): 0.060*\"android\" + 0.054*\"social\" + 0.045*\"working\" + 0.042*\"end\" + 0.038*\"today\" + 0.037*\"whatsapp\" + 0.037*\"always\" + 0.033*\"on\" + 0.031*\"media\" + 0.028*\"ideas\"\n",
      "INFO:gensim.models.ldamodel:topic #60 (0.010): 0.097*\"trump\" + 0.071*\"take\" + 0.057*\"donald\" + 0.056*\"will\" + 0.045*\"clinton\" + 0.044*\"president\" + 0.041*\"hillary\" + 0.033*\"win\" + 0.031*\"us\" + 0.030*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic #87 (0.010): 0.057*\"parents\" + 0.055*\"date\" + 0.028*\"knowledge\" + 0.024*\"land\" + 0.022*\"with\" + 0.021*\"kids\" + 0.017*\"my\" + 0.015*\"or\" + 0.014*\"candidate\" + 0.014*\"till\"\n",
      "INFO:gensim.models.ldamodel:topic #67 (0.010): 0.066*\"prepare\" + 0.053*\"water\" + 0.047*\"bank\" + 0.032*\"mechanical\" + 0.031*\"education\" + 0.029*\"should\" + 0.028*\"england\" + 0.028*\"cat\" + 0.020*\"invest\" + 0.019*\"with\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.060327, rho=0.086066\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #141 = documents up to #284000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #142 = documents up to #286000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.010): 0.095*\"go\" + 0.044*\"skills\" + 0.043*\"writing\" + 0.037*\"show\" + 0.032*\"stay\" + 0.030*\"causes\" + 0.030*\"wear\" + 0.026*\"required\" + 0.023*\"letter\" + 0.022*\"pro\"\n",
      "INFO:gensim.models.ldamodel:topic #97 (0.010): 0.156*\"more\" + 0.130*\"than\" + 0.066*\"study\" + 0.051*\"give\" + 0.026*\"or\" + 0.018*\"exams\" + 0.017*\"germany\" + 0.017*\"modern\" + 0.017*\"please\" + 0.017*\"2015\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.010): 0.182*\"would\" + 0.112*\"if\" + 0.062*\"be\" + 0.045*\"happen\" + 0.036*\"car\" + 0.030*\"will\" + 0.025*\"you\" + 0.022*\"light\" + 0.021*\"then\" + 0.019*\"speed\"\n",
      "INFO:gensim.models.ldamodel:topic #95 (0.010): 0.161*\"work\" + 0.065*\"does\" + 0.035*\"at\" + 0.032*\"bangalore\" + 0.029*\"apply\" + 0.027*\"differ\" + 0.027*\"4\" + 0.025*\"vote\" + 0.025*\"videos\" + 0.022*\"marks\"\n",
      "INFO:gensim.models.ldamodel:topic #90 (0.010): 0.117*\"2\" + 0.102*\"+\" + 0.089*\"c\" + 0.068*\"home\" + 0.037*\"foreign\" + 0.022*\"n\" + 0.022*\"good\" + 0.021*\"d\" + 0.020*\"bring\" + 0.018*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.058143, rho=0.085436\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #143 = documents up to #288000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #144 = documents up to #290000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #94 (0.010): 0.253*\"'\" + 0.071*\"meaning\" + 0.051*\"pakistan\" + 0.046*\"word\" + 0.031*\"universe\" + 0.025*\"hindi\" + 0.022*\"india\" + 0.017*\"certificate\" + 0.015*\"minimum\" + 0.014*\"ticket\"\n",
      "INFO:gensim.models.ldamodel:topic #24 (0.010): 0.204*\")\" + 0.203*\"(\" + 0.071*\":\" + 0.068*\"better\" + 0.068*\"or\" + 0.037*\"which\" + 0.035*\"long\" + 0.022*\"quoted_item\" + 0.016*\"mba\" + 0.016*\"main\"\n",
      "INFO:gensim.models.ldamodel:topic #61 (0.010): 0.107*\"thing\" + 0.077*\"you\" + 0.037*\"demonetization\" + 0.035*\"most\" + 0.033*\"advantages\" + 0.032*\"that\" + 0.031*\"given\" + 0.027*\"have\" + 0.024*\"disadvantages\" + 0.022*\"calculate\"\n",
      "INFO:gensim.models.ldamodel:topic #83 (0.010): 0.061*\"experience\" + 0.046*\"sites\" + 0.042*\"level\" + 0.038*\"photos\" + 0.038*\"preparation\" + 0.022*\"dating\" + 0.022*\"planning\" + 0.019*\"18\" + 0.019*\"11\" + 0.018*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic #48 (0.010): 0.120*\"other\" + 0.057*\"government\" + 0.045*\"india\" + 0.040*\"against\" + 0.040*\"each\" + 0.024*\"products\" + 0.022*\"policy\" + 0.022*\"female\" + 0.022*\"not\" + 0.021*\"network\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.058540, rho=0.084819\n",
      "INFO:gensim.models.ldamodel:-8.311 per-word bound, 317.7 perplexity estimate based on a held-out corpus of 2000 documents with 15028 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #145 = documents up to #292000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #82 (0.010): 0.085*\"bad\" + 0.060*\"two\" + 0.058*\"game\" + 0.031*\"blood\" + 0.030*\"you\" + 0.027*\"it\" + 0.027*\"or\" + 0.026*\"fix\" + 0.022*\"that\" + 0.020*\"try\"\n",
      "INFO:gensim.models.ldamodel:topic #73 (0.010): 0.066*\"safe\" + 0.063*\"service\" + 0.058*\"police\" + 0.051*\"hotel\" + 0.042*\"without\" + 0.029*\"be\" + 0.024*\"moral\" + 0.023*\"couples\" + 0.023*\"screen\" + 0.021*\"staff\"\n",
      "INFO:gensim.models.ldamodel:topic #84 (0.010): 0.106*\"book\" + 0.064*\"name\" + 0.053*\"tv\" + 0.042*\"series\" + 0.033*\"best\" + 0.028*\"ias\" + 0.026*\"my\" + 0.026*\"left\" + 0.023*\"hire\" + 0.019*\"officer\"\n",
      "INFO:gensim.models.ldamodel:topic #87 (0.010): 0.059*\"parents\" + 0.051*\"date\" + 0.031*\"knowledge\" + 0.025*\"land\" + 0.024*\"with\" + 0.023*\"kids\" + 0.017*\"candidate\" + 0.016*\"my\" + 0.014*\"you\" + 0.014*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.094*\"over\" + 0.091*\"before\" + 0.063*\"bing\" + 0.034*\"class\" + 0.033*\"correct\" + 0.029*\"short\" + 0.027*\"red\" + 0.023*\"because\" + 0.023*\"structure\" + 0.021*\"get\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.057980, rho=0.084215\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #146 = documents up to #294000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #147 = documents up to #296000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #148 = documents up to #298000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #82 (0.010): 0.083*\"bad\" + 0.062*\"two\" + 0.057*\"game\" + 0.030*\"you\" + 0.030*\"blood\" + 0.027*\"or\" + 0.027*\"it\" + 0.026*\"fix\" + 0.022*\"that\" + 0.021*\"try\"\n",
      "INFO:gensim.models.ldamodel:topic #72 (0.010): 0.101*\"their\" + 0.093*\"first\" + 0.080*\"day\" + 0.078*\"things\" + 0.075*\"into\" + 0.064*\"know\" + 0.056*\"going\" + 0.043*\"should\" + 0.040*\"some\" + 0.032*\"new\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.153*\"non_ascii_word\" + 0.069*\"delhi\" + 0.033*\"everyone\" + 0.029*\"related\" + 0.027*\"oil\" + 0.022*\"seo\" + 0.020*\"okay\" + 0.020*\"east\" + 0.019*\"does\" + 0.018*\"attractive\"\n",
      "INFO:gensim.models.ldamodel:topic #77 (0.010): 0.113*\"change\" + 0.057*\"around\" + 0.047*\"popular\" + 0.032*\"views\" + 0.027*\"decision\" + 0.027*\"let\" + 0.024*\"news\" + 0.023*\"!\" + 0.022*\"personality\" + 0.021*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic #76 (0.010): 0.067*\"watch\" + 0.047*\"something\" + 0.042*\"you\" + 0.042*\"seen\" + 0.030*\"have\" + 0.025*\"tax\" + 0.022*\"season\" + 0.022*\"movies\" + 0.020*\"on\" + 0.019*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.056256, rho=0.083624\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #149 = documents up to #300000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #150 = documents up to #302000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #58 (0.010): 0.098*\"app\" + 0.068*\"web\" + 0.049*\"java\" + 0.045*\"development\" + 0.043*\"living\" + 0.039*\"search\" + 0.027*\"android\" + 0.026*\"developer\" + 0.025*\"net\" + 0.023*\"best\"\n",
      "INFO:gensim.models.ldamodel:topic #64 (0.010): 0.080*\"need\" + 0.079*\"up\" + 0.041*\"pay\" + 0.040*\"keep\" + 0.040*\"got\" + 0.035*\"cause\" + 0.023*\"does\" + 0.022*\"get\" + 0.019*\"you\" + 0.019*\"chance\"\n",
      "INFO:gensim.models.ldamodel:topic #30 (0.010): 0.295*\"make\" + 0.036*\"current\" + 0.033*\"happened\" + 0.032*\"money\" + 0.031*\"full\" + 0.029*\"degree\" + 0.026*\"you\" + 0.019*\"master\" + 0.018*\"does\" + 0.018*\"obama\"\n",
      "INFO:gensim.models.ldamodel:topic #46 (0.010): 0.052*\"air\" + 0.050*\"reduce\" + 0.049*\"family\" + 0.046*\"apps\" + 0.034*\"uber\" + 0.029*\"my\" + 0.029*\"or\" + 0.023*\"special\" + 0.017*\"convince\" + 0.017*\"devices\"\n",
      "INFO:gensim.models.ldamodel:topic #75 (0.010): 0.072*\"doing\" + 0.055*\"internet\" + 0.041*\"wrong\" + 0.035*\"part\" + 0.034*\"modi\" + 0.030*\"studying\" + 0.027*\"sydney\" + 0.024*\"professional\" + 0.023*\"best\" + 0.019*\"narendra\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.056925, rho=0.083045\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #151 = documents up to #304000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #152 = documents up to #306000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #79 (0.010): 0.061*\"kind\" + 0.059*\"2016\" + 0.048*\"overcome\" + 0.029*\"fear\" + 0.028*\"beginner\" + 0.027*\"cut\" + 0.021*\"expected\" + 0.019*\"designer\" + 0.017*\"cutoff\" + 0.014*\"percentile\"\n",
      "INFO:gensim.models.ldamodel:topic #85 (0.010): 0.104*\".\" + 0.075*\"me\" + 0.066*\"my\" + 0.060*\"am\" + 0.040*\"want\" + 0.033*\"he\" + 0.033*\"not\" + 0.029*\"should\" + 0.028*\"if\" + 0.027*\"her\"\n",
      "INFO:gensim.models.ldamodel:topic #41 (0.010): 0.066*\"human\" + 0.061*\"state\" + 0.057*\"video\" + 0.049*\"considered\" + 0.037*\"point\" + 0.035*\"matter\" + 0.033*\"terms\" + 0.028*\"worst\" + 0.026*\"store\" + 0.026*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #69 (0.010): 0.287*\"best\" + 0.273*\"which\" + 0.041*\"way\" + 0.035*\"country\" + 0.033*\"india\" + 0.024*\"laptop\" + 0.022*\"test\" + 0.019*\"marketing\" + 0.019*\"course\" + 0.018*\"market\"\n",
      "INFO:gensim.models.ldamodel:topic #61 (0.010): 0.107*\"thing\" + 0.074*\"you\" + 0.040*\"demonetization\" + 0.035*\"most\" + 0.034*\"advantages\" + 0.032*\"that\" + 0.031*\"given\" + 0.025*\"have\" + 0.025*\"disadvantages\" + 0.022*\"taken\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.055532, rho=0.082479\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #153 = documents up to #308000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #154 = documents up to #310000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #44 (0.010): 0.189*\"about\" + 0.169*\"you\" + 0.117*\"think\" + 0.056*\"stop\" + 0.041*\"people\" + 0.029*\"know\" + 0.021*\"last\" + 0.020*\"that\" + 0.019*\"indians\" + 0.017*\"yourself\"\n",
      "INFO:gensim.models.ldamodel:topic #91 (0.010): 0.068*\"days\" + 0.056*\"even\" + 0.052*\"with\" + 0.039*\"period\" + 0.034*\"deal\" + 0.032*\"pregnant\" + 0.031*\"get\" + 0.030*\"my\" + 0.025*\"depression\" + 0.021*\"after\"\n",
      "INFO:gensim.models.ldamodel:topic #36 (0.010): 0.103*\"year\" + 0.088*\"old\" + 0.065*\"it\" + 0.054*\"true\" + 0.041*\"worth\" + 0.038*\"salary\" + 0.034*\"that\" + 0.023*\"fast\" + 0.023*\"application\" + 0.022*\"must\"\n",
      "INFO:gensim.models.ldamodel:topic #33 (0.010): 0.055*\"2017\" + 0.053*\"music\" + 0.047*\"power\" + 0.044*\"management\" + 0.038*\"move\" + 0.034*\"new\" + 0.033*\"you\" + 0.030*\"compared\" + 0.028*\"year\" + 0.028*\"field\"\n",
      "INFO:gensim.models.ldamodel:topic #96 (0.010): 0.141*\"have\" + 0.113*\"you\" + 0.085*\"had\" + 0.050*\"if\" + 0.032*\"been\" + 0.029*\"international\" + 0.025*\"night\" + 0.021*\"would\" + 0.021*\"dream\" + 0.020*\"area\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.054595, rho=0.081923\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #155 = documents up to #312000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #156 = documents up to #314000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.010): 0.063*\"every\" + 0.049*\"famous\" + 0.029*\"political\" + 0.024*\"cards\" + 0.024*\"capital\" + 0.023*\"towards\" + 0.023*\"systems\" + 0.022*\"voice\" + 0.019*\"trading\" + 0.019*\"banks\"\n",
      "INFO:gensim.models.ldamodel:topic #21 (0.010): 0.103*\"/\" + 0.057*\"math\" + 0.055*\"exam\" + 0.050*\"1\" + 0.047*\"[\" + 0.047*\"]\" + 0.037*\"x\" + 0.032*\"games\" + 0.031*\"=\" + 0.029*\"\\\"\n",
      "INFO:gensim.models.ldamodel:topic #52 (0.010): 0.124*\"possible\" + 0.084*\"it\" + 0.054*\"career\" + 0.043*\"travel\" + 0.028*\"house\" + 0.027*\"humans\" + 0.025*\"chemical\" + 0.023*\"taking\" + 0.022*\"options\" + 0.022*\"check\"\n",
      "INFO:gensim.models.ldamodel:topic #29 (0.010): 0.048*\"death\" + 0.045*\"build\" + 0.044*\"run\" + 0.038*\"security\" + 0.035*\"suicide\" + 0.029*\"dogs\" + 0.023*\"flat\" + 0.023*\"commit\" + 0.022*\"least\" + 0.020*\"after\"\n",
      "INFO:gensim.models.ldamodel:topic #99 (0.010): 0.134*\"google\" + 0.083*\"just\" + 0.034*\"speak\" + 0.033*\"view\" + 0.024*\"on\" + 0.024*\"here\" + 0.024*\"won\" + 0.021*\"sbi\" + 0.019*\"they\" + 0.017*\"analytics\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.050134, rho=0.081379\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #157 = documents up to #316000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #158 = documents up to #318000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #72 (0.010): 0.105*\"their\" + 0.095*\"first\" + 0.080*\"day\" + 0.080*\"things\" + 0.072*\"into\" + 0.063*\"know\" + 0.055*\"going\" + 0.043*\"should\" + 0.041*\"some\" + 0.031*\"new\"\n",
      "INFO:gensim.models.ldamodel:topic #40 (0.010): 0.164*\"much\" + 0.064*\"live\" + 0.057*\"during\" + 0.051*\"does\" + 0.046*\"it\" + 0.044*\"cost\" + 0.038*\"future\" + 0.031*\"behind\" + 0.025*\"so\" + 0.023*\"small\"\n",
      "INFO:gensim.models.ldamodel:topic #89 (0.010): 0.095*\"company\" + 0.075*\"software\" + 0.050*\"engineer\" + 0.042*\"another\" + 0.038*\"battle\" + 0.029*\"compare\" + 0.027*\"an\" + 0.024*\"term\" + 0.023*\"solution\" + 0.023*\"this\"\n",
      "INFO:gensim.models.ldamodel:topic #86 (0.010): 0.105*\"books\" + 0.074*\"read\" + 0.057*\"very\" + 0.045*\"best\" + 0.042*\"fat\" + 0.040*\"you\" + 0.030*\"theory\" + 0.026*\"some\" + 0.023*\"belly\" + 0.021*\"have\"\n",
      "INFO:gensim.models.ldamodel:topic #34 (0.010): 0.049*\"legal\" + 0.040*\"product\" + 0.035*\"happy\" + 0.029*\"written\" + 0.024*\"resolution\" + 0.023*\"expect\" + 0.023*\"core\" + 0.023*\"passport\" + 0.020*\"needs\" + 0.017*\"be\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.051845, rho=0.080845\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #159 = documents up to #320000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #160 = documents up to #322000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #17 (0.010): 0.055*\"energy\" + 0.040*\"believe\" + 0.039*\"god\" + 0.037*\"actually\" + 0.036*\"if\" + 0.032*\"dark\" + 0.031*\"that\" + 0.028*\"it\" + 0.027*\"no\" + 0.027*\"there\"\n",
      "INFO:gensim.models.ldamodel:topic #85 (0.010): 0.103*\".\" + 0.075*\"me\" + 0.065*\"my\" + 0.061*\"am\" + 0.042*\"want\" + 0.034*\"he\" + 0.032*\"not\" + 0.029*\"his\" + 0.028*\"if\" + 0.028*\"should\"\n",
      "INFO:gensim.models.ldamodel:topic #77 (0.010): 0.113*\"change\" + 0.054*\"around\" + 0.043*\"popular\" + 0.035*\"views\" + 0.029*\"decision\" + 0.025*\"let\" + 0.023*\"news\" + 0.022*\"personality\" + 0.022*\"!\" + 0.022*\"linux\"\n",
      "INFO:gensim.models.ldamodel:topic #50 (0.010): 0.139*\"love\" + 0.132*\"used\" + 0.047*\"makes\" + 0.034*\"by\" + 0.033*\"on\" + 0.031*\"fall\" + 0.026*\"safety\" + 0.025*\"proposed\" + 0.024*\"handling\" + 0.023*\"precautions\"\n",
      "INFO:gensim.models.ldamodel:topic #70 (0.010): 0.162*\"quora\" + 0.104*\"on\" + 0.066*\"questions\" + 0.052*\"question\" + 0.043*\"ask\" + 0.029*\"people\" + 0.028*\"answer\" + 0.026*\"my\" + 0.024*\"effects\" + 0.020*\"as\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.051000, rho=0.080322\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #161 = documents up to #324000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #162 = documents up to #326000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #49 (0.010): 0.082*\"computer\" + 0.076*\"science\" + 0.075*\"data\" + 0.045*\"history\" + 0.029*\"both\" + 0.029*\"canada\" + 0.026*\"others\" + 0.023*\"from\" + 0.020*\"ms\" + 0.019*\"difficult\"\n",
      "INFO:gensim.models.ldamodel:topic #33 (0.010): 0.057*\"2017\" + 0.049*\"music\" + 0.044*\"power\" + 0.044*\"management\" + 0.035*\"you\" + 0.034*\"move\" + 0.032*\"new\" + 0.031*\"compared\" + 0.029*\"year\" + 0.027*\"field\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.093*\"before\" + 0.089*\"over\" + 0.062*\"bing\" + 0.034*\"correct\" + 0.032*\"class\" + 0.027*\"short\" + 0.024*\"structure\" + 0.024*\"red\" + 0.021*\"because\" + 0.020*\"get\"\n",
      "INFO:gensim.models.ldamodel:topic #70 (0.010): 0.161*\"quora\" + 0.104*\"on\" + 0.067*\"questions\" + 0.052*\"question\" + 0.043*\"ask\" + 0.029*\"people\" + 0.028*\"answer\" + 0.026*\"my\" + 0.024*\"effects\" + 0.020*\"as\"\n",
      "INFO:gensim.models.ldamodel:topic #75 (0.010): 0.072*\"doing\" + 0.054*\"internet\" + 0.039*\"modi\" + 0.037*\"wrong\" + 0.034*\"part\" + 0.030*\"studying\" + 0.028*\"sydney\" + 0.023*\"narendra\" + 0.022*\"professional\" + 0.020*\"best\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.050219, rho=0.079809\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #163 = documents up to #328000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #164 = documents up to #330000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.010): 0.105*\"my\" + 0.082*\"account\" + 0.076*\"facebook\" + 0.040*\"password\" + 0.038*\"email\" + 0.028*\"gmail\" + 0.023*\"recover\" + 0.022*\"from\" + 0.019*\"delete\" + 0.018*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic #70 (0.010): 0.162*\"quora\" + 0.104*\"on\" + 0.067*\"questions\" + 0.052*\"question\" + 0.042*\"ask\" + 0.029*\"people\" + 0.028*\"answer\" + 0.026*\"my\" + 0.024*\"effects\" + 0.020*\"as\"\n",
      "INFO:gensim.models.ldamodel:topic #68 (0.010): 0.108*\"language\" + 0.096*\"programming\" + 0.083*\"website\" + 0.041*\"learn\" + 0.038*\"best\" + 0.036*\"hack\" + 0.035*\"open\" + 0.028*\"languages\" + 0.025*\"pros\" + 0.025*\"low\"\n",
      "INFO:gensim.models.ldamodel:topic #74 (0.010): 0.041*\"star\" + 0.039*\"does\" + 0.038*\"industry\" + 0.036*\"moon\" + 0.031*\"option\" + 0.026*\"sun\" + 0.026*\"sound\" + 0.022*\"wars\" + 0.019*\"stand\" + 0.019*\"gravity\"\n",
      "INFO:gensim.models.ldamodel:topic #67 (0.010): 0.072*\"prepare\" + 0.056*\"water\" + 0.046*\"bank\" + 0.034*\"education\" + 0.033*\"mechanical\" + 0.030*\"should\" + 0.029*\"england\" + 0.027*\"cat\" + 0.021*\"again\" + 0.020*\"army\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.049918, rho=0.079305\n",
      "INFO:gensim.models.ldamodel:-8.252 per-word bound, 304.8 perplexity estimate based on a held-out corpus of 2000 documents with 15388 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #165 = documents up to #332000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #37 (0.010): 0.199*\"has\" + 0.057*\"been\" + 0.043*\"next\" + 0.031*\"apple\" + 0.022*\"size\" + 0.021*\"quality\" + 0.021*\"when\" + 0.021*\"set\" + 0.020*\"americans\" + 0.020*\"often\"\n",
      "INFO:gensim.models.ldamodel:topic #97 (0.010): 0.152*\"more\" + 0.136*\"than\" + 0.062*\"study\" + 0.052*\"give\" + 0.029*\"or\" + 0.019*\"please\" + 0.019*\"2015\" + 0.018*\"mix\" + 0.018*\"exams\" + 0.016*\"/\"\n",
      "INFO:gensim.models.ldamodel:topic #53 (0.010): 0.152*\"system\" + 0.047*\"operating\" + 0.047*\"biggest\" + 0.037*\"similar\" + 0.029*\"personal\" + 0.025*\"buying\" + 0.025*\"device\" + 0.024*\"pain\" + 0.020*\"fake\" + 0.020*\"recent\"\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.010): 0.164*\"learn\" + 0.141*\"start\" + 0.042*\"best\" + 0.038*\"should\" + 0.036*\"way\" + 0.031*\"technology\" + 0.030*\"order\" + 0.024*\"python\" + 0.023*\"idea\" + 0.020*\"sell\"\n",
      "INFO:gensim.models.ldamodel:topic #10 (0.010): 0.133*\"phone\" + 0.099*\"buy\" + 0.047*\"under\" + 0.029*\"benefits\" + 0.026*\"should\" + 0.023*\"my\" + 0.022*\"an\" + 0.021*\"problems\" + 0.021*\"6\" + 0.020*\"iq\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.048533, rho=0.078811\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #166 = documents up to #334000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #167 = documents up to #336000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #168 = documents up to #338000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #20 (0.010): 0.063*\"place\" + 0.057*\"best\" + 0.056*\"usa\" + 0.055*\"places\" + 0.054*\"visit\" + 0.040*\"public\" + 0.039*\"visa\" + 0.025*\"india\" + 0.019*\"interested\" + 0.018*\"estate\"\n",
      "INFO:gensim.models.ldamodel:topic #23 (0.010): 0.141*\"world\" + 0.063*\"war\" + 0.055*\"3\" + 0.046*\"mobile\" + 0.043*\"countries\" + 0.034*\"off\" + 0.027*\"successful\" + 0.019*\"most\" + 0.019*\"turn\" + 0.019*\"who\"\n",
      "INFO:gensim.models.ldamodel:topic #89 (0.010): 0.093*\"company\" + 0.077*\"software\" + 0.053*\"engineer\" + 0.042*\"another\" + 0.041*\"battle\" + 0.030*\"compare\" + 0.026*\"an\" + 0.026*\"term\" + 0.025*\"solution\" + 0.023*\"this\"\n",
      "INFO:gensim.models.ldamodel:topic #81 (0.010): 0.056*\"10\" + 0.047*\"windows\" + 0.042*\"problem\" + 0.025*\"words\" + 0.024*\"it\" + 0.024*\"explain\" + 0.024*\"solve\" + 0.021*\"does\" + 0.020*\"memory\" + 0.019*\"shows\"\n",
      "INFO:gensim.models.ldamodel:topic #98 (0.010): 0.093*\"its\" + 0.065*\"download\" + 0.045*\"site\" + 0.037*\"less\" + 0.033*\"form\" + 0.030*\"develop\" + 0.027*\"office\" + 0.026*\"charge\" + 0.017*\"from\" + 0.016*\"india\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.048762, rho=0.078326\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #169 = documents up to #340000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #170 = documents up to #342000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #32 (0.010): 0.139*\"really\" + 0.048*\"exist\" + 0.042*\"does\" + 0.037*\"hate\" + 0.027*\"once\" + 0.024*\"that\" + 0.022*\"amount\" + 0.020*\"people\" + 0.020*\"there\" + 0.019*\"partner\"\n",
      "INFO:gensim.models.ldamodel:topic #13 (0.010): 0.046*\"song\" + 0.045*\"control\" + 0.043*\"california\" + 0.038*\"ca\" + 0.035*\"research\" + 0.035*\"solar\" + 0.031*\"provider\" + 0.029*\"avoid\" + 0.027*\"healthy\" + 0.027*\"hyderabad\"\n",
      "INFO:gensim.models.ldamodel:topic #80 (0.010): 0.079*\"write\" + 0.068*\"card\" + 0.066*\"differences\" + 0.063*\"body\" + 0.044*\"program\" + 0.036*\"credit\" + 0.035*\"medical\" + 0.029*\"basic\" + 0.023*\"works\" + 0.023*\"pressure\"\n",
      "INFO:gensim.models.ldamodel:topic #37 (0.010): 0.206*\"has\" + 0.057*\"been\" + 0.039*\"next\" + 0.031*\"apple\" + 0.023*\"size\" + 0.022*\"set\" + 0.022*\"when\" + 0.021*\"quality\" + 0.020*\"often\" + 0.020*\"americans\"\n",
      "INFO:gensim.models.ldamodel:topic #97 (0.010): 0.152*\"more\" + 0.136*\"than\" + 0.062*\"study\" + 0.051*\"give\" + 0.028*\"or\" + 0.019*\"please\" + 0.018*\"germany\" + 0.018*\"2015\" + 0.018*\"exams\" + 0.017*\"mix\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.047291, rho=0.077850\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #171 = documents up to #344000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #172 = documents up to #346000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #52 (0.010): 0.123*\"possible\" + 0.093*\"it\" + 0.053*\"career\" + 0.043*\"travel\" + 0.028*\"house\" + 0.027*\"humans\" + 0.024*\"chemical\" + 0.022*\"check\" + 0.022*\"options\" + 0.021*\"taking\"\n",
      "INFO:gensim.models.ldamodel:topic #40 (0.010): 0.164*\"much\" + 0.066*\"live\" + 0.055*\"during\" + 0.049*\"it\" + 0.048*\"does\" + 0.043*\"cost\" + 0.042*\"future\" + 0.031*\"behind\" + 0.025*\"so\" + 0.024*\"story\"\n",
      "INFO:gensim.models.ldamodel:topic #69 (0.010): 0.309*\"best\" + 0.266*\"which\" + 0.046*\"way\" + 0.032*\"india\" + 0.032*\"country\" + 0.022*\"laptop\" + 0.020*\"marketing\" + 0.018*\"test\" + 0.017*\"market\" + 0.017*\"course\"\n",
      "INFO:gensim.models.ldamodel:topic #41 (0.010): 0.059*\"state\" + 0.057*\"human\" + 0.054*\"video\" + 0.051*\"considered\" + 0.039*\"terms\" + 0.035*\"point\" + 0.034*\"matter\" + 0.033*\"worst\" + 0.026*\"at\" + 0.026*\"store\"\n",
      "INFO:gensim.models.ldamodel:topic #98 (0.010): 0.092*\"its\" + 0.067*\"download\" + 0.049*\"site\" + 0.036*\"less\" + 0.033*\"form\" + 0.029*\"develop\" + 0.026*\"office\" + 0.024*\"charge\" + 0.018*\"from\" + 0.017*\"india\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.045058, rho=0.077382\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #173 = documents up to #348000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #174 = documents up to #350000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #19 (0.010): 0.061*\"myself\" + 0.043*\"center\" + 0.042*\"value\" + 0.041*\"drug\" + 0.038*\"alcohol\" + 0.035*\"started\" + 0.032*\"near\" + 0.030*\"mass\" + 0.029*\"county\" + 0.028*\"rehab\"\n",
      "INFO:gensim.models.ldamodel:topic #96 (0.010): 0.171*\"have\" + 0.122*\"you\" + 0.080*\"had\" + 0.052*\"if\" + 0.035*\"been\" + 0.024*\"international\" + 0.023*\"night\" + 0.021*\"dream\" + 0.018*\"would\" + 0.017*\"area\"\n",
      "INFO:gensim.models.ldamodel:topic #81 (0.010): 0.062*\"10\" + 0.047*\"windows\" + 0.042*\"problem\" + 0.026*\"words\" + 0.024*\"it\" + 0.023*\"explain\" + 0.023*\"solve\" + 0.021*\"does\" + 0.020*\"following\" + 0.019*\"memory\"\n",
      "INFO:gensim.models.ldamodel:topic #21 (0.010): 0.135*\"/\" + 0.061*\"exam\" + 0.054*\"math\" + 0.052*\"1\" + 0.043*\"]\" + 0.043*\"[\" + 0.033*\"x\" + 0.028*\"games\" + 0.028*\"\\\" + 0.028*\"gate\"\n",
      "INFO:gensim.models.ldamodel:topic #88 (0.010): 0.146*\"many\" + 0.066*\"years\" + 0.054*\"5\" + 0.036*\"dollar\" + 0.030*\"there\" + 0.022*\"per\" + 0.022*\"20\" + 0.022*\"so\" + 0.020*\"hours\" + 0.020*\"week\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.044199, rho=0.076923\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #175 = documents up to #352000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #176 = documents up to #354000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #17 (0.010): 0.054*\"energy\" + 0.045*\"believe\" + 0.039*\"god\" + 0.038*\"actually\" + 0.036*\"no\" + 0.035*\"if\" + 0.030*\"that\" + 0.030*\"there\" + 0.029*\"dark\" + 0.026*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic #83 (0.010): 0.059*\"experience\" + 0.044*\"level\" + 0.043*\"sites\" + 0.040*\"preparation\" + 0.033*\"photos\" + 0.022*\"dating\" + 0.020*\"tcs\" + 0.020*\"18\" + 0.019*\"planning\" + 0.017*\"like\"\n",
      "INFO:gensim.models.ldamodel:topic #40 (0.010): 0.165*\"much\" + 0.065*\"live\" + 0.052*\"during\" + 0.050*\"it\" + 0.048*\"does\" + 0.042*\"cost\" + 0.039*\"future\" + 0.030*\"behind\" + 0.027*\"so\" + 0.024*\"story\"\n",
      "INFO:gensim.models.ldamodel:topic #45 (0.010): 0.058*\"hard\" + 0.053*\"percent\" + 0.039*\"choose\" + 0.033*\"group\" + 0.031*\"single\" + 0.028*\"grow\" + 0.027*\"it\" + 0.026*\"eating\" + 0.025*\"loss\" + 0.023*\"paper\"\n",
      "INFO:gensim.models.ldamodel:topic #80 (0.010): 0.079*\"write\" + 0.068*\"card\" + 0.066*\"differences\" + 0.060*\"body\" + 0.043*\"program\" + 0.038*\"medical\" + 0.033*\"credit\" + 0.028*\"basic\" + 0.023*\"works\" + 0.022*\"pressure\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.042998, rho=0.076472\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #177 = documents up to #356000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #178 = documents up to #358000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #24 (0.010): 0.201*\")\" + 0.199*\"(\" + 0.082*\":\" + 0.073*\"better\" + 0.066*\"or\" + 0.041*\"which\" + 0.037*\"long\" + 0.019*\"quoted_item\" + 0.016*\"mba\" + 0.014*\"main\"\n",
      "INFO:gensim.models.ldamodel:topic #77 (0.010): 0.106*\"change\" + 0.053*\"around\" + 0.042*\"popular\" + 0.033*\"views\" + 0.028*\"decision\" + 0.026*\"news\" + 0.023*\"personality\" + 0.023*\"!\" + 0.022*\"let\" + 0.022*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic #63 (0.010): 0.083*\"feel\" + 0.068*\"sex\" + 0.067*\"person\" + 0.061*\"it\" + 0.054*\"like\" + 0.051*\"does\" + 0.038*\"earth\" + 0.034*\"having\" + 0.028*\"have\" + 0.027*\"be\"\n",
      "INFO:gensim.models.ldamodel:topic #87 (0.010): 0.059*\"parents\" + 0.054*\"date\" + 0.030*\"knowledge\" + 0.029*\"land\" + 0.024*\"with\" + 0.020*\"kids\" + 0.018*\"candidate\" + 0.016*\"my\" + 0.015*\"usb\" + 0.014*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.010): 0.128*\"someone\" + 0.065*\"but\" + 0.061*\"them\" + 0.060*\"you\" + 0.040*\"not\" + 0.036*\"if\" + 0.033*\"on\" + 0.029*\"when\" + 0.025*\"they\" + 0.025*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.043586, rho=0.076029\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #179 = documents up to #360000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #180 = documents up to #362000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.321*\"your\" + 0.116*\"you\" + 0.077*\"life\" + 0.040*\"school\" + 0.038*\"high\" + 0.030*\"favorite\" + 0.019*\"join\" + 0.013*\"was\" + 0.012*\"understand\" + 0.012*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic #96 (0.010): 0.181*\"have\" + 0.120*\"you\" + 0.079*\"had\" + 0.053*\"if\" + 0.035*\"been\" + 0.023*\"international\" + 0.023*\"night\" + 0.021*\"dream\" + 0.017*\"would\" + 0.017*\"area\"\n",
      "INFO:gensim.models.ldamodel:topic #63 (0.010): 0.083*\"feel\" + 0.068*\"sex\" + 0.068*\"person\" + 0.063*\"it\" + 0.053*\"like\" + 0.052*\"does\" + 0.037*\"earth\" + 0.033*\"having\" + 0.028*\"have\" + 0.027*\"be\"\n",
      "INFO:gensim.models.ldamodel:topic #30 (0.010): 0.294*\"make\" + 0.034*\"current\" + 0.033*\"happened\" + 0.032*\"degree\" + 0.028*\"full\" + 0.028*\"money\" + 0.027*\"you\" + 0.019*\"french\" + 0.018*\"master\" + 0.018*\"obama\"\n",
      "INFO:gensim.models.ldamodel:topic #92 (0.010): 0.147*\"become\" + 0.050*\"come\" + 0.041*\"create\" + 0.033*\"jobs\" + 0.033*\"an\" + 0.026*\"sleep\" + 0.026*\"from\" + 0.023*\"does\" + 0.022*\"cell\" + 0.020*\"those\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.041164, rho=0.075593\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #181 = documents up to #364000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #182 = documents up to #366000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.010): 0.164*\"learn\" + 0.143*\"start\" + 0.040*\"should\" + 0.038*\"best\" + 0.034*\"way\" + 0.031*\"technology\" + 0.029*\"python\" + 0.028*\"order\" + 0.023*\"idea\" + 0.020*\"learning\"\n",
      "INFO:gensim.models.ldamodel:topic #69 (0.010): 0.326*\"best\" + 0.259*\"which\" + 0.050*\"way\" + 0.032*\"country\" + 0.030*\"india\" + 0.020*\"laptop\" + 0.020*\"marketing\" + 0.018*\"test\" + 0.016*\"market\" + 0.016*\"course\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.320*\"your\" + 0.115*\"you\" + 0.078*\"life\" + 0.040*\"school\" + 0.037*\"high\" + 0.031*\"favorite\" + 0.019*\"join\" + 0.014*\"was\" + 0.012*\"understand\" + 0.012*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic #62 (0.010): 0.102*\"engineering\" + 0.053*\"university\" + 0.051*\"student\" + 0.047*\"getting\" + 0.040*\"an\" + 0.039*\"students\" + 0.027*\"civil\" + 0.027*\"post\" + 0.025*\"etc\" + 0.023*\"get\"\n",
      "INFO:gensim.models.ldamodel:topic #85 (0.010): 0.102*\".\" + 0.075*\"me\" + 0.068*\"am\" + 0.067*\"my\" + 0.042*\"want\" + 0.033*\"not\" + 0.032*\"he\" + 0.030*\"if\" + 0.029*\"should\" + 0.028*\"his\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.041317, rho=0.075165\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #183 = documents up to #368000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #184 = documents up to #370000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #63 (0.010): 0.083*\"feel\" + 0.068*\"sex\" + 0.067*\"person\" + 0.063*\"it\" + 0.054*\"like\" + 0.052*\"does\" + 0.038*\"earth\" + 0.033*\"having\" + 0.029*\"have\" + 0.026*\"be\"\n",
      "INFO:gensim.models.ldamodel:topic #78 (0.010): 0.181*\"money\" + 0.177*\"online\" + 0.072*\"earn\" + 0.034*\"available\" + 0.032*\"from\" + 0.023*\"colleges\" + 0.020*\"way\" + 0.017*\"save\" + 0.016*\"break\" + 0.015*\"cure\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.097*\"before\" + 0.095*\"over\" + 0.064*\"bing\" + 0.035*\"correct\" + 0.034*\"class\" + 0.028*\"short\" + 0.026*\"red\" + 0.024*\"structure\" + 0.021*\"because\" + 0.021*\"get\"\n",
      "INFO:gensim.models.ldamodel:topic #58 (0.010): 0.100*\"app\" + 0.068*\"web\" + 0.049*\"java\" + 0.043*\"development\" + 0.041*\"living\" + 0.039*\"search\" + 0.028*\"net\" + 0.027*\"developer\" + 0.026*\"an\" + 0.025*\"android\"\n",
      "INFO:gensim.models.ldamodel:topic #33 (0.010): 0.064*\"2017\" + 0.050*\"power\" + 0.047*\"music\" + 0.039*\"management\" + 0.036*\"you\" + 0.033*\"compared\" + 0.033*\"new\" + 0.032*\"move\" + 0.030*\"year\" + 0.027*\"field\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.039670, rho=0.074744\n",
      "INFO:gensim.models.ldamodel:-8.269 per-word bound, 308.5 perplexity estimate based on a held-out corpus of 2000 documents with 15020 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #185 = documents up to #372000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #90 (0.010): 0.122*\"2\" + 0.108*\"+\" + 0.091*\"c\" + 0.081*\"home\" + 0.037*\"foreign\" + 0.022*\"good\" + 0.022*\"d\" + 0.021*\"at\" + 0.020*\"n\" + 0.016*\"bring\"\n",
      "INFO:gensim.models.ldamodel:topic #24 (0.010): 0.198*\")\" + 0.197*\"(\" + 0.085*\":\" + 0.074*\"better\" + 0.067*\"or\" + 0.043*\"which\" + 0.036*\"long\" + 0.019*\"quoted_item\" + 0.017*\"mba\" + 0.013*\"main\"\n",
      "INFO:gensim.models.ldamodel:topic #98 (0.010): 0.097*\"its\" + 0.061*\"download\" + 0.045*\"site\" + 0.039*\"less\" + 0.032*\"form\" + 0.030*\"develop\" + 0.028*\"office\" + 0.024*\"charge\" + 0.017*\"from\" + 0.017*\"india\"\n",
      "INFO:gensim.models.ldamodel:topic #22 (0.010): 0.093*\"instagram\" + 0.087*\"see\" + 0.065*\"on\" + 0.055*\"hair\" + 0.053*\"youtube\" + 0.039*\"my\" + 0.026*\"who\" + 0.025*\"beautiful\" + 0.019*\"currently\" + 0.018*\"most\"\n",
      "INFO:gensim.models.ldamodel:topic #93 (0.010): 0.130*\"free\" + 0.034*\"also\" + 0.027*\"reading\" + 0.026*\"share\" + 0.025*\"allowed\" + 0.024*\"not\" + 0.023*\"be\" + 0.023*\"india\" + 0.022*\"attack\" + 0.021*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.040962, rho=0.074329\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #186 = documents up to #374000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #187 = documents up to #376000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #188 = documents up to #378000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #78 (0.010): 0.183*\"online\" + 0.181*\"money\" + 0.073*\"earn\" + 0.034*\"available\" + 0.032*\"from\" + 0.023*\"colleges\" + 0.019*\"way\" + 0.016*\"save\" + 0.016*\"break\" + 0.014*\"without\"\n",
      "INFO:gensim.models.ldamodel:topic #39 (0.010): 0.108*\"top\" + 0.078*\"own\" + 0.040*\"normal\" + 0.040*\"green\" + 0.038*\"my\" + 0.037*\"bollywood\" + 0.033*\"on\" + 0.033*\"page\" + 0.024*\"who\" + 0.023*\"viewed\"\n",
      "INFO:gensim.models.ldamodel:topic #84 (0.010): 0.098*\"book\" + 0.073*\"name\" + 0.055*\"tv\" + 0.043*\"series\" + 0.029*\"ias\" + 0.027*\"left\" + 0.025*\"my\" + 0.024*\"hire\" + 0.021*\"best\" + 0.020*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.319*\"your\" + 0.116*\"you\" + 0.083*\"life\" + 0.040*\"school\" + 0.037*\"high\" + 0.031*\"favorite\" + 0.018*\"join\" + 0.014*\"was\" + 0.012*\"did\" + 0.012*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic #15 (0.010): 0.120*\"we\" + 0.057*\"women\" + 0.053*\"our\" + 0.047*\"made\" + 0.043*\"men\" + 0.042*\"say\" + 0.041*\"now\" + 0.038*\"happens\" + 0.037*\"right\" + 0.034*\"china\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.038893, rho=0.073922\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #189 = documents up to #380000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #190 = documents up to #382000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #96 (0.010): 0.197*\"have\" + 0.118*\"you\" + 0.072*\"had\" + 0.051*\"if\" + 0.034*\"been\" + 0.024*\"international\" + 0.023*\"night\" + 0.021*\"dream\" + 0.016*\"area\" + 0.014*\"one\"\n",
      "INFO:gensim.models.ldamodel:topic #22 (0.010): 0.094*\"instagram\" + 0.086*\"see\" + 0.065*\"on\" + 0.058*\"hair\" + 0.053*\"youtube\" + 0.039*\"my\" + 0.026*\"who\" + 0.026*\"beautiful\" + 0.019*\"currently\" + 0.018*\"most\"\n",
      "INFO:gensim.models.ldamodel:topic #19 (0.010): 0.066*\"myself\" + 0.043*\"center\" + 0.040*\"drug\" + 0.040*\"alcohol\" + 0.038*\"value\" + 0.036*\"started\" + 0.033*\"mass\" + 0.032*\"near\" + 0.029*\"county\" + 0.026*\"rehab\"\n",
      "INFO:gensim.models.ldamodel:topic #47 (0.010): 0.134*\"does\" + 0.128*\"mean\" + 0.070*\"it\" + 0.036*\"when\" + 0.036*\"too\" + 0.029*\"call\" + 0.024*\"found\" + 0.022*\"you\" + 0.022*\"plan\" + 0.018*\"lot\"\n",
      "INFO:gensim.models.ldamodel:topic #53 (0.010): 0.151*\"system\" + 0.048*\"biggest\" + 0.043*\"operating\" + 0.038*\"similar\" + 0.026*\"device\" + 0.026*\"pain\" + 0.026*\"personal\" + 0.025*\"fake\" + 0.024*\"buying\" + 0.017*\"recent\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.036749, rho=0.073521\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #191 = documents up to #384000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #192 = documents up to #386000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #99 (0.010): 0.138*\"google\" + 0.098*\"just\" + 0.032*\"speak\" + 0.031*\"view\" + 0.024*\"won\" + 0.022*\"on\" + 0.021*\"here\" + 0.020*\"sbi\" + 0.016*\"specific\" + 0.016*\"they\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.202*\"my\" + 0.164*\"english\" + 0.117*\"improve\" + 0.036*\"7\" + 0.035*\"month\" + 0.029*\"should\" + 0.024*\"communication\" + 0.023*\"speaking\" + 0.017*\"mother\" + 0.013*\"one\"\n",
      "INFO:gensim.models.ldamodel:topic #33 (0.010): 0.065*\"2017\" + 0.055*\"power\" + 0.048*\"music\" + 0.039*\"management\" + 0.035*\"compared\" + 0.034*\"move\" + 0.032*\"new\" + 0.032*\"you\" + 0.030*\"year\" + 0.028*\"courses\"\n",
      "INFO:gensim.models.ldamodel:topic #59 (0.010): 0.128*\"were\" + 0.102*\"still\" + 0.036*\"amazon\" + 0.030*\"on\" + 0.029*\"send\" + 0.023*\"you\" + 0.023*\"did\" + 0.021*\"was\" + 0.020*\"that\" + 0.017*\"if\"\n",
      "INFO:gensim.models.ldamodel:topic #79 (0.010): 0.110*\"2016\" + 0.058*\"kind\" + 0.057*\"overcome\" + 0.028*\"cut\" + 0.027*\"fear\" + 0.025*\"expected\" + 0.024*\"beginner\" + 0.018*\"cutoff\" + 0.017*\"designer\" + 0.016*\"off\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.037579, rho=0.073127\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #193 = documents up to #388000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #194 = documents up to #390000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #42 (0.010): 0.103*\"different\" + 0.081*\"help\" + 0.068*\"companies\" + 0.046*\"culture\" + 0.045*\"white\" + 0.037*\"self\" + 0.037*\"songs\" + 0.032*\"gain\" + 0.023*\"like\" + 0.019*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #84 (0.010): 0.099*\"book\" + 0.069*\"name\" + 0.053*\"tv\" + 0.040*\"series\" + 0.027*\"ias\" + 0.025*\"my\" + 0.024*\"left\" + 0.024*\"hire\" + 0.020*\"an\" + 0.019*\"officer\"\n",
      "INFO:gensim.models.ldamodel:topic #58 (0.010): 0.102*\"app\" + 0.070*\"web\" + 0.051*\"java\" + 0.044*\"development\" + 0.040*\"living\" + 0.040*\"search\" + 0.028*\"developer\" + 0.027*\"an\" + 0.025*\"net\" + 0.025*\"android\"\n",
      "INFO:gensim.models.ldamodel:topic #91 (0.010): 0.066*\"days\" + 0.058*\"even\" + 0.055*\"with\" + 0.039*\"period\" + 0.038*\"deal\" + 0.036*\"pregnant\" + 0.034*\"get\" + 0.030*\"my\" + 0.023*\"you\" + 0.023*\"after\"\n",
      "INFO:gensim.models.ldamodel:topic #38 (0.010): 0.073*\"they\" + 0.072*\"new\" + 0.058*\"play\" + 0.048*\"looking\" + 0.047*\"universities\" + 0.040*\"from\" + 0.038*\"does\" + 0.035*\"never\" + 0.030*\"national\" + 0.023*\"recruit\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.036669, rho=0.072739\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #195 = documents up to #392000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #196 = documents up to #394000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.010): 0.069*\"every\" + 0.040*\"famous\" + 0.034*\"political\" + 0.030*\"capital\" + 0.023*\"towards\" + 0.023*\"systems\" + 0.023*\"trading\" + 0.020*\"cards\" + 0.019*\"voice\" + 0.017*\"moving\"\n",
      "INFO:gensim.models.ldamodel:topic #43 (0.010): 0.129*\"job\" + 0.074*\"through\" + 0.061*\"interview\" + 0.056*\"learning\" + 0.052*\"process\" + 0.047*\"making\" + 0.046*\"tips\" + 0.042*\"at\" + 0.041*\"some\" + 0.039*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic #22 (0.010): 0.092*\"instagram\" + 0.090*\"see\" + 0.065*\"on\" + 0.060*\"hair\" + 0.053*\"youtube\" + 0.037*\"my\" + 0.027*\"who\" + 0.025*\"beautiful\" + 0.020*\"currently\" + 0.018*\"most\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.106*\"ways\" + 0.075*\"get\" + 0.051*\"rid\" + 0.049*\"some\" + 0.033*\"face\" + 0.030*\"my\" + 0.029*\"on\" + 0.028*\"daily\" + 0.024*\"best\" + 0.023*\"impact\"\n",
      "INFO:gensim.models.ldamodel:topic #69 (0.010): 0.340*\"best\" + 0.256*\"which\" + 0.053*\"way\" + 0.031*\"country\" + 0.029*\"india\" + 0.022*\"laptop\" + 0.019*\"marketing\" + 0.018*\"test\" + 0.016*\"market\" + 0.016*\"course\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.038184, rho=0.072357\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #197 = documents up to #396000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #198 = documents up to #398000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #52 (0.010): 0.119*\"possible\" + 0.096*\"it\" + 0.056*\"career\" + 0.044*\"travel\" + 0.028*\"humans\" + 0.024*\"house\" + 0.022*\"options\" + 0.022*\"taking\" + 0.021*\"check\" + 0.021*\"chemical\"\n",
      "INFO:gensim.models.ldamodel:topic #53 (0.010): 0.146*\"system\" + 0.052*\"biggest\" + 0.040*\"operating\" + 0.038*\"similar\" + 0.027*\"fake\" + 0.027*\"pain\" + 0.026*\"device\" + 0.025*\"personal\" + 0.024*\"buying\" + 0.018*\"location\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.320*\"your\" + 0.118*\"you\" + 0.091*\"life\" + 0.039*\"school\" + 0.035*\"high\" + 0.029*\"favorite\" + 0.019*\"join\" + 0.015*\"was\" + 0.013*\"did\" + 0.012*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic #17 (0.010): 0.055*\"energy\" + 0.045*\"no\" + 0.044*\"believe\" + 0.038*\"god\" + 0.036*\"actually\" + 0.032*\"that\" + 0.032*\"if\" + 0.029*\"there\" + 0.029*\"dark\" + 0.028*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic #59 (0.010): 0.129*\"were\" + 0.103*\"still\" + 0.038*\"amazon\" + 0.030*\"send\" + 0.029*\"on\" + 0.023*\"you\" + 0.023*\"did\" + 0.020*\"was\" + 0.019*\"that\" + 0.017*\"not\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.035277, rho=0.071982\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #199 = documents up to #400000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #200 = documents up to #402000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #95 (0.010): 0.163*\"work\" + 0.072*\"does\" + 0.035*\"at\" + 0.034*\"apply\" + 0.031*\"bangalore\" + 0.031*\"differ\" + 0.029*\"4\" + 0.027*\"videos\" + 0.024*\"it\" + 0.022*\"marks\"\n",
      "INFO:gensim.models.ldamodel:topic #93 (0.010): 0.132*\"free\" + 0.040*\"also\" + 0.030*\"share\" + 0.025*\"be\" + 0.025*\"reading\" + 0.025*\"allowed\" + 0.024*\"india\" + 0.023*\"not\" + 0.022*\"attack\" + 0.021*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic #73 (0.010): 0.099*\"without\" + 0.067*\"safe\" + 0.063*\"service\" + 0.055*\"police\" + 0.050*\"hotel\" + 0.028*\"be\" + 0.025*\"screen\" + 0.023*\"couples\" + 0.022*\"moral\" + 0.021*\"staff\"\n",
      "INFO:gensim.models.ldamodel:topic #87 (0.010): 0.056*\"parents\" + 0.053*\"date\" + 0.031*\"knowledge\" + 0.026*\"land\" + 0.024*\"with\" + 0.022*\"kids\" + 0.016*\"usb\" + 0.016*\"candidate\" + 0.015*\"whose\" + 0.014*\"my\"\n",
      "INFO:gensim.models.ldamodel:topic #94 (0.010): 0.257*\"'\" + 0.076*\"meaning\" + 0.060*\"pakistan\" + 0.052*\"word\" + 0.029*\"hindi\" + 0.028*\"india\" + 0.028*\"universe\" + 0.019*\"minimum\" + 0.016*\"ticket\" + 0.014*\"quoted_item\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.035140, rho=0.071611\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #201 = documents up to #404000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #202 = documents up to #406000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #67 (0.010): 0.077*\"prepare\" + 0.062*\"water\" + 0.047*\"bank\" + 0.034*\"cat\" + 0.033*\"education\" + 0.032*\"mechanical\" + 0.030*\"should\" + 0.027*\"england\" + 0.022*\"invest\" + 0.020*\"coming\"\n",
      "INFO:gensim.models.ldamodel:topic #61 (0.010): 0.112*\"thing\" + 0.066*\"you\" + 0.038*\"demonetization\" + 0.036*\"that\" + 0.036*\"most\" + 0.036*\"given\" + 0.032*\"advantages\" + 0.026*\"disadvantages\" + 0.025*\"second\" + 0.024*\"calculate\"\n",
      "INFO:gensim.models.ldamodel:topic #60 (0.010): 0.097*\"trump\" + 0.071*\"take\" + 0.061*\"donald\" + 0.055*\"us\" + 0.054*\"will\" + 0.049*\"president\" + 0.041*\"clinton\" + 0.038*\"hillary\" + 0.032*\"win\" + 0.031*\"who\"\n",
      "INFO:gensim.models.ldamodel:topic #50 (0.010): 0.143*\"love\" + 0.128*\"used\" + 0.045*\"makes\" + 0.033*\"by\" + 0.032*\"fall\" + 0.031*\"on\" + 0.027*\"safety\" + 0.025*\"sentence\" + 0.024*\"proposed\" + 0.023*\"handling\"\n",
      "INFO:gensim.models.ldamodel:topic #52 (0.010): 0.122*\"possible\" + 0.097*\"it\" + 0.056*\"career\" + 0.045*\"travel\" + 0.028*\"humans\" + 0.024*\"house\" + 0.022*\"options\" + 0.022*\"check\" + 0.021*\"taking\" + 0.020*\"chemical\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.033489, rho=0.071247\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #203 = documents up to #408000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #204 = documents up to #410000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #96 (0.010): 0.232*\"have\" + 0.110*\"you\" + 0.068*\"had\" + 0.050*\"if\" + 0.033*\"been\" + 0.024*\"international\" + 0.021*\"night\" + 0.020*\"dream\" + 0.016*\"area\" + 0.014*\"not\"\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.010): 0.079*\"look\" + 0.048*\"currency\" + 0.047*\"note\" + 0.045*\"ban\" + 0.045*\"does\" + 0.035*\"like\" + 0.034*\"address\" + 0.023*\"corruption\" + 0.023*\"hp\" + 0.020*\"recovery\"\n",
      "INFO:gensim.models.ldamodel:topic #10 (0.010): 0.145*\"phone\" + 0.092*\"buy\" + 0.045*\"under\" + 0.028*\"my\" + 0.026*\"should\" + 0.025*\"benefits\" + 0.023*\"an\" + 0.023*\"6\" + 0.022*\"problems\" + 0.020*\"iq\"\n",
      "INFO:gensim.models.ldamodel:topic #92 (0.010): 0.145*\"become\" + 0.049*\"come\" + 0.041*\"create\" + 0.032*\"an\" + 0.029*\"jobs\" + 0.028*\"sleep\" + 0.025*\"from\" + 0.022*\"those\" + 0.022*\"cell\" + 0.021*\"drive\"\n",
      "INFO:gensim.models.ldamodel:topic #86 (0.010): 0.116*\"books\" + 0.078*\"read\" + 0.053*\"very\" + 0.043*\"fat\" + 0.043*\"best\" + 0.033*\"theory\" + 0.028*\"some\" + 0.028*\"you\" + 0.025*\"moment\" + 0.024*\"belly\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.032861, rho=0.070888\n",
      "INFO:gensim.models.ldamodel:-8.187 per-word bound, 291.5 perplexity estimate based on a held-out corpus of 2000 documents with 15427 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #205 = documents up to #412000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #56 (0.010): 0.061*\"some\" + 0.046*\"interesting\" + 0.043*\"about\" + 0.036*\"based\" + 0.035*\"facts\" + 0.033*\"australia\" + 0.033*\"known\" + 0.028*\"japanese\" + 0.027*\"model\" + 0.023*\"india\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.010): 0.227*\"where\" + 0.144*\"find\" + 0.040*\"get\" + 0.038*\"support\" + 0.024*\"times\" + 0.021*\"sim\" + 0.019*\"my\" + 0.016*\"religion\" + 0.016*\"jio\" + 0.016*\"out\"\n",
      "INFO:gensim.models.ldamodel:topic #78 (0.010): 0.187*\"money\" + 0.178*\"online\" + 0.076*\"earn\" + 0.034*\"available\" + 0.031*\"from\" + 0.023*\"colleges\" + 0.018*\"way\" + 0.017*\"easy\" + 0.016*\"india\" + 0.016*\"save\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.320*\"your\" + 0.116*\"you\" + 0.097*\"life\" + 0.039*\"school\" + 0.035*\"high\" + 0.028*\"favorite\" + 0.019*\"join\" + 0.015*\"was\" + 0.012*\"on\" + 0.011*\"most\"\n",
      "INFO:gensim.models.ldamodel:topic #63 (0.010): 0.082*\"feel\" + 0.072*\"person\" + 0.066*\"sex\" + 0.065*\"it\" + 0.054*\"like\" + 0.052*\"does\" + 0.040*\"earth\" + 0.034*\"having\" + 0.027*\"be\" + 0.026*\"have\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.033764, rho=0.070535\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #206 = documents up to #414000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #207 = documents up to #416000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #208 = documents up to #418000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.010): 0.087*\"my\" + 0.080*\"increase\" + 0.040*\"type\" + 0.037*\"traffic\" + 0.034*\"get\" + 0.034*\"height\" + 0.031*\"called\" + 0.031*\"does\" + 0.029*\"blog\" + 0.029*\"dog\"\n",
      "INFO:gensim.models.ldamodel:topic #13 (0.010): 0.048*\"control\" + 0.046*\"song\" + 0.046*\"ca\" + 0.040*\"california\" + 0.036*\"solar\" + 0.032*\"research\" + 0.031*\"provider\" + 0.031*\"healthy\" + 0.029*\"avoid\" + 0.026*\"good\"\n",
      "INFO:gensim.models.ldamodel:topic #78 (0.010): 0.187*\"money\" + 0.177*\"online\" + 0.076*\"earn\" + 0.035*\"available\" + 0.031*\"from\" + 0.022*\"colleges\" + 0.018*\"way\" + 0.018*\"easy\" + 0.016*\"india\" + 0.016*\"break\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.010): 0.068*\"every\" + 0.039*\"famous\" + 0.036*\"political\" + 0.027*\"capital\" + 0.023*\"systems\" + 0.023*\"towards\" + 0.021*\"trading\" + 0.021*\"cards\" + 0.016*\"voice\" + 0.016*\"india\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.319*\"your\" + 0.116*\"you\" + 0.098*\"life\" + 0.039*\"school\" + 0.035*\"high\" + 0.027*\"favorite\" + 0.019*\"join\" + 0.015*\"was\" + 0.011*\"on\" + 0.011*\"most\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.033328, rho=0.070186\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #209 = documents up to #420000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #210 = documents up to #422000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #36 (0.010): 0.119*\"year\" + 0.092*\"old\" + 0.064*\"it\" + 0.051*\"true\" + 0.037*\"salary\" + 0.034*\"worth\" + 0.034*\"that\" + 0.028*\"fast\" + 0.025*\"must\" + 0.023*\"effective\"\n",
      "INFO:gensim.models.ldamodel:topic #25 (0.010): 0.051*\"girl\" + 0.045*\"tell\" + 0.040*\"eat\" + 0.039*\"friends\" + 0.038*\"guy\" + 0.035*\"that\" + 0.033*\"mind\" + 0.031*\"woman\" + 0.030*\"common\" + 0.029*\"not\"\n",
      "INFO:gensim.models.ldamodel:topic #45 (0.010): 0.055*\"percent\" + 0.052*\"hard\" + 0.045*\"choose\" + 0.033*\"group\" + 0.031*\"single\" + 0.030*\"eating\" + 0.027*\"it\" + 0.025*\"grow\" + 0.023*\"front\" + 0.023*\"paper\"\n",
      "INFO:gensim.models.ldamodel:topic #41 (0.010): 0.061*\"human\" + 0.061*\"state\" + 0.058*\"video\" + 0.053*\"considered\" + 0.038*\"terms\" + 0.037*\"point\" + 0.032*\"worst\" + 0.031*\"matter\" + 0.027*\"inside\" + 0.027*\"store\"\n",
      "INFO:gensim.models.ldamodel:topic #91 (0.010): 0.062*\"days\" + 0.062*\"even\" + 0.055*\"with\" + 0.040*\"period\" + 0.039*\"deal\" + 0.036*\"pregnant\" + 0.033*\"get\" + 0.031*\"my\" + 0.024*\"after\" + 0.022*\"depression\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.031833, rho=0.069843\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #211 = documents up to #424000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #212 = documents up to #426000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #73 (0.010): 0.119*\"without\" + 0.065*\"safe\" + 0.062*\"service\" + 0.051*\"police\" + 0.045*\"hotel\" + 0.026*\"be\" + 0.023*\"screen\" + 0.020*\"couples\" + 0.019*\"moral\" + 0.018*\"staff\"\n",
      "INFO:gensim.models.ldamodel:topic #64 (0.010): 0.118*\"up\" + 0.092*\"need\" + 0.040*\"got\" + 0.039*\"keep\" + 0.037*\"pay\" + 0.034*\"cause\" + 0.029*\"does\" + 0.022*\"get\" + 0.019*\"chance\" + 0.018*\"muslim\"\n",
      "INFO:gensim.models.ldamodel:topic #57 (0.010): 0.467*\"\"\" + 0.057*\"examples\" + 0.054*\"important\" + 0.050*\"some\" + 0.019*\"side\" + 0.016*\"you\" + 0.014*\"word\" + 0.012*\"dead\" + 0.010*\"quoted_item\" + 0.008*\"does\"\n",
      "INFO:gensim.models.ldamodel:topic #62 (0.010): 0.105*\"engineering\" + 0.056*\"student\" + 0.050*\"university\" + 0.050*\"getting\" + 0.042*\"an\" + 0.035*\"students\" + 0.029*\"civil\" + 0.028*\"post\" + 0.025*\"etc\" + 0.023*\"get\"\n",
      "INFO:gensim.models.ldamodel:topic #68 (0.010): 0.112*\"language\" + 0.101*\"programming\" + 0.079*\"website\" + 0.041*\"open\" + 0.040*\"learn\" + 0.037*\"hack\" + 0.031*\"cons\" + 0.030*\"low\" + 0.030*\"pros\" + 0.028*\"best\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.031761, rho=0.069505\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #213 = documents up to #428000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #214 = documents up to #430000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #76 (0.010): 0.065*\"watch\" + 0.049*\"something\" + 0.042*\"seen\" + 0.039*\"you\" + 0.028*\"tax\" + 0.023*\"movies\" + 0.022*\"have\" + 0.021*\"on\" + 0.021*\"season\" + 0.019*\"interest\"\n",
      "INFO:gensim.models.ldamodel:topic #82 (0.010): 0.086*\"bad\" + 0.077*\"two\" + 0.059*\"game\" + 0.030*\"blood\" + 0.029*\"you\" + 0.028*\"it\" + 0.027*\"or\" + 0.026*\"that\" + 0.025*\"fix\" + 0.019*\"try\"\n",
      "INFO:gensim.models.ldamodel:topic #98 (0.010): 0.095*\"its\" + 0.053*\"download\" + 0.045*\"site\" + 0.036*\"form\" + 0.035*\"less\" + 0.031*\"develop\" + 0.029*\"office\" + 0.024*\"charge\" + 0.019*\"india\" + 0.018*\"from\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.010): 0.136*\"someone\" + 0.070*\"them\" + 0.065*\"but\" + 0.062*\"you\" + 0.042*\"not\" + 0.036*\"if\" + 0.032*\"on\" + 0.028*\"when\" + 0.026*\"they\" + 0.025*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic #99 (0.010): 0.142*\"google\" + 0.104*\"just\" + 0.036*\"speak\" + 0.031*\"view\" + 0.023*\"on\" + 0.022*\"won\" + 0.020*\"sbi\" + 0.020*\"here\" + 0.017*\"specific\" + 0.015*\"they\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.031038, rho=0.069171\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #215 = documents up to #432000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #216 = documents up to #434000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #64 (0.010): 0.122*\"up\" + 0.091*\"need\" + 0.041*\"keep\" + 0.040*\"got\" + 0.039*\"pay\" + 0.033*\"cause\" + 0.030*\"does\" + 0.021*\"get\" + 0.018*\"chance\" + 0.018*\"meet\"\n",
      "INFO:gensim.models.ldamodel:topic #16 (0.010): 0.110*\"college\" + 0.060*\"chinese\" + 0.048*\"major\" + 0.043*\"reason\" + 0.034*\"that\" + 0.029*\"everything\" + 0.026*\"away\" + 0.026*\"contact\" + 0.025*\"changed\" + 0.020*\"percentage\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.010): 0.194*\"would\" + 0.139*\"if\" + 0.068*\"be\" + 0.044*\"you\" + 0.041*\"happen\" + 0.033*\"car\" + 0.028*\"will\" + 0.023*\"then\" + 0.020*\"it\" + 0.016*\"light\"\n",
      "INFO:gensim.models.ldamodel:topic #65 (0.010): 0.058*\"social\" + 0.056*\"android\" + 0.051*\"working\" + 0.050*\"end\" + 0.041*\"always\" + 0.041*\"whatsapp\" + 0.038*\"today\" + 0.030*\"on\" + 0.029*\"ideas\" + 0.029*\"media\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.010): 0.091*\"my\" + 0.080*\"increase\" + 0.040*\"type\" + 0.035*\"traffic\" + 0.035*\"get\" + 0.035*\"height\" + 0.031*\"called\" + 0.030*\"dog\" + 0.029*\"does\" + 0.029*\"blog\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.031017, rho=0.068843\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #217 = documents up to #436000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #218 = documents up to #438000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #86 (0.010): 0.113*\"books\" + 0.077*\"read\" + 0.054*\"very\" + 0.045*\"fat\" + 0.038*\"best\" + 0.035*\"theory\" + 0.030*\"some\" + 0.027*\"you\" + 0.025*\"moment\" + 0.023*\"belly\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.010): 0.090*\"my\" + 0.081*\"increase\" + 0.040*\"type\" + 0.036*\"traffic\" + 0.036*\"get\" + 0.036*\"height\" + 0.031*\"called\" + 0.030*\"dog\" + 0.030*\"does\" + 0.028*\"blog\"\n",
      "INFO:gensim.models.ldamodel:topic #65 (0.010): 0.058*\"social\" + 0.054*\"android\" + 0.052*\"working\" + 0.051*\"end\" + 0.041*\"always\" + 0.040*\"whatsapp\" + 0.037*\"today\" + 0.030*\"on\" + 0.029*\"ideas\" + 0.029*\"media\"\n",
      "INFO:gensim.models.ldamodel:topic #94 (0.010): 0.254*\"'\" + 0.075*\"meaning\" + 0.061*\"pakistan\" + 0.055*\"word\" + 0.031*\"hindi\" + 0.028*\"universe\" + 0.026*\"india\" + 0.019*\"minimum\" + 0.015*\"quoted_item\" + 0.015*\"certificate\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.061*\"real\" + 0.054*\"average\" + 0.050*\"america\" + 0.049*\"food\" + 0.047*\"non\" + 0.046*\"age\" + 0.034*\"able\" + 0.027*\"child\" + 0.025*\"ones\" + 0.025*\"100\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.029031, rho=0.068519\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #219 = documents up to #440000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #220 = documents up to #442000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #46 (0.010): 0.052*\"reduce\" + 0.052*\"air\" + 0.048*\"family\" + 0.047*\"apps\" + 0.037*\"uber\" + 0.029*\"or\" + 0.026*\"my\" + 0.026*\"special\" + 0.017*\"devices\" + 0.017*\"with\"\n",
      "INFO:gensim.models.ldamodel:topic #76 (0.010): 0.068*\"watch\" + 0.052*\"something\" + 0.042*\"seen\" + 0.039*\"you\" + 0.028*\"tax\" + 0.022*\"movies\" + 0.022*\"on\" + 0.021*\"season\" + 0.021*\"an\" + 0.019*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic #59 (0.010): 0.131*\"were\" + 0.104*\"still\" + 0.036*\"amazon\" + 0.031*\"send\" + 0.029*\"on\" + 0.023*\"did\" + 0.023*\"you\" + 0.022*\"that\" + 0.020*\"was\" + 0.017*\"touch\"\n",
      "INFO:gensim.models.ldamodel:topic #92 (0.010): 0.151*\"become\" + 0.051*\"come\" + 0.040*\"create\" + 0.034*\"an\" + 0.031*\"jobs\" + 0.028*\"sleep\" + 0.026*\"from\" + 0.023*\"drive\" + 0.023*\"cell\" + 0.022*\"those\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.010): 0.090*\"my\" + 0.081*\"increase\" + 0.039*\"type\" + 0.037*\"height\" + 0.035*\"traffic\" + 0.035*\"get\" + 0.030*\"called\" + 0.030*\"dog\" + 0.030*\"does\" + 0.028*\"blog\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.029718, rho=0.068199\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #221 = documents up to #444000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #222 = documents up to #446000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.010): 0.115*\"my\" + 0.085*\"account\" + 0.071*\"facebook\" + 0.039*\"password\" + 0.036*\"email\" + 0.030*\"gmail\" + 0.026*\"delete\" + 0.025*\"from\" + 0.024*\"recover\" + 0.020*\"lost\"\n",
      "INFO:gensim.models.ldamodel:topic #70 (0.010): 0.166*\"quora\" + 0.105*\"on\" + 0.067*\"questions\" + 0.048*\"question\" + 0.040*\"ask\" + 0.030*\"answer\" + 0.028*\"people\" + 0.028*\"my\" + 0.025*\"effects\" + 0.021*\"as\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.235*\"my\" + 0.153*\"english\" + 0.111*\"improve\" + 0.037*\"should\" + 0.036*\"month\" + 0.035*\"7\" + 0.021*\"communication\" + 0.021*\"speaking\" + 0.016*\"mother\" + 0.012*\"material\"\n",
      "INFO:gensim.models.ldamodel:topic #87 (0.010): 0.059*\"parents\" + 0.052*\"date\" + 0.030*\"knowledge\" + 0.026*\"with\" + 0.025*\"land\" + 0.023*\"kids\" + 0.018*\"candidate\" + 0.017*\"usb\" + 0.015*\"performance\" + 0.014*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic #93 (0.010): 0.138*\"free\" + 0.039*\"also\" + 0.032*\"share\" + 0.028*\"reading\" + 0.026*\"be\" + 0.024*\"allowed\" + 0.023*\"not\" + 0.022*\"on\" + 0.021*\"attack\" + 0.020*\"india\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.027525, rho=0.067884\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #223 = documents up to #448000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #224 = documents up to #450000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #87 (0.010): 0.059*\"parents\" + 0.050*\"date\" + 0.029*\"knowledge\" + 0.026*\"land\" + 0.026*\"with\" + 0.022*\"kids\" + 0.018*\"usb\" + 0.018*\"candidate\" + 0.016*\"performance\" + 0.014*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.010): 0.232*\"where\" + 0.145*\"find\" + 0.044*\"get\" + 0.037*\"support\" + 0.022*\"times\" + 0.020*\"sim\" + 0.019*\"my\" + 0.017*\"quickly\" + 0.017*\"religion\" + 0.016*\"out\"\n",
      "INFO:gensim.models.ldamodel:topic #60 (0.010): 0.096*\"trump\" + 0.070*\"take\" + 0.063*\"us\" + 0.060*\"donald\" + 0.055*\"will\" + 0.050*\"president\" + 0.042*\"clinton\" + 0.039*\"hillary\" + 0.035*\"win\" + 0.032*\"who\"\n",
      "INFO:gensim.models.ldamodel:topic #69 (0.010): 0.369*\"best\" + 0.238*\"which\" + 0.063*\"way\" + 0.029*\"country\" + 0.028*\"india\" + 0.020*\"laptop\" + 0.018*\"test\" + 0.017*\"marketing\" + 0.016*\"market\" + 0.014*\"course\"\n",
      "INFO:gensim.models.ldamodel:topic #29 (0.010): 0.055*\"build\" + 0.053*\"run\" + 0.048*\"death\" + 0.039*\"security\" + 0.039*\"suicide\" + 0.026*\"least\" + 0.025*\"dogs\" + 0.023*\"commit\" + 0.019*\"flat\" + 0.019*\"way\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.027443, rho=0.067574\n",
      "INFO:gensim.models.ldamodel:-8.155 per-word bound, 284.9 perplexity estimate based on a held-out corpus of 2000 documents with 15524 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #225 = documents up to #452000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #79 (0.010): 0.140*\"2016\" + 0.064*\"kind\" + 0.049*\"overcome\" + 0.029*\"fear\" + 0.028*\"beginner\" + 0.027*\"cut\" + 0.022*\"expected\" + 0.017*\"off\" + 0.016*\"designer\" + 0.015*\"cutoff\"\n",
      "INFO:gensim.models.ldamodel:topic #37 (0.010): 0.231*\"has\" + 0.050*\"been\" + 0.046*\"next\" + 0.035*\"apple\" + 0.025*\"size\" + 0.023*\"set\" + 0.022*\"often\" + 0.021*\"quality\" + 0.019*\"americans\" + 0.019*\"penis\"\n",
      "INFO:gensim.models.ldamodel:topic #47 (0.010): 0.132*\"does\" + 0.126*\"mean\" + 0.071*\"it\" + 0.041*\"too\" + 0.035*\"when\" + 0.030*\"call\" + 0.028*\"plan\" + 0.024*\"found\" + 0.023*\"you\" + 0.020*\"says\"\n",
      "INFO:gensim.models.ldamodel:topic #78 (0.010): 0.185*\"money\" + 0.171*\"online\" + 0.077*\"earn\" + 0.036*\"available\" + 0.030*\"from\" + 0.024*\"colleges\" + 0.021*\"easy\" + 0.018*\"way\" + 0.017*\"break\" + 0.017*\"save\"\n",
      "INFO:gensim.models.ldamodel:topic #76 (0.010): 0.071*\"watch\" + 0.056*\"something\" + 0.044*\"seen\" + 0.037*\"you\" + 0.027*\"tax\" + 0.024*\"movies\" + 0.022*\"on\" + 0.022*\"season\" + 0.020*\"an\" + 0.020*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.027982, rho=0.067267\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #226 = documents up to #454000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #227 = documents up to #456000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #228 = documents up to #458000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #21 (0.010): 0.217*\"/\" + 0.056*\"1\" + 0.052*\"math\" + 0.052*\"exam\" + 0.043*\"[\" + 0.043*\"]\" + 0.035*\"x\" + 0.028*\"\\\" + 0.027*\"games\" + 0.024*\"=\"\n",
      "INFO:gensim.models.ldamodel:topic #93 (0.010): 0.137*\"free\" + 0.041*\"also\" + 0.033*\"share\" + 0.028*\"be\" + 0.026*\"reading\" + 0.025*\"allowed\" + 0.025*\"not\" + 0.022*\"on\" + 0.020*\"india\" + 0.019*\"attack\"\n",
      "INFO:gensim.models.ldamodel:topic #85 (0.010): 0.113*\".\" + 0.074*\"me\" + 0.074*\"am\" + 0.069*\"my\" + 0.041*\"want\" + 0.035*\"he\" + 0.035*\"not\" + 0.029*\"should\" + 0.028*\"his\" + 0.028*\"her\"\n",
      "INFO:gensim.models.ldamodel:topic #94 (0.010): 0.246*\"'\" + 0.074*\"meaning\" + 0.062*\"word\" + 0.062*\"pakistan\" + 0.029*\"hindi\" + 0.028*\"universe\" + 0.026*\"india\" + 0.020*\"minimum\" + 0.014*\"ticket\" + 0.014*\"quoted_item\"\n",
      "INFO:gensim.models.ldamodel:topic #22 (0.010): 0.094*\"see\" + 0.090*\"instagram\" + 0.064*\"hair\" + 0.062*\"on\" + 0.057*\"youtube\" + 0.040*\"my\" + 0.026*\"who\" + 0.024*\"beautiful\" + 0.021*\"currently\" + 0.018*\"most\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.027288, rho=0.066965\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #229 = documents up to #460000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #230 = documents up to #462000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.249*\"my\" + 0.155*\"english\" + 0.113*\"improve\" + 0.037*\"should\" + 0.035*\"month\" + 0.035*\"7\" + 0.021*\"communication\" + 0.019*\"speaking\" + 0.017*\"mother\" + 0.012*\"material\"\n",
      "INFO:gensim.models.ldamodel:topic #93 (0.010): 0.138*\"free\" + 0.040*\"also\" + 0.033*\"share\" + 0.028*\"be\" + 0.026*\"reading\" + 0.025*\"allowed\" + 0.024*\"not\" + 0.021*\"on\" + 0.020*\"india\" + 0.019*\"attack\"\n",
      "INFO:gensim.models.ldamodel:topic #22 (0.010): 0.094*\"see\" + 0.090*\"instagram\" + 0.065*\"hair\" + 0.061*\"on\" + 0.057*\"youtube\" + 0.041*\"my\" + 0.026*\"who\" + 0.023*\"beautiful\" + 0.021*\"currently\" + 0.018*\"most\"\n",
      "INFO:gensim.models.ldamodel:topic #98 (0.010): 0.092*\"its\" + 0.060*\"download\" + 0.045*\"site\" + 0.036*\"less\" + 0.035*\"form\" + 0.033*\"develop\" + 0.025*\"office\" + 0.022*\"charge\" + 0.019*\"from\" + 0.018*\"india\"\n",
      "INFO:gensim.models.ldamodel:topic #55 (0.010): 0.102*\"number\" + 0.059*\"tech\" + 0.045*\"list\" + 0.037*\"remove\" + 0.032*\"m\" + 0.030*\"from\" + 0.028*\"exactly\" + 0.022*\"after\" + 0.021*\"father\" + 0.018*\"does\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.025781, rho=0.066667\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #231 = documents up to #464000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #232 = documents up to #466000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #76 (0.010): 0.075*\"watch\" + 0.056*\"something\" + 0.043*\"seen\" + 0.037*\"you\" + 0.028*\"tax\" + 0.024*\"movies\" + 0.022*\"on\" + 0.022*\"an\" + 0.021*\"season\" + 0.020*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic #37 (0.010): 0.229*\"has\" + 0.053*\"been\" + 0.046*\"next\" + 0.036*\"apple\" + 0.025*\"size\" + 0.023*\"set\" + 0.023*\"often\" + 0.021*\"penis\" + 0.021*\"americans\" + 0.020*\"quality\"\n",
      "INFO:gensim.models.ldamodel:topic #47 (0.010): 0.133*\"does\" + 0.126*\"mean\" + 0.071*\"it\" + 0.041*\"too\" + 0.036*\"when\" + 0.029*\"call\" + 0.028*\"plan\" + 0.024*\"found\" + 0.022*\"you\" + 0.020*\"says\"\n",
      "INFO:gensim.models.ldamodel:topic #23 (0.010): 0.142*\"world\" + 0.077*\"war\" + 0.058*\"3\" + 0.046*\"mobile\" + 0.042*\"countries\" + 0.037*\"off\" + 0.026*\"successful\" + 0.022*\"who\" + 0.020*\"turn\" + 0.019*\"british\"\n",
      "INFO:gensim.models.ldamodel:topic #97 (0.010): 0.161*\"more\" + 0.146*\"than\" + 0.066*\"study\" + 0.055*\"give\" + 0.030*\"or\" + 0.021*\"germany\" + 0.020*\"2015\" + 0.016*\"please\" + 0.016*\"one\" + 0.016*\"exams\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.024794, rho=0.066372\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #233 = documents up to #468000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #234 = documents up to #470000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #62 (0.010): 0.098*\"engineering\" + 0.056*\"student\" + 0.056*\"getting\" + 0.050*\"university\" + 0.040*\"an\" + 0.035*\"students\" + 0.030*\"civil\" + 0.030*\"post\" + 0.026*\"after\" + 0.023*\"etc\"\n",
      "INFO:gensim.models.ldamodel:topic #76 (0.010): 0.075*\"watch\" + 0.056*\"something\" + 0.044*\"seen\" + 0.038*\"you\" + 0.027*\"tax\" + 0.024*\"movies\" + 0.023*\"on\" + 0.022*\"an\" + 0.021*\"season\" + 0.020*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.010): 0.238*\"where\" + 0.142*\"find\" + 0.044*\"get\" + 0.036*\"support\" + 0.022*\"times\" + 0.021*\"sim\" + 0.020*\"my\" + 0.018*\"quickly\" + 0.016*\"religion\" + 0.015*\"jio\"\n",
      "INFO:gensim.models.ldamodel:topic #58 (0.010): 0.099*\"app\" + 0.072*\"web\" + 0.058*\"java\" + 0.045*\"development\" + 0.040*\"living\" + 0.039*\"search\" + 0.037*\"using\" + 0.029*\"android\" + 0.029*\"developer\" + 0.025*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #46 (0.010): 0.053*\"family\" + 0.051*\"air\" + 0.050*\"reduce\" + 0.045*\"apps\" + 0.036*\"uber\" + 0.029*\"or\" + 0.025*\"special\" + 0.025*\"my\" + 0.016*\"convince\" + 0.016*\"with\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.024909, rho=0.066082\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #235 = documents up to #472000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #236 = documents up to #474000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #22 (0.010): 0.098*\"see\" + 0.093*\"instagram\" + 0.062*\"hair\" + 0.061*\"on\" + 0.057*\"youtube\" + 0.041*\"my\" + 0.027*\"who\" + 0.021*\"beautiful\" + 0.021*\"currently\" + 0.017*\"reset\"\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.010): 0.116*\"my\" + 0.088*\"account\" + 0.072*\"facebook\" + 0.039*\"password\" + 0.035*\"email\" + 0.032*\"gmail\" + 0.027*\"from\" + 0.026*\"delete\" + 0.025*\"recover\" + 0.020*\"lost\"\n",
      "INFO:gensim.models.ldamodel:topic #18 (0.010): 0.201*\"time\" + 0.083*\"business\" + 0.056*\"same\" + 0.048*\"back\" + 0.027*\"it\" + 0.026*\"instead\" + 0.022*\"at\" + 0.020*\"12\" + 0.019*\"physics\" + 0.019*\"my\"\n",
      "INFO:gensim.models.ldamodel:topic #16 (0.010): 0.109*\"college\" + 0.061*\"chinese\" + 0.049*\"major\" + 0.043*\"reason\" + 0.035*\"that\" + 0.029*\"everything\" + 0.028*\"contact\" + 0.027*\"away\" + 0.026*\"changed\" + 0.021*\"percentage\"\n",
      "INFO:gensim.models.ldamodel:topic #44 (0.010): 0.197*\"about\" + 0.159*\"you\" + 0.119*\"think\" + 0.059*\"stop\" + 0.049*\"people\" + 0.037*\"know\" + 0.027*\"that\" + 0.021*\"last\" + 0.018*\"not\" + 0.017*\"indians\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.023840, rho=0.065795\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #237 = documents up to #476000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #238 = documents up to #478000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #54 (0.010): 0.116*\"weight\" + 0.115*\"being\" + 0.102*\"lose\" + 0.055*\"man\" + 0.039*\"die\" + 0.033*\"websites\" + 0.027*\"way\" + 0.025*\"easiest\" + 0.023*\"you\" + 0.019*\"50\"\n",
      "INFO:gensim.models.ldamodel:topic #67 (0.010): 0.079*\"prepare\" + 0.066*\"water\" + 0.050*\"bank\" + 0.033*\"cat\" + 0.032*\"mechanical\" + 0.031*\"education\" + 0.030*\"england\" + 0.029*\"should\" + 0.026*\"invest\" + 0.022*\"again\"\n",
      "INFO:gensim.models.ldamodel:topic #63 (0.010): 0.096*\"feel\" + 0.073*\"person\" + 0.073*\"it\" + 0.065*\"sex\" + 0.061*\"like\" + 0.052*\"does\" + 0.044*\"earth\" + 0.034*\"having\" + 0.030*\"be\" + 0.023*\"purpose\"\n",
      "INFO:gensim.models.ldamodel:topic #66 (0.010): 0.169*\"ever\" + 0.076*\"have\" + 0.076*\"you\" + 0.059*\"done\" + 0.041*\"best\" + 0.032*\"space\" + 0.027*\"coaching\" + 0.026*\"institute\" + 0.024*\"training\" + 0.018*\"some\"\n",
      "INFO:gensim.models.ldamodel:topic #44 (0.010): 0.195*\"about\" + 0.159*\"you\" + 0.117*\"think\" + 0.059*\"stop\" + 0.048*\"people\" + 0.037*\"know\" + 0.027*\"that\" + 0.022*\"last\" + 0.018*\"not\" + 0.017*\"indians\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.024006, rho=0.065512\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #239 = documents up to #480000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #240 = documents up to #482000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #25 (0.010): 0.052*\"girl\" + 0.048*\"tell\" + 0.045*\"guy\" + 0.045*\"friends\" + 0.039*\"eat\" + 0.033*\"that\" + 0.032*\"mind\" + 0.031*\"woman\" + 0.030*\"american\" + 0.029*\"not\"\n",
      "INFO:gensim.models.ldamodel:topic #63 (0.010): 0.096*\"feel\" + 0.074*\"person\" + 0.072*\"it\" + 0.063*\"sex\" + 0.062*\"like\" + 0.052*\"does\" + 0.043*\"earth\" + 0.034*\"having\" + 0.032*\"be\" + 0.023*\"purpose\"\n",
      "INFO:gensim.models.ldamodel:topic #74 (0.010): 0.043*\"star\" + 0.041*\"industry\" + 0.040*\"does\" + 0.034*\"option\" + 0.032*\"moon\" + 0.031*\"sun\" + 0.026*\"sound\" + 0.024*\"gravity\" + 0.022*\"wars\" + 0.018*\"stand\"\n",
      "INFO:gensim.models.ldamodel:topic #32 (0.010): 0.137*\"really\" + 0.058*\"exist\" + 0.036*\"hate\" + 0.036*\"does\" + 0.026*\"that\" + 0.024*\"people\" + 0.024*\"once\" + 0.021*\"amount\" + 0.019*\"there\" + 0.019*\"evidence\"\n",
      "INFO:gensim.models.ldamodel:topic #81 (0.010): 0.066*\"10\" + 0.051*\"windows\" + 0.044*\"problem\" + 0.029*\"solve\" + 0.024*\"it\" + 0.023*\"words\" + 0.023*\"does\" + 0.022*\"following\" + 0.021*\"explain\" + 0.020*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.023127, rho=0.065233\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #241 = documents up to #484000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #242 = documents up to #486000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.010): 0.172*\"learn\" + 0.165*\"start\" + 0.047*\"should\" + 0.031*\"technology\" + 0.029*\"order\" + 0.029*\"idea\" + 0.026*\"python\" + 0.024*\"sell\" + 0.022*\"with\" + 0.022*\"enough\"\n",
      "INFO:gensim.models.ldamodel:topic #66 (0.010): 0.174*\"ever\" + 0.076*\"have\" + 0.075*\"you\" + 0.056*\"done\" + 0.041*\"best\" + 0.034*\"space\" + 0.028*\"coaching\" + 0.026*\"institute\" + 0.024*\"training\" + 0.018*\"some\"\n",
      "INFO:gensim.models.ldamodel:topic #44 (0.010): 0.199*\"about\" + 0.158*\"you\" + 0.117*\"think\" + 0.057*\"stop\" + 0.049*\"people\" + 0.038*\"know\" + 0.027*\"that\" + 0.022*\"last\" + 0.018*\"not\" + 0.017*\"indians\"\n",
      "INFO:gensim.models.ldamodel:topic #38 (0.010): 0.121*\"new\" + 0.112*\"they\" + 0.057*\"play\" + 0.045*\"looking\" + 0.043*\"universities\" + 0.041*\"from\" + 0.038*\"does\" + 0.031*\"never\" + 0.022*\"national\" + 0.022*\"recruit\"\n",
      "INFO:gensim.models.ldamodel:topic #39 (0.010): 0.106*\"top\" + 0.085*\"own\" + 0.045*\"normal\" + 0.036*\"green\" + 0.035*\"my\" + 0.033*\"bollywood\" + 0.033*\"page\" + 0.030*\"on\" + 0.026*\"who\" + 0.024*\"hollywood\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.023759, rho=0.064957\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #243 = documents up to #488000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #244 = documents up to #490000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #15 (0.010): 0.179*\"we\" + 0.052*\"our\" + 0.051*\"women\" + 0.046*\"made\" + 0.042*\"say\" + 0.041*\"men\" + 0.040*\"now\" + 0.038*\"china\" + 0.038*\"right\" + 0.034*\"happens\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.010): 0.135*\"someone\" + 0.074*\"them\" + 0.066*\"but\" + 0.064*\"you\" + 0.044*\"not\" + 0.039*\"if\" + 0.033*\"on\" + 0.026*\"when\" + 0.026*\"it\" + 0.024*\"they\"\n",
      "INFO:gensim.models.ldamodel:topic #82 (0.010): 0.091*\"bad\" + 0.078*\"two\" + 0.061*\"game\" + 0.029*\"it\" + 0.028*\"you\" + 0.025*\"blood\" + 0.025*\"that\" + 0.025*\"fix\" + 0.025*\"or\" + 0.020*\"try\"\n",
      "INFO:gensim.models.ldamodel:topic #68 (0.010): 0.110*\"language\" + 0.104*\"programming\" + 0.083*\"website\" + 0.041*\"open\" + 0.041*\"hack\" + 0.041*\"learn\" + 0.028*\"low\" + 0.027*\"cons\" + 0.027*\"pros\" + 0.027*\"languages\"\n",
      "INFO:gensim.models.ldamodel:topic #67 (0.010): 0.079*\"prepare\" + 0.064*\"water\" + 0.050*\"bank\" + 0.035*\"mechanical\" + 0.032*\"cat\" + 0.030*\"england\" + 0.030*\"education\" + 0.028*\"should\" + 0.025*\"invest\" + 0.022*\"again\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.022584, rho=0.064685\n",
      "INFO:gensim.models.ldamodel:-8.128 per-word bound, 279.7 perplexity estimate based on a held-out corpus of 2000 documents with 15944 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #245 = documents up to #492000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.010): 0.127*\"go\" + 0.047*\"skills\" + 0.039*\"writing\" + 0.036*\"show\" + 0.035*\"stay\" + 0.030*\"causes\" + 0.028*\"wear\" + 0.026*\"required\" + 0.025*\"pro\" + 0.021*\"pokemon\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.010): 0.070*\"every\" + 0.040*\"famous\" + 0.032*\"political\" + 0.027*\"capital\" + 0.027*\"towards\" + 0.023*\"systems\" + 0.021*\"cards\" + 0.021*\"trading\" + 0.019*\"voice\" + 0.017*\"iii\"\n",
      "INFO:gensim.models.ldamodel:topic #39 (0.010): 0.104*\"top\" + 0.089*\"own\" + 0.046*\"normal\" + 0.036*\"my\" + 0.035*\"bollywood\" + 0.034*\"green\" + 0.031*\"page\" + 0.031*\"on\" + 0.026*\"who\" + 0.025*\"hollywood\"\n",
      "INFO:gensim.models.ldamodel:topic #25 (0.010): 0.051*\"girl\" + 0.047*\"tell\" + 0.046*\"guy\" + 0.045*\"friends\" + 0.041*\"eat\" + 0.033*\"that\" + 0.032*\"mind\" + 0.030*\"woman\" + 0.030*\"common\" + 0.029*\"not\"\n",
      "INFO:gensim.models.ldamodel:topic #38 (0.010): 0.123*\"new\" + 0.117*\"they\" + 0.058*\"play\" + 0.045*\"looking\" + 0.043*\"universities\" + 0.040*\"from\" + 0.038*\"does\" + 0.030*\"never\" + 0.023*\"national\" + 0.021*\"recruit\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.022272, rho=0.064416\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #246 = documents up to #494000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #247 = documents up to #496000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #248 = documents up to #498000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #22 (0.010): 0.099*\"see\" + 0.093*\"instagram\" + 0.063*\"hair\" + 0.061*\"on\" + 0.060*\"youtube\" + 0.043*\"my\" + 0.028*\"who\" + 0.022*\"beautiful\" + 0.019*\"currently\" + 0.018*\"does\"\n",
      "INFO:gensim.models.ldamodel:topic #12 (0.010): 0.439*\".\" + 0.032*\"u\" + 0.031*\"b\" + 0.031*\"girls\" + 0.022*\"answers\" + 0.016*\"have\" + 0.015*\"am\" + 0.015*\"guys\" + 0.015*\"rate\" + 0.014*\"not\"\n",
      "INFO:gensim.models.ldamodel:topic #43 (0.010): 0.151*\"job\" + 0.070*\"through\" + 0.059*\"interview\" + 0.058*\"learning\" + 0.050*\"tips\" + 0.046*\"process\" + 0.042*\"making\" + 0.041*\"at\" + 0.041*\"get\" + 0.040*\"some\"\n",
      "INFO:gensim.models.ldamodel:topic #50 (0.010): 0.156*\"love\" + 0.128*\"used\" + 0.055*\"makes\" + 0.033*\"by\" + 0.033*\"fall\" + 0.030*\"on\" + 0.027*\"safety\" + 0.024*\"proposed\" + 0.024*\"sentence\" + 0.022*\"precautions\"\n",
      "INFO:gensim.models.ldamodel:topic #72 (0.010): 0.120*\"their\" + 0.104*\"first\" + 0.082*\"day\" + 0.079*\"things\" + 0.075*\"into\" + 0.061*\"going\" + 0.058*\"know\" + 0.041*\"should\" + 0.039*\"some\" + 0.030*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.021549, rho=0.064150\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #249 = documents up to #500000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #250 = documents up to #502000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #20 (0.010): 0.069*\"place\" + 0.062*\"usa\" + 0.053*\"visit\" + 0.051*\"places\" + 0.050*\"best\" + 0.042*\"visa\" + 0.038*\"public\" + 0.032*\"india\" + 0.023*\"interested\" + 0.019*\"estate\"\n",
      "INFO:gensim.models.ldamodel:topic #72 (0.010): 0.120*\"their\" + 0.103*\"first\" + 0.082*\"day\" + 0.078*\"things\" + 0.075*\"into\" + 0.061*\"going\" + 0.057*\"know\" + 0.041*\"should\" + 0.039*\"some\" + 0.030*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #85 (0.010): 0.117*\".\" + 0.077*\"am\" + 0.074*\"me\" + 0.069*\"my\" + 0.041*\"want\" + 0.037*\"not\" + 0.035*\"he\" + 0.029*\"should\" + 0.029*\"her\" + 0.025*\"if\"\n",
      "INFO:gensim.models.ldamodel:topic #71 (0.010): 0.059*\"private\" + 0.057*\"score\" + 0.051*\"startup\" + 0.041*\"advice\" + 0.034*\"engine\" + 0.031*\"paid\" + 0.031*\"get\" + 0.027*\"gre\" + 0.026*\"eyes\" + 0.025*\"islam\"\n",
      "INFO:gensim.models.ldamodel:topic #46 (0.010): 0.054*\"air\" + 0.053*\"family\" + 0.052*\"reduce\" + 0.046*\"apps\" + 0.034*\"uber\" + 0.029*\"or\" + 0.026*\"my\" + 0.024*\"special\" + 0.019*\"convince\" + 0.016*\"devices\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.020535, rho=0.063888\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #251 = documents up to #504000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #252 = documents up to #506000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.010): 0.242*\"where\" + 0.139*\"find\" + 0.047*\"get\" + 0.037*\"support\" + 0.023*\"times\" + 0.021*\"my\" + 0.020*\"sim\" + 0.017*\"religion\" + 0.017*\"quickly\" + 0.017*\"jio\"\n",
      "INFO:gensim.models.ldamodel:topic #72 (0.010): 0.119*\"their\" + 0.103*\"first\" + 0.082*\"day\" + 0.079*\"things\" + 0.075*\"into\" + 0.061*\"going\" + 0.058*\"know\" + 0.041*\"should\" + 0.039*\"some\" + 0.029*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #87 (0.010): 0.062*\"parents\" + 0.058*\"date\" + 0.028*\"knowledge\" + 0.027*\"with\" + 0.025*\"land\" + 0.023*\"kids\" + 0.016*\"usb\" + 0.016*\"candidate\" + 0.016*\"performance\" + 0.013*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic #76 (0.010): 0.068*\"watch\" + 0.056*\"something\" + 0.044*\"seen\" + 0.034*\"you\" + 0.030*\"tax\" + 0.024*\"on\" + 0.023*\"an\" + 0.023*\"season\" + 0.021*\"movies\" + 0.021*\"interest\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.164*\"non_ascii_word\" + 0.070*\"delhi\" + 0.038*\"oil\" + 0.034*\"related\" + 0.028*\"everyone\" + 0.025*\"seo\" + 0.021*\"okay\" + 0.020*\"asian\" + 0.020*\"attractive\" + 0.018*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.019977, rho=0.063628\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #253 = documents up to #508000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #254 = documents up to #510000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.010): 0.171*\"learn\" + 0.163*\"start\" + 0.047*\"should\" + 0.033*\"idea\" + 0.030*\"technology\" + 0.029*\"order\" + 0.027*\"sell\" + 0.026*\"python\" + 0.022*\"enough\" + 0.021*\"with\"\n",
      "INFO:gensim.models.ldamodel:topic #77 (0.010): 0.108*\"change\" + 0.055*\"around\" + 0.045*\"popular\" + 0.034*\"decision\" + 0.034*\"views\" + 0.027*\"let\" + 0.024*\"linux\" + 0.024*\"it\" + 0.023*\"news\" + 0.021*\"europe\"\n",
      "INFO:gensim.models.ldamodel:topic #35 (0.010): 0.063*\"movies\" + 0.043*\"some\" + 0.036*\"jee\" + 0.035*\"iit\" + 0.035*\"down\" + 0.033*\"project\" + 0.031*\"effect\" + 0.031*\"put\" + 0.025*\"children\" + 0.022*\"topics\"\n",
      "INFO:gensim.models.ldamodel:topic #64 (0.010): 0.136*\"up\" + 0.101*\"need\" + 0.045*\"got\" + 0.043*\"keep\" + 0.040*\"pay\" + 0.030*\"cause\" + 0.029*\"does\" + 0.017*\"get\" + 0.016*\"chance\" + 0.016*\"meet\"\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.010): 0.088*\"look\" + 0.056*\"note\" + 0.048*\"currency\" + 0.043*\"ban\" + 0.040*\"does\" + 0.032*\"like\" + 0.032*\"address\" + 0.028*\"corruption\" + 0.019*\"recovery\" + 0.019*\"hp\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.020230, rho=0.063372\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #255 = documents up to #512000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #256 = documents up to #514000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #61 (0.010): 0.123*\"thing\" + 0.058*\"you\" + 0.053*\"demonetization\" + 0.039*\"given\" + 0.039*\"that\" + 0.034*\"most\" + 0.029*\"advantages\" + 0.027*\"second\" + 0.026*\"taken\" + 0.023*\"income\"\n",
      "INFO:gensim.models.ldamodel:topic #52 (0.010): 0.125*\"possible\" + 0.106*\"it\" + 0.050*\"career\" + 0.048*\"travel\" + 0.028*\"house\" + 0.028*\"humans\" + 0.023*\"options\" + 0.020*\"after\" + 0.019*\"check\" + 0.019*\"chemical\"\n",
      "INFO:gensim.models.ldamodel:topic #40 (0.010): 0.171*\"much\" + 0.062*\"live\" + 0.056*\"during\" + 0.050*\"does\" + 0.049*\"it\" + 0.044*\"cost\" + 0.040*\"future\" + 0.029*\"behind\" + 0.024*\"small\" + 0.023*\"so\"\n",
      "INFO:gensim.models.ldamodel:topic #62 (0.010): 0.098*\"engineering\" + 0.057*\"student\" + 0.057*\"getting\" + 0.049*\"university\" + 0.043*\"an\" + 0.035*\"students\" + 0.031*\"post\" + 0.028*\"civil\" + 0.025*\"after\" + 0.023*\"file\"\n",
      "INFO:gensim.models.ldamodel:topic #80 (0.010): 0.079*\"write\" + 0.073*\"card\" + 0.070*\"body\" + 0.048*\"differences\" + 0.047*\"program\" + 0.040*\"medical\" + 0.032*\"credit\" + 0.026*\"basic\" + 0.019*\"works\" + 0.019*\"pressure\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.019657, rho=0.063119\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #257 = documents up to #516000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #258 = documents up to #518000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.151*\"non_ascii_word\" + 0.071*\"delhi\" + 0.039*\"oil\" + 0.032*\"related\" + 0.028*\"everyone\" + 0.025*\"seo\" + 0.023*\"asian\" + 0.021*\"okay\" + 0.021*\"attractive\" + 0.018*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic #45 (0.010): 0.061*\"hard\" + 0.054*\"percent\" + 0.039*\"choose\" + 0.031*\"single\" + 0.030*\"it\" + 0.028*\"grow\" + 0.026*\"group\" + 0.026*\"eating\" + 0.024*\"paper\" + 0.023*\"loss\"\n",
      "INFO:gensim.models.ldamodel:topic #46 (0.010): 0.056*\"family\" + 0.055*\"reduce\" + 0.054*\"air\" + 0.049*\"apps\" + 0.032*\"uber\" + 0.030*\"or\" + 0.026*\"my\" + 0.024*\"special\" + 0.018*\"convince\" + 0.017*\"devices\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.298*\"my\" + 0.143*\"english\" + 0.108*\"improve\" + 0.043*\"should\" + 0.034*\"month\" + 0.033*\"7\" + 0.019*\"speaking\" + 0.019*\"communication\" + 0.017*\"mother\" + 0.011*\"24\"\n",
      "INFO:gensim.models.ldamodel:topic #99 (0.010): 0.147*\"google\" + 0.113*\"just\" + 0.036*\"speak\" + 0.034*\"view\" + 0.028*\"won\" + 0.024*\"on\" + 0.021*\"sbi\" + 0.018*\"here\" + 0.017*\"they\" + 0.015*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.019158, rho=0.062869\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #259 = documents up to #520000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #260 = documents up to #522000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #45 (0.010): 0.062*\"hard\" + 0.056*\"percent\" + 0.040*\"choose\" + 0.032*\"single\" + 0.030*\"it\" + 0.029*\"group\" + 0.028*\"grow\" + 0.026*\"eating\" + 0.023*\"paper\" + 0.022*\"loss\"\n",
      "INFO:gensim.models.ldamodel:topic #83 (0.010): 0.082*\"experience\" + 0.046*\"level\" + 0.045*\"sites\" + 0.043*\"preparation\" + 0.035*\"photos\" + 0.030*\"dating\" + 0.023*\"planning\" + 0.023*\"determined\" + 0.022*\"18\" + 0.021*\"isis\"\n",
      "INFO:gensim.models.ldamodel:topic #79 (0.010): 0.152*\"2016\" + 0.064*\"kind\" + 0.047*\"overcome\" + 0.029*\"cut\" + 0.027*\"fear\" + 0.025*\"beginner\" + 0.023*\"expected\" + 0.019*\"off\" + 0.017*\"designer\" + 0.014*\"cutoff\"\n",
      "INFO:gensim.models.ldamodel:topic #64 (0.010): 0.137*\"up\" + 0.099*\"need\" + 0.043*\"got\" + 0.042*\"keep\" + 0.041*\"pay\" + 0.030*\"cause\" + 0.030*\"does\" + 0.017*\"get\" + 0.017*\"meet\" + 0.016*\"chance\"\n",
      "INFO:gensim.models.ldamodel:topic #49 (0.010): 0.090*\"computer\" + 0.088*\"science\" + 0.073*\"data\" + 0.044*\"history\" + 0.034*\"canada\" + 0.030*\"from\" + 0.029*\"both\" + 0.029*\"others\" + 0.028*\"ms\" + 0.018*\"laws\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.018731, rho=0.062622\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #261 = documents up to #524000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #262 = documents up to #526000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #81 (0.010): 0.073*\"10\" + 0.051*\"windows\" + 0.044*\"problem\" + 0.027*\"solve\" + 0.025*\"words\" + 0.025*\"following\" + 0.024*\"it\" + 0.023*\"does\" + 0.022*\"on\" + 0.021*\"mac\"\n",
      "INFO:gensim.models.ldamodel:topic #39 (0.010): 0.102*\"top\" + 0.087*\"own\" + 0.045*\"normal\" + 0.038*\"green\" + 0.035*\"my\" + 0.034*\"bollywood\" + 0.029*\"on\" + 0.029*\"page\" + 0.026*\"who\" + 0.024*\"tea\"\n",
      "INFO:gensim.models.ldamodel:topic #19 (0.010): 0.067*\"myself\" + 0.049*\"center\" + 0.044*\"drug\" + 0.042*\"value\" + 0.039*\"alcohol\" + 0.035*\"mass\" + 0.034*\"near\" + 0.034*\"started\" + 0.028*\"county\" + 0.028*\"rehab\"\n",
      "INFO:gensim.models.ldamodel:topic #61 (0.010): 0.122*\"thing\" + 0.058*\"you\" + 0.052*\"demonetization\" + 0.039*\"that\" + 0.039*\"given\" + 0.034*\"most\" + 0.029*\"advantages\" + 0.028*\"second\" + 0.028*\"taken\" + 0.025*\"income\"\n",
      "INFO:gensim.models.ldamodel:topic #34 (0.010): 0.048*\"product\" + 0.048*\"legal\" + 0.046*\"happy\" + 0.028*\"be\" + 0.028*\"written\" + 0.027*\"passport\" + 0.026*\"expect\" + 0.024*\"needs\" + 0.024*\"core\" + 0.019*\"programs\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.018567, rho=0.062378\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #263 = documents up to #528000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #264 = documents up to #530000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.099*\"over\" + 0.092*\"before\" + 0.065*\"bing\" + 0.041*\"class\" + 0.031*\"correct\" + 0.030*\"short\" + 0.025*\"red\" + 0.022*\"structure\" + 0.021*\"get\" + 0.021*\"because\"\n",
      "INFO:gensim.models.ldamodel:topic #99 (0.010): 0.149*\"google\" + 0.116*\"just\" + 0.035*\"view\" + 0.034*\"speak\" + 0.028*\"won\" + 0.024*\"on\" + 0.019*\"here\" + 0.018*\"sbi\" + 0.018*\"they\" + 0.014*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic #44 (0.010): 0.197*\"about\" + 0.160*\"you\" + 0.120*\"think\" + 0.057*\"stop\" + 0.050*\"people\" + 0.038*\"know\" + 0.028*\"that\" + 0.025*\"last\" + 0.018*\"indians\" + 0.018*\"not\"\n",
      "INFO:gensim.models.ldamodel:topic #34 (0.010): 0.049*\"legal\" + 0.048*\"product\" + 0.047*\"happy\" + 0.029*\"be\" + 0.029*\"written\" + 0.027*\"passport\" + 0.025*\"expect\" + 0.024*\"core\" + 0.023*\"needs\" + 0.020*\"sure\"\n",
      "INFO:gensim.models.ldamodel:topic #52 (0.010): 0.127*\"possible\" + 0.107*\"it\" + 0.054*\"career\" + 0.049*\"travel\" + 0.029*\"house\" + 0.028*\"humans\" + 0.023*\"options\" + 0.020*\"check\" + 0.019*\"after\" + 0.019*\"chemical\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.018308, rho=0.062137\n",
      "INFO:gensim.models.ldamodel:-8.139 per-word bound, 282.0 perplexity estimate based on a held-out corpus of 2000 documents with 15700 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #265 = documents up to #532000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #92 (0.010): 0.151*\"become\" + 0.051*\"come\" + 0.044*\"create\" + 0.032*\"jobs\" + 0.032*\"an\" + 0.030*\"sleep\" + 0.028*\"from\" + 0.025*\"drive\" + 0.024*\"cell\" + 0.023*\"does\"\n",
      "INFO:gensim.models.ldamodel:topic #36 (0.010): 0.134*\"year\" + 0.101*\"old\" + 0.064*\"it\" + 0.054*\"true\" + 0.037*\"salary\" + 0.036*\"worth\" + 0.034*\"that\" + 0.027*\"fast\" + 0.024*\"must\" + 0.023*\"application\"\n",
      "INFO:gensim.models.ldamodel:topic #74 (0.010): 0.045*\"star\" + 0.042*\"does\" + 0.041*\"industry\" + 0.032*\"option\" + 0.030*\"moon\" + 0.030*\"sun\" + 0.027*\"sound\" + 0.024*\"wars\" + 0.023*\"stand\" + 0.022*\"gravity\"\n",
      "INFO:gensim.models.ldamodel:topic #60 (0.010): 0.095*\"trump\" + 0.072*\"take\" + 0.071*\"us\" + 0.061*\"donald\" + 0.058*\"will\" + 0.049*\"president\" + 0.044*\"clinton\" + 0.039*\"hillary\" + 0.037*\"win\" + 0.034*\"who\"\n",
      "INFO:gensim.models.ldamodel:topic #95 (0.010): 0.176*\"work\" + 0.071*\"does\" + 0.036*\"at\" + 0.036*\"apply\" + 0.030*\"bangalore\" + 0.030*\"4\" + 0.029*\"differ\" + 0.028*\"it\" + 0.026*\"videos\" + 0.022*\"vote\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.017852, rho=0.061898\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #266 = documents up to #534000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #267 = documents up to #536000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #268 = documents up to #538000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.010): 0.122*\"go\" + 0.049*\"skills\" + 0.039*\"writing\" + 0.037*\"stay\" + 0.036*\"show\" + 0.032*\"wear\" + 0.031*\"causes\" + 0.026*\"pro\" + 0.025*\"required\" + 0.023*\"team\"\n",
      "INFO:gensim.models.ldamodel:topic #60 (0.010): 0.095*\"trump\" + 0.071*\"take\" + 0.071*\"us\" + 0.062*\"donald\" + 0.058*\"will\" + 0.049*\"president\" + 0.044*\"clinton\" + 0.039*\"hillary\" + 0.037*\"win\" + 0.034*\"who\"\n",
      "INFO:gensim.models.ldamodel:topic #95 (0.010): 0.176*\"work\" + 0.071*\"does\" + 0.036*\"apply\" + 0.036*\"at\" + 0.031*\"4\" + 0.030*\"bangalore\" + 0.029*\"differ\" + 0.028*\"it\" + 0.026*\"videos\" + 0.023*\"vote\"\n",
      "INFO:gensim.models.ldamodel:topic #22 (0.010): 0.100*\"see\" + 0.092*\"instagram\" + 0.062*\"on\" + 0.061*\"hair\" + 0.058*\"youtube\" + 0.045*\"my\" + 0.029*\"who\" + 0.022*\"beautiful\" + 0.019*\"most\" + 0.019*\"currently\"\n",
      "INFO:gensim.models.ldamodel:topic #44 (0.010): 0.199*\"about\" + 0.159*\"you\" + 0.119*\"think\" + 0.057*\"stop\" + 0.050*\"people\" + 0.038*\"know\" + 0.028*\"that\" + 0.027*\"last\" + 0.018*\"not\" + 0.018*\"indians\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.017477, rho=0.061663\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #269 = documents up to #540000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #270 = documents up to #542000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #75 (0.010): 0.074*\"doing\" + 0.053*\"internet\" + 0.049*\"while\" + 0.043*\"wrong\" + 0.041*\"modi\" + 0.038*\"part\" + 0.033*\"studying\" + 0.027*\"sydney\" + 0.026*\"narendra\" + 0.023*\"final\"\n",
      "INFO:gensim.models.ldamodel:topic #91 (0.010): 0.072*\"even\" + 0.067*\"days\" + 0.054*\"with\" + 0.046*\"deal\" + 0.040*\"period\" + 0.036*\"pregnant\" + 0.033*\"get\" + 0.025*\"my\" + 0.024*\"within\" + 0.024*\"depression\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.010): 0.091*\"my\" + 0.077*\"increase\" + 0.041*\"height\" + 0.040*\"type\" + 0.036*\"traffic\" + 0.034*\"get\" + 0.034*\"dog\" + 0.032*\"called\" + 0.025*\"party\" + 0.025*\"function\"\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.010): 0.167*\"start\" + 0.165*\"learn\" + 0.050*\"should\" + 0.035*\"idea\" + 0.033*\"technology\" + 0.030*\"order\" + 0.028*\"sell\" + 0.026*\"python\" + 0.025*\"learning\" + 0.022*\"enough\"\n",
      "INFO:gensim.models.ldamodel:topic #70 (0.010): 0.166*\"quora\" + 0.108*\"on\" + 0.067*\"questions\" + 0.047*\"question\" + 0.043*\"ask\" + 0.031*\"answer\" + 0.031*\"people\" + 0.026*\"my\" + 0.024*\"effects\" + 0.021*\"as\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.017283, rho=0.061430\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #271 = documents up to #544000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #272 = documents up to #546000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #273 = documents up to #548000/808580, outstanding queue size 7\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #55 (0.010): 0.112*\"number\" + 0.063*\"tech\" + 0.047*\"list\" + 0.038*\"remove\" + 0.035*\"from\" + 0.033*\"m\" + 0.025*\"exactly\" + 0.022*\"after\" + 0.019*\"does\" + 0.017*\"steps\"\n",
      "INFO:gensim.models.ldamodel:topic #88 (0.010): 0.159*\"many\" + 0.081*\"years\" + 0.051*\"5\" + 0.040*\"dollar\" + 0.034*\"so\" + 0.029*\"there\" + 0.023*\"hours\" + 0.023*\"week\" + 0.023*\"per\" + 0.020*\"20\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.124*\"ways\" + 0.087*\"get\" + 0.059*\"rid\" + 0.052*\"some\" + 0.034*\"face\" + 0.032*\"on\" + 0.025*\"daily\" + 0.025*\"my\" + 0.024*\"impact\" + 0.021*\"bill\"\n",
      "INFO:gensim.models.ldamodel:topic #60 (0.010): 0.096*\"trump\" + 0.072*\"us\" + 0.069*\"take\" + 0.062*\"donald\" + 0.058*\"will\" + 0.049*\"president\" + 0.043*\"clinton\" + 0.039*\"hillary\" + 0.038*\"win\" + 0.034*\"who\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.061*\"real\" + 0.053*\"america\" + 0.053*\"average\" + 0.053*\"food\" + 0.050*\"non\" + 0.042*\"age\" + 0.036*\"able\" + 0.028*\"child\" + 0.025*\"there\" + 0.025*\"marriage\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.016205, rho=0.061199\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #274 = documents up to #550000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #56 (0.010): 0.069*\"some\" + 0.048*\"about\" + 0.045*\"interesting\" + 0.043*\"facts\" + 0.036*\"based\" + 0.034*\"known\" + 0.031*\"australia\" + 0.027*\"india\" + 0.024*\"model\" + 0.024*\"japanese\"\n",
      "INFO:gensim.models.ldamodel:topic #82 (0.010): 0.092*\"bad\" + 0.077*\"two\" + 0.059*\"game\" + 0.030*\"it\" + 0.029*\"you\" + 0.027*\"blood\" + 0.026*\"or\" + 0.023*\"that\" + 0.023*\"fix\" + 0.021*\"try\"\n",
      "INFO:gensim.models.ldamodel:topic #99 (0.010): 0.155*\"google\" + 0.122*\"just\" + 0.035*\"speak\" + 0.033*\"view\" + 0.027*\"won\" + 0.023*\"on\" + 0.019*\"sbi\" + 0.018*\"here\" + 0.017*\"they\" + 0.016*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.148*\"non_ascii_word\" + 0.074*\"delhi\" + 0.034*\"oil\" + 0.033*\"related\" + 0.028*\"seo\" + 0.025*\"everyone\" + 0.024*\"asian\" + 0.021*\"attractive\" + 0.021*\"okay\" + 0.018*\"developed\"\n",
      "INFO:gensim.models.ldamodel:topic #73 (0.010): 0.178*\"without\" + 0.064*\"safe\" + 0.062*\"service\" + 0.049*\"police\" + 0.045*\"hotel\" + 0.026*\"be\" + 0.019*\"screen\" + 0.019*\"moral\" + 0.019*\"couples\" + 0.019*\"suggest\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.016666, rho=0.060971\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #275 = documents up to #552000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #276 = documents up to #554000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #77 (0.010): 0.105*\"change\" + 0.049*\"around\" + 0.042*\"popular\" + 0.035*\"decision\" + 0.032*\"views\" + 0.027*\"it\" + 0.026*\"linux\" + 0.025*\"let\" + 0.022*\"news\" + 0.021*\"!\"\n",
      "INFO:gensim.models.ldamodel:topic #46 (0.010): 0.053*\"reduce\" + 0.052*\"family\" + 0.052*\"apps\" + 0.051*\"air\" + 0.035*\"uber\" + 0.033*\"or\" + 0.024*\"my\" + 0.023*\"special\" + 0.020*\"convince\" + 0.016*\"driver\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.306*\"your\" + 0.136*\"life\" + 0.112*\"you\" + 0.039*\"school\" + 0.037*\"high\" + 0.027*\"favorite\" + 0.021*\"join\" + 0.015*\"was\" + 0.014*\"most\" + 0.013*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic #73 (0.010): 0.176*\"without\" + 0.063*\"safe\" + 0.061*\"service\" + 0.050*\"police\" + 0.045*\"hotel\" + 0.026*\"be\" + 0.019*\"screen\" + 0.019*\"moral\" + 0.019*\"couples\" + 0.019*\"suggest\"\n",
      "INFO:gensim.models.ldamodel:topic #54 (0.010): 0.124*\"weight\" + 0.115*\"being\" + 0.103*\"lose\" + 0.058*\"man\" + 0.040*\"die\" + 0.031*\"way\" + 0.029*\"websites\" + 0.027*\"easiest\" + 0.020*\"you\" + 0.017*\"50\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.016368, rho=0.060746\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #277 = documents up to #556000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #278 = documents up to #558000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.010): 0.126*\"go\" + 0.049*\"skills\" + 0.037*\"writing\" + 0.037*\"show\" + 0.036*\"stay\" + 0.032*\"wear\" + 0.030*\"causes\" + 0.026*\"pro\" + 0.025*\"required\" + 0.022*\"team\"\n",
      "INFO:gensim.models.ldamodel:topic #18 (0.010): 0.207*\"time\" + 0.077*\"business\" + 0.057*\"same\" + 0.047*\"back\" + 0.026*\"instead\" + 0.026*\"it\" + 0.025*\"physics\" + 0.022*\"at\" + 0.020*\"12\" + 0.017*\"from\"\n",
      "INFO:gensim.models.ldamodel:topic #67 (0.010): 0.076*\"prepare\" + 0.064*\"water\" + 0.057*\"bank\" + 0.035*\"cat\" + 0.034*\"england\" + 0.034*\"mechanical\" + 0.031*\"education\" + 0.029*\"invest\" + 0.028*\"should\" + 0.022*\"again\"\n",
      "INFO:gensim.models.ldamodel:topic #43 (0.010): 0.153*\"job\" + 0.070*\"through\" + 0.056*\"learning\" + 0.054*\"interview\" + 0.049*\"tips\" + 0.045*\"making\" + 0.043*\"process\" + 0.042*\"at\" + 0.042*\"get\" + 0.041*\"some\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.145*\"non_ascii_word\" + 0.074*\"delhi\" + 0.037*\"oil\" + 0.031*\"related\" + 0.029*\"seo\" + 0.026*\"everyone\" + 0.023*\"asian\" + 0.021*\"attractive\" + 0.021*\"okay\" + 0.018*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.016167, rho=0.060523\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #279 = documents up to #560000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #280 = documents up to #562000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #49 (0.010): 0.094*\"computer\" + 0.087*\"science\" + 0.075*\"data\" + 0.043*\"history\" + 0.033*\"canada\" + 0.030*\"both\" + 0.030*\"from\" + 0.027*\"others\" + 0.027*\"ms\" + 0.017*\"laws\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.062*\"real\" + 0.055*\"america\" + 0.053*\"average\" + 0.051*\"food\" + 0.050*\"non\" + 0.042*\"age\" + 0.035*\"able\" + 0.027*\"child\" + 0.025*\"there\" + 0.024*\"100\"\n",
      "INFO:gensim.models.ldamodel:topic #96 (0.010): 0.368*\"have\" + 0.093*\"you\" + 0.055*\"had\" + 0.038*\"if\" + 0.036*\"been\" + 0.020*\"not\" + 0.016*\"that\" + 0.016*\"any\" + 0.015*\"dream\" + 0.015*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic #97 (0.010): 0.161*\"more\" + 0.148*\"than\" + 0.068*\"study\" + 0.056*\"give\" + 0.028*\"or\" + 0.022*\"germany\" + 0.022*\"2015\" + 0.019*\"exams\" + 0.015*\"please\" + 0.014*\"be\"\n",
      "INFO:gensim.models.ldamodel:topic #82 (0.010): 0.094*\"bad\" + 0.080*\"two\" + 0.057*\"game\" + 0.030*\"it\" + 0.028*\"blood\" + 0.027*\"you\" + 0.025*\"fix\" + 0.025*\"or\" + 0.022*\"that\" + 0.022*\"try\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.015247, rho=0.060302\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #281 = documents up to #564000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #282 = documents up to #566000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #83 (0.010): 0.080*\"experience\" + 0.052*\"sites\" + 0.045*\"level\" + 0.043*\"preparation\" + 0.034*\"photos\" + 0.031*\"dating\" + 0.023*\"determined\" + 0.022*\"18\" + 0.022*\"planning\" + 0.020*\"11\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.150*\"non_ascii_word\" + 0.073*\"delhi\" + 0.037*\"oil\" + 0.029*\"related\" + 0.028*\"seo\" + 0.027*\"everyone\" + 0.022*\"asian\" + 0.022*\"attractive\" + 0.020*\"okay\" + 0.018*\"developed\"\n",
      "INFO:gensim.models.ldamodel:topic #18 (0.010): 0.209*\"time\" + 0.078*\"business\" + 0.058*\"same\" + 0.047*\"back\" + 0.026*\"physics\" + 0.026*\"it\" + 0.025*\"instead\" + 0.022*\"at\" + 0.019*\"12\" + 0.017*\"from\"\n",
      "INFO:gensim.models.ldamodel:topic #19 (0.010): 0.067*\"myself\" + 0.048*\"center\" + 0.048*\"drug\" + 0.045*\"value\" + 0.038*\"alcohol\" + 0.036*\"near\" + 0.034*\"started\" + 0.034*\"mass\" + 0.029*\"rehab\" + 0.029*\"county\"\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.010): 0.122*\"my\" + 0.090*\"account\" + 0.078*\"facebook\" + 0.043*\"password\" + 0.035*\"email\" + 0.032*\"gmail\" + 0.029*\"from\" + 0.027*\"delete\" + 0.024*\"recover\" + 0.019*\"if\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.015549, rho=0.060084\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #283 = documents up to #568000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #284 = documents up to #570000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #25 (0.010): 0.050*\"girl\" + 0.047*\"guy\" + 0.047*\"friends\" + 0.045*\"tell\" + 0.045*\"eat\" + 0.036*\"mind\" + 0.033*\"woman\" + 0.033*\"american\" + 0.032*\"that\" + 0.031*\"common\"\n",
      "INFO:gensim.models.ldamodel:topic #91 (0.010): 0.071*\"even\" + 0.070*\"days\" + 0.054*\"with\" + 0.046*\"deal\" + 0.040*\"period\" + 0.038*\"pregnant\" + 0.035*\"get\" + 0.026*\"my\" + 0.024*\"depression\" + 0.023*\"after\"\n",
      "INFO:gensim.models.ldamodel:topic #55 (0.010): 0.115*\"number\" + 0.063*\"tech\" + 0.046*\"list\" + 0.037*\"m\" + 0.037*\"remove\" + 0.035*\"from\" + 0.024*\"exactly\" + 0.023*\"after\" + 0.019*\"father\" + 0.018*\"does\"\n",
      "INFO:gensim.models.ldamodel:topic #29 (0.010): 0.054*\"build\" + 0.053*\"run\" + 0.045*\"death\" + 0.039*\"dogs\" + 0.036*\"suicide\" + 0.034*\"security\" + 0.032*\"least\" + 0.023*\"flat\" + 0.023*\"commit\" + 0.022*\"soon\"\n",
      "INFO:gensim.models.ldamodel:topic #49 (0.010): 0.094*\"computer\" + 0.085*\"science\" + 0.074*\"data\" + 0.042*\"history\" + 0.033*\"canada\" + 0.031*\"both\" + 0.030*\"from\" + 0.029*\"ms\" + 0.026*\"others\" + 0.018*\"laws\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.016804, rho=0.059868\n",
      "INFO:gensim.models.ldamodel:-8.096 per-word bound, 273.5 perplexity estimate based on a held-out corpus of 2000 documents with 15672 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #285 = documents up to #572000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.010): 0.121*\"my\" + 0.088*\"account\" + 0.078*\"facebook\" + 0.042*\"password\" + 0.036*\"email\" + 0.032*\"gmail\" + 0.029*\"from\" + 0.026*\"delete\" + 0.025*\"recover\" + 0.020*\"deleted\"\n",
      "INFO:gensim.models.ldamodel:topic #55 (0.010): 0.114*\"number\" + 0.062*\"tech\" + 0.046*\"list\" + 0.039*\"remove\" + 0.037*\"m\" + 0.036*\"from\" + 0.024*\"exactly\" + 0.022*\"after\" + 0.018*\"father\" + 0.018*\"steps\"\n",
      "INFO:gensim.models.ldamodel:topic #48 (0.010): 0.159*\"other\" + 0.051*\"government\" + 0.044*\"against\" + 0.042*\"india\" + 0.041*\"each\" + 0.025*\"products\" + 0.022*\"text\" + 0.022*\"any\" + 0.021*\"numbers\" + 0.020*\"there\"\n",
      "INFO:gensim.models.ldamodel:topic #25 (0.010): 0.050*\"girl\" + 0.048*\"guy\" + 0.045*\"friends\" + 0.045*\"tell\" + 0.045*\"eat\" + 0.037*\"mind\" + 0.034*\"woman\" + 0.033*\"american\" + 0.032*\"that\" + 0.031*\"common\"\n",
      "INFO:gensim.models.ldamodel:topic #35 (0.010): 0.069*\"movies\" + 0.044*\"some\" + 0.035*\"iit\" + 0.035*\"down\" + 0.033*\"put\" + 0.032*\"jee\" + 0.031*\"project\" + 0.030*\"effect\" + 0.023*\"topics\" + 0.022*\"children\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.014820, rho=0.059655\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #286 = documents up to #574000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #287 = documents up to #576000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #288 = documents up to #578000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #47 (0.010): 0.130*\"does\" + 0.122*\"mean\" + 0.070*\"it\" + 0.043*\"too\" + 0.031*\"when\" + 0.030*\"call\" + 0.028*\"plan\" + 0.024*\"found\" + 0.022*\"says\" + 0.021*\"lot\"\n",
      "INFO:gensim.models.ldamodel:topic #61 (0.010): 0.125*\"thing\" + 0.059*\"you\" + 0.050*\"demonetization\" + 0.041*\"that\" + 0.041*\"given\" + 0.032*\"most\" + 0.029*\"advantages\" + 0.028*\"second\" + 0.027*\"calculate\" + 0.026*\"taken\"\n",
      "INFO:gensim.models.ldamodel:topic #75 (0.010): 0.071*\"doing\" + 0.062*\"while\" + 0.051*\"internet\" + 0.044*\"wrong\" + 0.042*\"part\" + 0.039*\"modi\" + 0.034*\"studying\" + 0.027*\"sydney\" + 0.025*\"narendra\" + 0.021*\"property\"\n",
      "INFO:gensim.models.ldamodel:topic #70 (0.010): 0.167*\"quora\" + 0.106*\"on\" + 0.065*\"questions\" + 0.048*\"question\" + 0.044*\"ask\" + 0.032*\"answer\" + 0.029*\"people\" + 0.026*\"my\" + 0.024*\"effects\" + 0.022*\"as\"\n",
      "INFO:gensim.models.ldamodel:topic #54 (0.010): 0.124*\"weight\" + 0.116*\"being\" + 0.102*\"lose\" + 0.057*\"man\" + 0.040*\"die\" + 0.033*\"way\" + 0.029*\"websites\" + 0.029*\"easiest\" + 0.018*\"you\" + 0.018*\"50\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.014063, rho=0.059444\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #289 = documents up to #580000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #290 = documents up to #582000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #32 (0.010): 0.150*\"really\" + 0.056*\"exist\" + 0.044*\"hate\" + 0.041*\"does\" + 0.026*\"that\" + 0.026*\"once\" + 0.025*\"people\" + 0.022*\"amount\" + 0.021*\"evidence\" + 0.019*\"there\"\n",
      "INFO:gensim.models.ldamodel:topic #34 (0.010): 0.050*\"product\" + 0.048*\"legal\" + 0.042*\"happy\" + 0.029*\"passport\" + 0.027*\"written\" + 0.027*\"be\" + 0.024*\"core\" + 0.024*\"expect\" + 0.022*\"needs\" + 0.020*\"sure\"\n",
      "INFO:gensim.models.ldamodel:topic #15 (0.010): 0.193*\"we\" + 0.053*\"women\" + 0.053*\"our\" + 0.043*\"made\" + 0.043*\"men\" + 0.040*\"say\" + 0.039*\"china\" + 0.038*\"now\" + 0.038*\"right\" + 0.031*\"happens\"\n",
      "INFO:gensim.models.ldamodel:topic #91 (0.010): 0.072*\"even\" + 0.070*\"days\" + 0.054*\"with\" + 0.045*\"deal\" + 0.041*\"period\" + 0.036*\"pregnant\" + 0.035*\"get\" + 0.025*\"my\" + 0.024*\"depression\" + 0.023*\"after\"\n",
      "INFO:gensim.models.ldamodel:topic #78 (0.010): 0.209*\"money\" + 0.166*\"online\" + 0.070*\"earn\" + 0.033*\"available\" + 0.033*\"from\" + 0.027*\"easy\" + 0.023*\"colleges\" + 0.021*\"way\" + 0.019*\"break\" + 0.018*\"there\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.013943, rho=0.059235\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #291 = documents up to #584000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #292 = documents up to #586000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #43 (0.010): 0.152*\"job\" + 0.071*\"through\" + 0.055*\"interview\" + 0.054*\"learning\" + 0.052*\"tips\" + 0.044*\"making\" + 0.043*\"process\" + 0.043*\"get\" + 0.043*\"some\" + 0.042*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #15 (0.010): 0.192*\"we\" + 0.053*\"our\" + 0.053*\"women\" + 0.044*\"made\" + 0.042*\"men\" + 0.040*\"say\" + 0.040*\"china\" + 0.038*\"right\" + 0.038*\"now\" + 0.031*\"happens\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.095*\"before\" + 0.094*\"over\" + 0.070*\"bing\" + 0.038*\"class\" + 0.031*\"correct\" + 0.030*\"short\" + 0.026*\"red\" + 0.023*\"because\" + 0.022*\"get\" + 0.021*\"structure\"\n",
      "INFO:gensim.models.ldamodel:topic #13 (0.010): 0.055*\"song\" + 0.052*\"control\" + 0.039*\"ca\" + 0.039*\"california\" + 0.036*\"research\" + 0.034*\"solar\" + 0.033*\"avoid\" + 0.031*\"healthy\" + 0.030*\"provider\" + 0.026*\"good\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.010): 0.249*\"where\" + 0.149*\"find\" + 0.051*\"get\" + 0.037*\"support\" + 0.026*\"times\" + 0.018*\"sim\" + 0.018*\"quickly\" + 0.017*\"out\" + 0.016*\"religion\" + 0.016*\"jio\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.014247, rho=0.059028\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #293 = documents up to #588000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #294 = documents up to #590000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #24 (0.010): 0.194*\")\" + 0.192*\"(\" + 0.100*\":\" + 0.077*\"better\" + 0.069*\"or\" + 0.048*\"which\" + 0.033*\"long\" + 0.018*\"quoted_item\" + 0.016*\"mba\" + 0.014*\"one\"\n",
      "INFO:gensim.models.ldamodel:topic #87 (0.010): 0.064*\"parents\" + 0.057*\"date\" + 0.031*\"knowledge\" + 0.030*\"with\" + 0.027*\"kids\" + 0.026*\"land\" + 0.017*\"candidate\" + 0.015*\"performance\" + 0.015*\"fair\" + 0.014*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic #44 (0.010): 0.199*\"about\" + 0.152*\"you\" + 0.119*\"think\" + 0.060*\"stop\" + 0.050*\"people\" + 0.041*\"know\" + 0.029*\"that\" + 0.024*\"last\" + 0.019*\"not\" + 0.018*\"indians\"\n",
      "INFO:gensim.models.ldamodel:topic #73 (0.010): 0.178*\"without\" + 0.064*\"safe\" + 0.058*\"service\" + 0.051*\"police\" + 0.044*\"hotel\" + 0.026*\"be\" + 0.021*\"screen\" + 0.020*\"suggest\" + 0.019*\"moral\" + 0.019*\"couples\"\n",
      "INFO:gensim.models.ldamodel:topic #59 (0.010): 0.137*\"were\" + 0.116*\"still\" + 0.034*\"amazon\" + 0.034*\"send\" + 0.030*\"on\" + 0.024*\"did\" + 0.020*\"that\" + 0.019*\"was\" + 0.018*\"who\" + 0.018*\"you\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.014122, rho=0.058824\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #295 = documents up to #592000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #296 = documents up to #594000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #62 (0.010): 0.098*\"engineering\" + 0.058*\"getting\" + 0.055*\"student\" + 0.046*\"an\" + 0.043*\"university\" + 0.040*\"students\" + 0.031*\"post\" + 0.029*\"civil\" + 0.026*\"after\" + 0.024*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #30 (0.010): 0.318*\"make\" + 0.038*\"current\" + 0.036*\"degree\" + 0.035*\"happened\" + 0.029*\"you\" + 0.024*\"does\" + 0.023*\"obama\" + 0.023*\"full\" + 0.022*\"master\" + 0.016*\"pune\"\n",
      "INFO:gensim.models.ldamodel:topic #97 (0.010): 0.159*\"more\" + 0.152*\"than\" + 0.066*\"study\" + 0.060*\"give\" + 0.028*\"or\" + 0.022*\"2015\" + 0.022*\"germany\" + 0.020*\"exams\" + 0.016*\"please\" + 0.014*\"should\"\n",
      "INFO:gensim.models.ldamodel:topic #77 (0.010): 0.109*\"change\" + 0.050*\"around\" + 0.045*\"popular\" + 0.035*\"decision\" + 0.035*\"views\" + 0.026*\"let\" + 0.026*\"it\" + 0.024*\"!\" + 0.024*\"linux\" + 0.024*\"news\"\n",
      "INFO:gensim.models.ldamodel:topic #96 (0.010): 0.377*\"have\" + 0.089*\"you\" + 0.054*\"had\" + 0.036*\"if\" + 0.034*\"been\" + 0.022*\"not\" + 0.017*\"that\" + 0.016*\"any\" + 0.016*\"night\" + 0.016*\"international\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.013157, rho=0.058621\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #297 = documents up to #596000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #298 = documents up to #598000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #56 (0.010): 0.066*\"some\" + 0.049*\"about\" + 0.047*\"interesting\" + 0.040*\"facts\" + 0.040*\"based\" + 0.034*\"known\" + 0.029*\"australia\" + 0.027*\"model\" + 0.026*\"japanese\" + 0.026*\"india\"\n",
      "INFO:gensim.models.ldamodel:topic #78 (0.010): 0.212*\"money\" + 0.165*\"online\" + 0.068*\"earn\" + 0.034*\"available\" + 0.031*\"from\" + 0.028*\"easy\" + 0.025*\"colleges\" + 0.021*\"way\" + 0.018*\"break\" + 0.017*\"there\"\n",
      "INFO:gensim.models.ldamodel:topic #70 (0.010): 0.169*\"quora\" + 0.107*\"on\" + 0.064*\"questions\" + 0.048*\"question\" + 0.045*\"ask\" + 0.032*\"answer\" + 0.030*\"people\" + 0.025*\"effects\" + 0.024*\"my\" + 0.022*\"as\"\n",
      "INFO:gensim.models.ldamodel:topic #41 (0.010): 0.062*\"human\" + 0.059*\"state\" + 0.050*\"video\" + 0.048*\"considered\" + 0.041*\"point\" + 0.036*\"terms\" + 0.034*\"matter\" + 0.033*\"worst\" + 0.027*\"store\" + 0.027*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #42 (0.010): 0.101*\"help\" + 0.099*\"different\" + 0.066*\"companies\" + 0.052*\"white\" + 0.044*\"self\" + 0.041*\"culture\" + 0.038*\"songs\" + 0.030*\"gain\" + 0.019*\"some\" + 0.019*\"like\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.013155, rho=0.058421\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #299 = documents up to #600000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #300 = documents up to #602000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.060*\"real\" + 0.056*\"america\" + 0.053*\"average\" + 0.051*\"non\" + 0.050*\"food\" + 0.040*\"age\" + 0.035*\"able\" + 0.028*\"child\" + 0.024*\"married\" + 0.024*\"there\"\n",
      "INFO:gensim.models.ldamodel:topic #41 (0.010): 0.062*\"human\" + 0.058*\"state\" + 0.049*\"video\" + 0.048*\"considered\" + 0.041*\"point\" + 0.037*\"terms\" + 0.036*\"matter\" + 0.034*\"worst\" + 0.028*\"store\" + 0.027*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #67 (0.010): 0.079*\"prepare\" + 0.068*\"water\" + 0.056*\"bank\" + 0.034*\"england\" + 0.034*\"mechanical\" + 0.033*\"cat\" + 0.031*\"should\" + 0.030*\"education\" + 0.028*\"invest\" + 0.024*\"again\"\n",
      "INFO:gensim.models.ldamodel:topic #93 (0.010): 0.143*\"free\" + 0.047*\"also\" + 0.030*\"share\" + 0.028*\"reading\" + 0.026*\"allowed\" + 0.025*\"attack\" + 0.025*\"be\" + 0.020*\"get\" + 0.019*\"not\" + 0.019*\"should\"\n",
      "INFO:gensim.models.ldamodel:topic #55 (0.010): 0.114*\"number\" + 0.063*\"tech\" + 0.045*\"list\" + 0.038*\"remove\" + 0.036*\"from\" + 0.035*\"m\" + 0.026*\"exactly\" + 0.023*\"after\" + 0.018*\"acid\" + 0.017*\"does\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.012668, rho=0.058222\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #301 = documents up to #604000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #302 = documents up to #606000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #80 (0.010): 0.075*\"card\" + 0.073*\"write\" + 0.069*\"body\" + 0.057*\"differences\" + 0.049*\"program\" + 0.042*\"medical\" + 0.030*\"credit\" + 0.029*\"basic\" + 0.022*\"works\" + 0.021*\"pressure\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.060*\"real\" + 0.055*\"america\" + 0.053*\"average\" + 0.050*\"food\" + 0.050*\"non\" + 0.039*\"age\" + 0.035*\"able\" + 0.028*\"child\" + 0.026*\"there\" + 0.025*\"married\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.310*\"your\" + 0.139*\"life\" + 0.114*\"you\" + 0.043*\"school\" + 0.038*\"high\" + 0.026*\"favorite\" + 0.020*\"join\" + 0.014*\"was\" + 0.014*\"on\" + 0.013*\"most\"\n",
      "INFO:gensim.models.ldamodel:topic #45 (0.010): 0.054*\"hard\" + 0.054*\"percent\" + 0.037*\"choose\" + 0.033*\"single\" + 0.033*\"group\" + 0.027*\"eating\" + 0.026*\"it\" + 0.026*\"grow\" + 0.023*\"paper\" + 0.022*\"football\"\n",
      "INFO:gensim.models.ldamodel:topic #87 (0.010): 0.066*\"parents\" + 0.056*\"date\" + 0.031*\"knowledge\" + 0.030*\"with\" + 0.028*\"kids\" + 0.026*\"land\" + 0.016*\"candidate\" + 0.016*\"performance\" + 0.014*\"usb\" + 0.014*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.013443, rho=0.058026\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #303 = documents up to #608000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #304 = documents up to #610000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #79 (0.010): 0.155*\"2016\" + 0.061*\"kind\" + 0.044*\"overcome\" + 0.028*\"cut\" + 0.028*\"fear\" + 0.025*\"beginner\" + 0.021*\"expected\" + 0.019*\"off\" + 0.017*\"designer\" + 0.014*\"you\"\n",
      "INFO:gensim.models.ldamodel:topic #32 (0.010): 0.148*\"really\" + 0.061*\"exist\" + 0.044*\"hate\" + 0.041*\"does\" + 0.027*\"that\" + 0.026*\"once\" + 0.023*\"people\" + 0.023*\"amount\" + 0.022*\"evidence\" + 0.019*\"there\"\n",
      "INFO:gensim.models.ldamodel:topic #58 (0.010): 0.096*\"app\" + 0.094*\"using\" + 0.064*\"web\" + 0.052*\"java\" + 0.041*\"development\" + 0.037*\"living\" + 0.036*\"search\" + 0.027*\"developer\" + 0.026*\"an\" + 0.026*\"net\"\n",
      "INFO:gensim.models.ldamodel:topic #38 (0.010): 0.171*\"they\" + 0.143*\"new\" + 0.053*\"play\" + 0.041*\"looking\" + 0.039*\"universities\" + 0.039*\"from\" + 0.036*\"does\" + 0.024*\"never\" + 0.020*\"recruit\" + 0.019*\"majors\"\n",
      "INFO:gensim.models.ldamodel:topic #91 (0.010): 0.075*\"even\" + 0.066*\"days\" + 0.056*\"with\" + 0.047*\"deal\" + 0.038*\"period\" + 0.037*\"pregnant\" + 0.034*\"get\" + 0.024*\"my\" + 0.024*\"depression\" + 0.024*\"within\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.012886, rho=0.057831\n",
      "INFO:gensim.models.ldamodel:-8.068 per-word bound, 268.3 perplexity estimate based on a held-out corpus of 2000 documents with 15044 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #305 = documents up to #612000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #81 (0.010): 0.074*\"10\" + 0.050*\"windows\" + 0.043*\"problem\" + 0.029*\"words\" + 0.027*\"solve\" + 0.025*\"following\" + 0.024*\"does\" + 0.022*\"on\" + 0.022*\"it\" + 0.021*\"explain\"\n",
      "INFO:gensim.models.ldamodel:topic #76 (0.010): 0.072*\"watch\" + 0.050*\"something\" + 0.046*\"seen\" + 0.031*\"tax\" + 0.031*\"you\" + 0.024*\"season\" + 0.024*\"on\" + 0.022*\"movies\" + 0.022*\"an\" + 0.021*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic #90 (0.010): 0.128*\"2\" + 0.123*\"+\" + 0.105*\"c\" + 0.070*\"home\" + 0.032*\"foreign\" + 0.022*\"d\" + 0.022*\"n\" + 0.022*\"at\" + 0.020*\"good\" + 0.018*\"bring\"\n",
      "INFO:gensim.models.ldamodel:topic #46 (0.010): 0.051*\"reduce\" + 0.050*\"family\" + 0.049*\"air\" + 0.047*\"apps\" + 0.035*\"or\" + 0.034*\"uber\" + 0.023*\"special\" + 0.020*\"driver\" + 0.019*\"convince\" + 0.015*\"my\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.063*\"real\" + 0.056*\"america\" + 0.053*\"average\" + 0.050*\"food\" + 0.048*\"non\" + 0.040*\"age\" + 0.035*\"able\" + 0.028*\"child\" + 0.025*\"there\" + 0.024*\"married\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.013287, rho=0.057639\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #306 = documents up to #614000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #307 = documents up to #616000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #308 = documents up to #618000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.135*\"ways\" + 0.082*\"get\" + 0.056*\"rid\" + 0.056*\"some\" + 0.034*\"face\" + 0.030*\"on\" + 0.026*\"impact\" + 0.024*\"daily\" + 0.021*\"twitter\" + 0.020*\"my\"\n",
      "INFO:gensim.models.ldamodel:topic #29 (0.010): 0.054*\"build\" + 0.052*\"run\" + 0.049*\"death\" + 0.038*\"dogs\" + 0.037*\"suicide\" + 0.034*\"security\" + 0.033*\"least\" + 0.024*\"commit\" + 0.022*\"flat\" + 0.019*\"soon\"\n",
      "INFO:gensim.models.ldamodel:topic #20 (0.010): 0.065*\"place\" + 0.062*\"usa\" + 0.057*\"places\" + 0.053*\"visit\" + 0.042*\"visa\" + 0.041*\"public\" + 0.037*\"best\" + 0.031*\"india\" + 0.024*\"interested\" + 0.020*\"real\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.010): 0.244*\"where\" + 0.148*\"find\" + 0.049*\"get\" + 0.038*\"support\" + 0.025*\"times\" + 0.019*\"sim\" + 0.018*\"quickly\" + 0.018*\"religion\" + 0.017*\"out\" + 0.016*\"jio\"\n",
      "INFO:gensim.models.ldamodel:topic #72 (0.010): 0.119*\"their\" + 0.101*\"first\" + 0.087*\"day\" + 0.083*\"things\" + 0.074*\"into\" + 0.061*\"going\" + 0.055*\"know\" + 0.041*\"some\" + 0.041*\"should\" + 0.031*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.011919, rho=0.057448\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #309 = documents up to #620000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #310 = documents up to #622000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #70 (0.010): 0.170*\"quora\" + 0.107*\"on\" + 0.065*\"questions\" + 0.050*\"question\" + 0.044*\"ask\" + 0.030*\"answer\" + 0.030*\"people\" + 0.026*\"effects\" + 0.022*\"my\" + 0.021*\"as\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.134*\"ways\" + 0.082*\"get\" + 0.056*\"rid\" + 0.056*\"some\" + 0.034*\"face\" + 0.030*\"on\" + 0.026*\"impact\" + 0.024*\"daily\" + 0.021*\"twitter\" + 0.020*\"my\"\n",
      "INFO:gensim.models.ldamodel:topic #49 (0.010): 0.093*\"computer\" + 0.080*\"science\" + 0.076*\"data\" + 0.043*\"history\" + 0.033*\"both\" + 0.032*\"canada\" + 0.028*\"from\" + 0.027*\"others\" + 0.024*\"ms\" + 0.019*\"difficult\"\n",
      "INFO:gensim.models.ldamodel:topic #36 (0.010): 0.135*\"year\" + 0.108*\"old\" + 0.062*\"it\" + 0.054*\"true\" + 0.037*\"salary\" + 0.037*\"worth\" + 0.033*\"that\" + 0.027*\"fast\" + 0.024*\"an\" + 0.022*\"must\"\n",
      "INFO:gensim.models.ldamodel:topic #45 (0.010): 0.054*\"percent\" + 0.054*\"hard\" + 0.038*\"choose\" + 0.035*\"group\" + 0.034*\"single\" + 0.028*\"eating\" + 0.025*\"it\" + 0.024*\"grow\" + 0.021*\"paper\" + 0.021*\"loss\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.012199, rho=0.057260\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #311 = documents up to #624000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #312 = documents up to #626000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #62 (0.010): 0.097*\"engineering\" + 0.058*\"getting\" + 0.055*\"student\" + 0.046*\"university\" + 0.045*\"an\" + 0.038*\"students\" + 0.030*\"post\" + 0.029*\"civil\" + 0.026*\"after\" + 0.025*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #89 (0.010): 0.100*\"company\" + 0.082*\"software\" + 0.054*\"engineer\" + 0.046*\"another\" + 0.039*\"compare\" + 0.030*\"battle\" + 0.030*\"an\" + 0.026*\"term\" + 0.021*\"t\" + 0.021*\"solution\"\n",
      "INFO:gensim.models.ldamodel:topic #77 (0.010): 0.110*\"change\" + 0.051*\"around\" + 0.045*\"popular\" + 0.035*\"views\" + 0.033*\"decision\" + 0.026*\"it\" + 0.026*\"let\" + 0.023*\"linux\" + 0.023*\"!\" + 0.022*\"news\"\n",
      "INFO:gensim.models.ldamodel:topic #82 (0.010): 0.094*\"bad\" + 0.088*\"two\" + 0.062*\"game\" + 0.029*\"it\" + 0.029*\"fix\" + 0.027*\"blood\" + 0.027*\"you\" + 0.024*\"or\" + 0.022*\"try\" + 0.022*\"that\"\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.010): 0.086*\"look\" + 0.060*\"note\" + 0.046*\"currency\" + 0.042*\"ban\" + 0.036*\"does\" + 0.033*\"address\" + 0.032*\"corruption\" + 0.030*\"like\" + 0.022*\"hp\" + 0.022*\"building\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.012502, rho=0.057073\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #313 = documents up to #628000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #314 = documents up to #630000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #67 (0.010): 0.077*\"prepare\" + 0.066*\"water\" + 0.054*\"bank\" + 0.034*\"cat\" + 0.034*\"england\" + 0.034*\"mechanical\" + 0.033*\"education\" + 0.032*\"should\" + 0.029*\"invest\" + 0.026*\"again\"\n",
      "INFO:gensim.models.ldamodel:topic #71 (0.010): 0.059*\"private\" + 0.059*\"score\" + 0.048*\"startup\" + 0.042*\"advice\" + 0.040*\"engine\" + 0.036*\"get\" + 0.032*\"islam\" + 0.031*\"paid\" + 0.024*\"gre\" + 0.023*\"eyes\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.136*\"ways\" + 0.080*\"get\" + 0.057*\"some\" + 0.056*\"rid\" + 0.034*\"face\" + 0.029*\"on\" + 0.026*\"impact\" + 0.025*\"daily\" + 0.021*\"twitter\" + 0.020*\"good\"\n",
      "INFO:gensim.models.ldamodel:topic #53 (0.010): 0.159*\"system\" + 0.053*\"biggest\" + 0.050*\"operating\" + 0.031*\"similar\" + 0.031*\"personal\" + 0.028*\"buying\" + 0.027*\"device\" + 0.027*\"fake\" + 0.025*\"pain\" + 0.018*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #44 (0.010): 0.197*\"about\" + 0.153*\"you\" + 0.118*\"think\" + 0.061*\"stop\" + 0.052*\"people\" + 0.039*\"know\" + 0.029*\"that\" + 0.024*\"last\" + 0.020*\"not\" + 0.018*\"indians\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.011709, rho=0.056888\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #315 = documents up to #632000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #316 = documents up to #634000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #50 (0.010): 0.161*\"love\" + 0.131*\"used\" + 0.048*\"makes\" + 0.034*\"by\" + 0.033*\"fall\" + 0.032*\"on\" + 0.027*\"safety\" + 0.026*\"sentence\" + 0.024*\"proposed\" + 0.023*\"precautions\"\n",
      "INFO:gensim.models.ldamodel:topic #53 (0.010): 0.159*\"system\" + 0.052*\"biggest\" + 0.050*\"operating\" + 0.031*\"similar\" + 0.030*\"personal\" + 0.027*\"device\" + 0.027*\"fake\" + 0.027*\"buying\" + 0.025*\"pain\" + 0.018*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #56 (0.010): 0.066*\"some\" + 0.047*\"interesting\" + 0.046*\"about\" + 0.040*\"based\" + 0.038*\"facts\" + 0.033*\"australia\" + 0.032*\"known\" + 0.027*\"japanese\" + 0.026*\"model\" + 0.026*\"india\"\n",
      "INFO:gensim.models.ldamodel:topic #87 (0.010): 0.065*\"parents\" + 0.061*\"date\" + 0.030*\"with\" + 0.029*\"knowledge\" + 0.027*\"kids\" + 0.027*\"land\" + 0.018*\"candidate\" + 0.017*\"performance\" + 0.014*\"on\" + 0.013*\"fair\"\n",
      "INFO:gensim.models.ldamodel:topic #98 (0.010): 0.104*\"its\" + 0.059*\"download\" + 0.049*\"site\" + 0.038*\"less\" + 0.036*\"form\" + 0.027*\"office\" + 0.026*\"develop\" + 0.020*\"from\" + 0.020*\"india\" + 0.019*\"charge\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.010616, rho=0.056705\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #317 = documents up to #636000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #318 = documents up to #638000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #49 (0.010): 0.093*\"computer\" + 0.082*\"science\" + 0.077*\"data\" + 0.044*\"history\" + 0.032*\"both\" + 0.031*\"canada\" + 0.028*\"from\" + 0.028*\"others\" + 0.026*\"ms\" + 0.019*\"difficult\"\n",
      "INFO:gensim.models.ldamodel:topic #97 (0.010): 0.159*\"more\" + 0.150*\"than\" + 0.063*\"study\" + 0.059*\"give\" + 0.030*\"or\" + 0.026*\"2015\" + 0.024*\"germany\" + 0.018*\"exams\" + 0.016*\"please\" + 0.015*\"should\"\n",
      "INFO:gensim.models.ldamodel:topic #40 (0.010): 0.168*\"much\" + 0.065*\"live\" + 0.053*\"during\" + 0.051*\"it\" + 0.051*\"does\" + 0.042*\"future\" + 0.042*\"cost\" + 0.026*\"small\" + 0.026*\"behind\" + 0.024*\"so\"\n",
      "INFO:gensim.models.ldamodel:topic #22 (0.010): 0.104*\"see\" + 0.093*\"instagram\" + 0.061*\"hair\" + 0.059*\"on\" + 0.059*\"youtube\" + 0.039*\"my\" + 0.029*\"who\" + 0.026*\"beautiful\" + 0.021*\"currently\" + 0.019*\"most\"\n",
      "INFO:gensim.models.ldamodel:topic #16 (0.010): 0.114*\"college\" + 0.063*\"chinese\" + 0.049*\"major\" + 0.048*\"reason\" + 0.031*\"that\" + 0.029*\"contact\" + 0.028*\"everything\" + 0.027*\"changed\" + 0.024*\"away\" + 0.021*\"percentage\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.010921, rho=0.056523\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #319 = documents up to #640000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #320 = documents up to #642000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #10 (0.010): 0.154*\"phone\" + 0.106*\"buy\" + 0.053*\"under\" + 0.029*\"should\" + 0.026*\"benefits\" + 0.024*\"an\" + 0.023*\"6\" + 0.023*\"or\" + 0.020*\"iq\" + 0.019*\"problems\"\n",
      "INFO:gensim.models.ldamodel:topic #33 (0.010): 0.061*\"music\" + 0.059*\"2017\" + 0.053*\"power\" + 0.039*\"management\" + 0.039*\"move\" + 0.033*\"field\" + 0.032*\"compared\" + 0.031*\"courses\" + 0.031*\"new\" + 0.029*\"past\"\n",
      "INFO:gensim.models.ldamodel:topic #50 (0.010): 0.162*\"love\" + 0.130*\"used\" + 0.048*\"makes\" + 0.034*\"by\" + 0.032*\"fall\" + 0.032*\"on\" + 0.026*\"safety\" + 0.025*\"sentence\" + 0.024*\"proposed\" + 0.024*\"precautions\"\n",
      "INFO:gensim.models.ldamodel:topic #18 (0.010): 0.209*\"time\" + 0.081*\"business\" + 0.061*\"same\" + 0.045*\"back\" + 0.026*\"instead\" + 0.025*\"it\" + 0.024*\"physics\" + 0.024*\"at\" + 0.018*\"12\" + 0.017*\"from\"\n",
      "INFO:gensim.models.ldamodel:topic #52 (0.010): 0.131*\"possible\" + 0.111*\"it\" + 0.058*\"career\" + 0.048*\"travel\" + 0.032*\"house\" + 0.029*\"humans\" + 0.024*\"options\" + 0.021*\"check\" + 0.019*\"after\" + 0.019*\"animals\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.011444, rho=0.056344\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #321 = documents up to #644000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #322 = documents up to #646000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #47 (0.010): 0.127*\"does\" + 0.121*\"mean\" + 0.070*\"it\" + 0.044*\"too\" + 0.031*\"when\" + 0.029*\"plan\" + 0.029*\"call\" + 0.026*\"found\" + 0.021*\"says\" + 0.020*\"lot\"\n",
      "INFO:gensim.models.ldamodel:topic #99 (0.010): 0.146*\"google\" + 0.129*\"just\" + 0.035*\"speak\" + 0.035*\"view\" + 0.024*\"won\" + 0.022*\"on\" + 0.021*\"here\" + 0.018*\"sbi\" + 0.016*\"specific\" + 0.016*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic #79 (0.010): 0.166*\"2016\" + 0.062*\"kind\" + 0.046*\"overcome\" + 0.030*\"fear\" + 0.027*\"cut\" + 0.026*\"beginner\" + 0.022*\"expected\" + 0.018*\"designer\" + 0.018*\"off\" + 0.013*\"you\"\n",
      "INFO:gensim.models.ldamodel:topic #29 (0.010): 0.056*\"build\" + 0.053*\"run\" + 0.047*\"death\" + 0.041*\"dogs\" + 0.036*\"security\" + 0.035*\"suicide\" + 0.030*\"least\" + 0.022*\"flat\" + 0.021*\"commit\" + 0.018*\"soon\"\n",
      "INFO:gensim.models.ldamodel:topic #82 (0.010): 0.091*\"bad\" + 0.088*\"two\" + 0.064*\"game\" + 0.031*\"fix\" + 0.028*\"it\" + 0.027*\"you\" + 0.025*\"blood\" + 0.024*\"or\" + 0.024*\"try\" + 0.023*\"that\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.011390, rho=0.056166\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #323 = documents up to #648000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #324 = documents up to #650000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #29 (0.010): 0.055*\"build\" + 0.053*\"run\" + 0.046*\"death\" + 0.041*\"dogs\" + 0.036*\"security\" + 0.035*\"suicide\" + 0.030*\"least\" + 0.022*\"flat\" + 0.021*\"commit\" + 0.018*\"soon\"\n",
      "INFO:gensim.models.ldamodel:topic #86 (0.010): 0.131*\"books\" + 0.092*\"read\" + 0.066*\"very\" + 0.052*\"fat\" + 0.034*\"some\" + 0.034*\"theory\" + 0.025*\"moment\" + 0.024*\"you\" + 0.023*\"belly\" + 0.022*\"good\"\n",
      "INFO:gensim.models.ldamodel:topic #45 (0.010): 0.056*\"percent\" + 0.055*\"hard\" + 0.039*\"choose\" + 0.033*\"single\" + 0.033*\"group\" + 0.026*\"eating\" + 0.025*\"it\" + 0.022*\"grow\" + 0.021*\"football\" + 0.021*\"loss\"\n",
      "INFO:gensim.models.ldamodel:topic #30 (0.010): 0.326*\"make\" + 0.037*\"happened\" + 0.034*\"degree\" + 0.034*\"current\" + 0.033*\"you\" + 0.025*\"full\" + 0.023*\"does\" + 0.022*\"master\" + 0.019*\"obama\" + 0.015*\"french\"\n",
      "INFO:gensim.models.ldamodel:topic #88 (0.010): 0.156*\"many\" + 0.083*\"years\" + 0.052*\"5\" + 0.043*\"dollar\" + 0.035*\"so\" + 0.027*\"there\" + 0.024*\"hours\" + 0.024*\"week\" + 0.023*\"per\" + 0.021*\"20\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.010514, rho=0.055989\n",
      "INFO:gensim.models.ldamodel:-8.109 per-word bound, 276.2 perplexity estimate based on a held-out corpus of 2000 documents with 15285 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #325 = documents up to #652000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.102*\"over\" + 0.095*\"before\" + 0.069*\"bing\" + 0.037*\"class\" + 0.031*\"short\" + 0.029*\"correct\" + 0.024*\"red\" + 0.022*\"get\" + 0.022*\"structure\" + 0.021*\"because\"\n",
      "INFO:gensim.models.ldamodel:topic #80 (0.010): 0.076*\"write\" + 0.073*\"card\" + 0.065*\"body\" + 0.060*\"differences\" + 0.048*\"program\" + 0.046*\"medical\" + 0.033*\"credit\" + 0.030*\"basic\" + 0.021*\"pressure\" + 0.020*\"works\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.010): 0.067*\"every\" + 0.039*\"famous\" + 0.031*\"political\" + 0.027*\"capital\" + 0.023*\"towards\" + 0.023*\"systems\" + 0.021*\"voice\" + 0.021*\"trading\" + 0.021*\"cards\" + 0.018*\"moving\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.010): 0.089*\"my\" + 0.083*\"increase\" + 0.039*\"type\" + 0.039*\"height\" + 0.036*\"traffic\" + 0.036*\"dog\" + 0.034*\"get\" + 0.031*\"called\" + 0.026*\"function\" + 0.025*\"party\"\n",
      "INFO:gensim.models.ldamodel:topic #81 (0.010): 0.071*\"10\" + 0.052*\"windows\" + 0.042*\"problem\" + 0.028*\"words\" + 0.028*\"following\" + 0.027*\"solve\" + 0.024*\"on\" + 0.023*\"does\" + 0.022*\"explain\" + 0.022*\"this\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.011580, rho=0.055815\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #326 = documents up to #654000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #327 = documents up to #656000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #328 = documents up to #658000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.010): 0.179*\"learn\" + 0.161*\"start\" + 0.048*\"should\" + 0.035*\"idea\" + 0.033*\"technology\" + 0.032*\"order\" + 0.031*\"python\" + 0.025*\"sell\" + 0.024*\"learning\" + 0.021*\"enough\"\n",
      "INFO:gensim.models.ldamodel:topic #64 (0.010): 0.135*\"up\" + 0.102*\"need\" + 0.041*\"keep\" + 0.040*\"pay\" + 0.039*\"got\" + 0.029*\"cause\" + 0.026*\"does\" + 0.020*\"meet\" + 0.018*\"muslim\" + 0.017*\"chance\"\n",
      "INFO:gensim.models.ldamodel:topic #60 (0.010): 0.096*\"trump\" + 0.078*\"us\" + 0.070*\"take\" + 0.063*\"donald\" + 0.056*\"will\" + 0.045*\"president\" + 0.043*\"clinton\" + 0.040*\"win\" + 0.038*\"hillary\" + 0.037*\"who\"\n",
      "INFO:gensim.models.ldamodel:topic #78 (0.010): 0.213*\"money\" + 0.171*\"online\" + 0.066*\"earn\" + 0.034*\"available\" + 0.031*\"from\" + 0.030*\"easy\" + 0.024*\"colleges\" + 0.020*\"way\" + 0.017*\"there\" + 0.016*\"break\"\n",
      "INFO:gensim.models.ldamodel:topic #84 (0.010): 0.111*\"book\" + 0.070*\"name\" + 0.061*\"tv\" + 0.050*\"series\" + 0.031*\"ias\" + 0.029*\"left\" + 0.023*\"officer\" + 0.021*\"on\" + 0.021*\"hire\" + 0.021*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.010392, rho=0.055641\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #329 = documents up to #660000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #330 = documents up to #662000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #21 (0.010): 0.253*\"/\" + 0.054*\"math\" + 0.052*\"1\" + 0.051*\"exam\" + 0.042*\"]\" + 0.042*\"[\" + 0.035*\"x\" + 0.028*\"games\" + 0.023*\"\\\" + 0.021*\"gate\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.010): 0.188*\"if\" + 0.171*\"would\" + 0.068*\"be\" + 0.061*\"you\" + 0.035*\"happen\" + 0.031*\"it\" + 0.031*\"will\" + 0.028*\"car\" + 0.024*\"then\" + 0.018*\"could\"\n",
      "INFO:gensim.models.ldamodel:topic #53 (0.010): 0.157*\"system\" + 0.051*\"biggest\" + 0.047*\"operating\" + 0.034*\"similar\" + 0.033*\"personal\" + 0.028*\"buying\" + 0.027*\"fake\" + 0.027*\"pain\" + 0.025*\"device\" + 0.018*\"location\"\n",
      "INFO:gensim.models.ldamodel:topic #65 (0.010): 0.063*\"android\" + 0.055*\"working\" + 0.053*\"social\" + 0.052*\"end\" + 0.041*\"always\" + 0.040*\"today\" + 0.037*\"whatsapp\" + 0.035*\"on\" + 0.031*\"ideas\" + 0.029*\"media\"\n",
      "INFO:gensim.models.ldamodel:topic #72 (0.010): 0.120*\"their\" + 0.100*\"first\" + 0.088*\"day\" + 0.081*\"things\" + 0.075*\"into\" + 0.062*\"going\" + 0.061*\"know\" + 0.040*\"some\" + 0.038*\"should\" + 0.031*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.011100, rho=0.055470\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #331 = documents up to #664000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #332 = documents up to #666000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #55 (0.010): 0.115*\"number\" + 0.064*\"tech\" + 0.044*\"list\" + 0.038*\"from\" + 0.037*\"remove\" + 0.037*\"m\" + 0.033*\"exactly\" + 0.021*\"after\" + 0.019*\"does\" + 0.016*\"acid\"\n",
      "INFO:gensim.models.ldamodel:topic #43 (0.010): 0.153*\"job\" + 0.070*\"through\" + 0.056*\"interview\" + 0.056*\"learning\" + 0.049*\"tips\" + 0.045*\"get\" + 0.044*\"some\" + 0.044*\"process\" + 0.044*\"making\" + 0.042*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #60 (0.010): 0.096*\"trump\" + 0.076*\"us\" + 0.070*\"take\" + 0.062*\"donald\" + 0.056*\"will\" + 0.044*\"president\" + 0.044*\"clinton\" + 0.041*\"win\" + 0.039*\"hillary\" + 0.037*\"who\"\n",
      "INFO:gensim.models.ldamodel:topic #84 (0.010): 0.115*\"book\" + 0.069*\"name\" + 0.061*\"tv\" + 0.051*\"series\" + 0.032*\"ias\" + 0.028*\"left\" + 0.023*\"officer\" + 0.022*\"on\" + 0.021*\"hire\" + 0.021*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.010): 0.124*\"my\" + 0.094*\"account\" + 0.079*\"facebook\" + 0.041*\"password\" + 0.037*\"email\" + 0.030*\"gmail\" + 0.029*\"from\" + 0.025*\"delete\" + 0.023*\"recover\" + 0.018*\"not\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.009513, rho=0.055300\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #333 = documents up to #668000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #334 = documents up to #670000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #56 (0.010): 0.068*\"some\" + 0.049*\"interesting\" + 0.048*\"about\" + 0.039*\"facts\" + 0.038*\"based\" + 0.033*\"known\" + 0.031*\"australia\" + 0.027*\"india\" + 0.026*\"model\" + 0.025*\"japanese\"\n",
      "INFO:gensim.models.ldamodel:topic #41 (0.010): 0.064*\"human\" + 0.060*\"state\" + 0.054*\"considered\" + 0.053*\"video\" + 0.037*\"terms\" + 0.034*\"point\" + 0.034*\"matter\" + 0.033*\"worst\" + 0.030*\"store\" + 0.025*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #97 (0.010): 0.162*\"more\" + 0.155*\"than\" + 0.067*\"study\" + 0.055*\"give\" + 0.031*\"or\" + 0.025*\"2015\" + 0.024*\"germany\" + 0.018*\"exams\" + 0.017*\"please\" + 0.014*\"should\"\n",
      "INFO:gensim.models.ldamodel:topic #47 (0.010): 0.127*\"does\" + 0.120*\"mean\" + 0.071*\"it\" + 0.046*\"too\" + 0.033*\"when\" + 0.029*\"call\" + 0.028*\"found\" + 0.027*\"plan\" + 0.020*\"lot\" + 0.020*\"says\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.100*\"before\" + 0.099*\"over\" + 0.069*\"bing\" + 0.037*\"class\" + 0.031*\"short\" + 0.027*\"red\" + 0.027*\"correct\" + 0.023*\"structure\" + 0.021*\"get\" + 0.021*\"because\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.010223, rho=0.055132\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #335 = documents up to #672000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #336 = documents up to #674000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #71 (0.010): 0.064*\"score\" + 0.055*\"private\" + 0.050*\"startup\" + 0.040*\"advice\" + 0.038*\"get\" + 0.035*\"engine\" + 0.034*\"paid\" + 0.033*\"islam\" + 0.028*\"gre\" + 0.026*\"eyes\"\n",
      "INFO:gensim.models.ldamodel:topic #68 (0.010): 0.113*\"language\" + 0.101*\"programming\" + 0.091*\"website\" + 0.043*\"learn\" + 0.040*\"open\" + 0.040*\"hack\" + 0.029*\"cons\" + 0.028*\"pros\" + 0.028*\"low\" + 0.027*\"languages\"\n",
      "INFO:gensim.models.ldamodel:topic #41 (0.010): 0.064*\"human\" + 0.059*\"state\" + 0.055*\"video\" + 0.053*\"considered\" + 0.037*\"terms\" + 0.035*\"matter\" + 0.034*\"point\" + 0.032*\"worst\" + 0.030*\"store\" + 0.025*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #47 (0.010): 0.128*\"does\" + 0.120*\"mean\" + 0.070*\"it\" + 0.046*\"too\" + 0.033*\"when\" + 0.029*\"found\" + 0.028*\"call\" + 0.027*\"plan\" + 0.020*\"says\" + 0.020*\"lot\"\n",
      "INFO:gensim.models.ldamodel:topic #96 (0.010): 0.396*\"have\" + 0.081*\"you\" + 0.058*\"had\" + 0.032*\"if\" + 0.031*\"been\" + 0.022*\"not\" + 0.018*\"that\" + 0.017*\"any\" + 0.016*\"international\" + 0.016*\"night\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.009786, rho=0.054965\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #337 = documents up to #676000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #338 = documents up to #678000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.010): 0.072*\"every\" + 0.039*\"famous\" + 0.031*\"political\" + 0.029*\"capital\" + 0.025*\"systems\" + 0.024*\"towards\" + 0.021*\"cards\" + 0.021*\"voice\" + 0.021*\"trading\" + 0.020*\"banks\"\n",
      "INFO:gensim.models.ldamodel:topic #61 (0.010): 0.130*\"thing\" + 0.062*\"you\" + 0.053*\"demonetization\" + 0.043*\"that\" + 0.041*\"given\" + 0.034*\"most\" + 0.031*\"second\" + 0.031*\"advantages\" + 0.026*\"calculate\" + 0.024*\"income\"\n",
      "INFO:gensim.models.ldamodel:topic #40 (0.010): 0.174*\"much\" + 0.065*\"live\" + 0.053*\"does\" + 0.053*\"during\" + 0.049*\"it\" + 0.045*\"cost\" + 0.042*\"future\" + 0.026*\"behind\" + 0.026*\"so\" + 0.025*\"small\"\n",
      "INFO:gensim.models.ldamodel:topic #20 (0.010): 0.063*\"place\" + 0.059*\"usa\" + 0.057*\"places\" + 0.054*\"visit\" + 0.040*\"public\" + 0.038*\"visa\" + 0.034*\"india\" + 0.031*\"best\" + 0.023*\"interested\" + 0.022*\"estate\"\n",
      "INFO:gensim.models.ldamodel:topic #30 (0.010): 0.324*\"make\" + 0.038*\"happened\" + 0.036*\"degree\" + 0.033*\"current\" + 0.033*\"you\" + 0.028*\"full\" + 0.023*\"master\" + 0.023*\"does\" + 0.020*\"obama\" + 0.016*\"pune\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.009804, rho=0.054800\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #339 = documents up to #680000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #340 = documents up to #682000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #15 (0.010): 0.202*\"we\" + 0.053*\"women\" + 0.049*\"our\" + 0.045*\"made\" + 0.041*\"men\" + 0.041*\"right\" + 0.040*\"say\" + 0.040*\"now\" + 0.037*\"china\" + 0.033*\"happens\"\n",
      "INFO:gensim.models.ldamodel:topic #71 (0.010): 0.064*\"score\" + 0.056*\"private\" + 0.052*\"startup\" + 0.039*\"advice\" + 0.038*\"get\" + 0.036*\"engine\" + 0.033*\"paid\" + 0.033*\"islam\" + 0.029*\"gre\" + 0.026*\"eyes\"\n",
      "INFO:gensim.models.ldamodel:topic #91 (0.010): 0.072*\"even\" + 0.067*\"days\" + 0.056*\"with\" + 0.046*\"deal\" + 0.041*\"period\" + 0.040*\"pregnant\" + 0.035*\"get\" + 0.023*\"after\" + 0.023*\"depression\" + 0.021*\"within\"\n",
      "INFO:gensim.models.ldamodel:topic #37 (0.010): 0.228*\"has\" + 0.047*\"been\" + 0.045*\"next\" + 0.036*\"apple\" + 0.028*\"size\" + 0.025*\"often\" + 0.024*\"set\" + 0.023*\"quality\" + 0.021*\"already\" + 0.021*\"americans\"\n",
      "INFO:gensim.models.ldamodel:topic #17 (0.010): 0.074*\"no\" + 0.056*\"energy\" + 0.040*\"god\" + 0.039*\"believe\" + 0.037*\"if\" + 0.036*\"that\" + 0.035*\"there\" + 0.034*\"actually\" + 0.032*\"dark\" + 0.026*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.009545, rho=0.054636\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #341 = documents up to #684000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #342 = documents up to #686000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #32 (0.010): 0.151*\"really\" + 0.058*\"exist\" + 0.042*\"hate\" + 0.040*\"does\" + 0.029*\"that\" + 0.025*\"once\" + 0.023*\"people\" + 0.022*\"amount\" + 0.021*\"evidence\" + 0.019*\"there\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.310*\"your\" + 0.144*\"life\" + 0.114*\"you\" + 0.041*\"school\" + 0.037*\"high\" + 0.028*\"favorite\" + 0.020*\"join\" + 0.014*\"was\" + 0.013*\"on\" + 0.013*\"most\"\n",
      "INFO:gensim.models.ldamodel:topic #58 (0.010): 0.108*\"using\" + 0.096*\"app\" + 0.067*\"web\" + 0.052*\"java\" + 0.042*\"living\" + 0.042*\"development\" + 0.036*\"search\" + 0.028*\"developer\" + 0.025*\"android\" + 0.025*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #17 (0.010): 0.075*\"no\" + 0.057*\"energy\" + 0.042*\"god\" + 0.040*\"believe\" + 0.037*\"if\" + 0.036*\"that\" + 0.036*\"there\" + 0.034*\"actually\" + 0.032*\"dark\" + 0.026*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic #75 (0.010): 0.076*\"while\" + 0.071*\"doing\" + 0.052*\"internet\" + 0.044*\"wrong\" + 0.040*\"modi\" + 0.039*\"part\" + 0.030*\"studying\" + 0.026*\"sydney\" + 0.023*\"narendra\" + 0.022*\"final\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.009100, rho=0.054473\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #343 = documents up to #688000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #344 = documents up to #690000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #42 (0.010): 0.107*\"different\" + 0.098*\"help\" + 0.063*\"companies\" + 0.052*\"white\" + 0.042*\"self\" + 0.040*\"culture\" + 0.036*\"songs\" + 0.033*\"gain\" + 0.019*\"like\" + 0.018*\"some\"\n",
      "INFO:gensim.models.ldamodel:topic #66 (0.010): 0.182*\"ever\" + 0.088*\"you\" + 0.082*\"have\" + 0.054*\"done\" + 0.037*\"space\" + 0.032*\"coaching\" + 0.025*\"institute\" + 0.023*\"most\" + 0.022*\"training\" + 0.020*\"best\"\n",
      "INFO:gensim.models.ldamodel:topic #86 (0.010): 0.131*\"books\" + 0.091*\"read\" + 0.067*\"very\" + 0.051*\"fat\" + 0.035*\"theory\" + 0.034*\"some\" + 0.025*\"belly\" + 0.024*\"moment\" + 0.024*\"good\" + 0.023*\"you\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.310*\"your\" + 0.144*\"life\" + 0.114*\"you\" + 0.041*\"school\" + 0.036*\"high\" + 0.028*\"favorite\" + 0.020*\"join\" + 0.013*\"was\" + 0.013*\"on\" + 0.013*\"most\"\n",
      "INFO:gensim.models.ldamodel:topic #77 (0.010): 0.118*\"change\" + 0.052*\"around\" + 0.044*\"popular\" + 0.037*\"decision\" + 0.035*\"views\" + 0.028*\"let\" + 0.026*\"it\" + 0.023*\"news\" + 0.022*\"linux\" + 0.022*\"!\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.008804, rho=0.054313\n",
      "INFO:gensim.models.ldamodel:-8.203 per-word bound, 294.7 perplexity estimate based on a held-out corpus of 2000 documents with 15284 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #345 = documents up to #692000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #84 (0.010): 0.111*\"book\" + 0.071*\"name\" + 0.058*\"tv\" + 0.049*\"series\" + 0.032*\"ias\" + 0.029*\"left\" + 0.023*\"hire\" + 0.022*\"officer\" + 0.021*\"on\" + 0.021*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #17 (0.010): 0.075*\"no\" + 0.055*\"energy\" + 0.043*\"god\" + 0.041*\"believe\" + 0.037*\"that\" + 0.036*\"there\" + 0.036*\"if\" + 0.033*\"actually\" + 0.032*\"dark\" + 0.027*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic #40 (0.010): 0.176*\"much\" + 0.066*\"live\" + 0.053*\"does\" + 0.051*\"during\" + 0.049*\"it\" + 0.047*\"cost\" + 0.043*\"future\" + 0.027*\"behind\" + 0.026*\"so\" + 0.025*\"small\"\n",
      "INFO:gensim.models.ldamodel:topic #71 (0.010): 0.064*\"score\" + 0.058*\"private\" + 0.051*\"startup\" + 0.040*\"advice\" + 0.039*\"get\" + 0.034*\"paid\" + 0.034*\"engine\" + 0.032*\"islam\" + 0.028*\"gre\" + 0.027*\"eyes\"\n",
      "INFO:gensim.models.ldamodel:topic #57 (0.010): 0.462*\"\"\" + 0.059*\"important\" + 0.057*\"examples\" + 0.050*\"some\" + 0.020*\"side\" + 0.018*\"you\" + 0.014*\"word\" + 0.011*\"dead\" + 0.011*\"quoted_item\" + 0.010*\"2014\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.008851, rho=0.054153\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #346 = documents up to #694000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #347 = documents up to #696000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #348 = documents up to #698000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #71 (0.010): 0.066*\"score\" + 0.059*\"private\" + 0.050*\"startup\" + 0.039*\"advice\" + 0.039*\"get\" + 0.034*\"engine\" + 0.033*\"paid\" + 0.033*\"islam\" + 0.028*\"gre\" + 0.026*\"eyes\"\n",
      "INFO:gensim.models.ldamodel:topic #29 (0.010): 0.057*\"build\" + 0.054*\"run\" + 0.050*\"death\" + 0.036*\"security\" + 0.036*\"dogs\" + 0.035*\"suicide\" + 0.029*\"least\" + 0.023*\"commit\" + 0.022*\"flat\" + 0.017*\"after\"\n",
      "INFO:gensim.models.ldamodel:topic #69 (0.010): 0.407*\"best\" + 0.215*\"which\" + 0.083*\"way\" + 0.027*\"country\" + 0.025*\"india\" + 0.019*\"laptop\" + 0.016*\"marketing\" + 0.016*\"test\" + 0.015*\"market\" + 0.015*\"course\"\n",
      "INFO:gensim.models.ldamodel:topic #74 (0.010): 0.044*\"star\" + 0.037*\"does\" + 0.037*\"industry\" + 0.036*\"moon\" + 0.032*\"sun\" + 0.031*\"option\" + 0.028*\"sound\" + 0.025*\"wars\" + 0.023*\"php\" + 0.020*\"gravity\"\n",
      "INFO:gensim.models.ldamodel:topic #49 (0.010): 0.096*\"computer\" + 0.083*\"science\" + 0.080*\"data\" + 0.046*\"history\" + 0.032*\"both\" + 0.030*\"canada\" + 0.029*\"from\" + 0.028*\"ms\" + 0.026*\"others\" + 0.021*\"difficult\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.009779, rho=0.053995\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #349 = documents up to #700000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #350 = documents up to #702000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #98 (0.010): 0.099*\"its\" + 0.061*\"download\" + 0.051*\"site\" + 0.042*\"less\" + 0.035*\"form\" + 0.027*\"develop\" + 0.026*\"office\" + 0.022*\"from\" + 0.021*\"charge\" + 0.018*\"india\"\n",
      "INFO:gensim.models.ldamodel:topic #39 (0.010): 0.106*\"top\" + 0.087*\"own\" + 0.043*\"normal\" + 0.039*\"bollywood\" + 0.035*\"page\" + 0.034*\"green\" + 0.029*\"on\" + 0.027*\"who\" + 0.025*\"hollywood\" + 0.024*\"tea\"\n",
      "INFO:gensim.models.ldamodel:topic #97 (0.010): 0.167*\"more\" + 0.157*\"than\" + 0.068*\"study\" + 0.053*\"give\" + 0.030*\"or\" + 0.025*\"2015\" + 0.023*\"germany\" + 0.018*\"exams\" + 0.017*\"please\" + 0.013*\"should\"\n",
      "INFO:gensim.models.ldamodel:topic #47 (0.010): 0.125*\"does\" + 0.121*\"mean\" + 0.069*\"it\" + 0.045*\"too\" + 0.033*\"when\" + 0.030*\"call\" + 0.027*\"plan\" + 0.027*\"found\" + 0.021*\"says\" + 0.021*\"line\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.010): 0.144*\"someone\" + 0.082*\"them\" + 0.072*\"you\" + 0.072*\"but\" + 0.045*\"not\" + 0.039*\"if\" + 0.033*\"on\" + 0.027*\"it\" + 0.027*\"when\" + 0.026*\"with\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.009845, rho=0.053838\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #351 = documents up to #704000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #352 = documents up to #706000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #33 (0.010): 0.059*\"music\" + 0.056*\"2017\" + 0.053*\"power\" + 0.043*\"management\" + 0.036*\"move\" + 0.034*\"compared\" + 0.033*\"field\" + 0.032*\"new\" + 0.029*\"courses\" + 0.029*\"past\"\n",
      "INFO:gensim.models.ldamodel:topic #36 (0.010): 0.131*\"year\" + 0.105*\"old\" + 0.063*\"it\" + 0.054*\"true\" + 0.042*\"worth\" + 0.035*\"salary\" + 0.031*\"that\" + 0.029*\"fast\" + 0.025*\"must\" + 0.024*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #38 (0.010): 0.195*\"they\" + 0.141*\"new\" + 0.049*\"play\" + 0.042*\"looking\" + 0.038*\"universities\" + 0.036*\"from\" + 0.033*\"does\" + 0.021*\"never\" + 0.019*\"recruit\" + 0.017*\"majors\"\n",
      "INFO:gensim.models.ldamodel:topic #71 (0.010): 0.066*\"score\" + 0.060*\"private\" + 0.051*\"startup\" + 0.039*\"get\" + 0.039*\"advice\" + 0.035*\"engine\" + 0.034*\"paid\" + 0.032*\"islam\" + 0.028*\"gre\" + 0.025*\"eyes\"\n",
      "INFO:gensim.models.ldamodel:topic #13 (0.010): 0.055*\"song\" + 0.050*\"control\" + 0.040*\"ca\" + 0.039*\"california\" + 0.037*\"solar\" + 0.036*\"research\" + 0.030*\"provider\" + 0.030*\"healthy\" + 0.029*\"avoid\" + 0.027*\"good\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.008940, rho=0.053683\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #353 = documents up to #708000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #354 = documents up to #710000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #74 (0.010): 0.046*\"star\" + 0.038*\"does\" + 0.037*\"industry\" + 0.035*\"moon\" + 0.033*\"option\" + 0.030*\"sun\" + 0.028*\"sound\" + 0.026*\"wars\" + 0.022*\"php\" + 0.022*\"gravity\"\n",
      "INFO:gensim.models.ldamodel:topic #70 (0.010): 0.172*\"quora\" + 0.107*\"on\" + 0.068*\"questions\" + 0.051*\"question\" + 0.044*\"ask\" + 0.033*\"people\" + 0.032*\"answer\" + 0.024*\"effects\" + 0.021*\"as\" + 0.020*\"these\"\n",
      "INFO:gensim.models.ldamodel:topic #69 (0.010): 0.408*\"best\" + 0.214*\"which\" + 0.084*\"way\" + 0.028*\"country\" + 0.025*\"india\" + 0.019*\"laptop\" + 0.016*\"marketing\" + 0.015*\"test\" + 0.015*\"course\" + 0.014*\"market\"\n",
      "INFO:gensim.models.ldamodel:topic #38 (0.010): 0.194*\"they\" + 0.140*\"new\" + 0.050*\"play\" + 0.042*\"looking\" + 0.038*\"universities\" + 0.037*\"from\" + 0.033*\"does\" + 0.020*\"never\" + 0.020*\"recruit\" + 0.018*\"grads\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.311*\"your\" + 0.145*\"life\" + 0.113*\"you\" + 0.040*\"school\" + 0.036*\"high\" + 0.028*\"favorite\" + 0.019*\"join\" + 0.013*\"on\" + 0.013*\"was\" + 0.013*\"most\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.009070, rho=0.053529\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #355 = documents up to #712000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #356 = documents up to #714000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #36 (0.010): 0.130*\"year\" + 0.104*\"old\" + 0.064*\"it\" + 0.056*\"true\" + 0.040*\"worth\" + 0.035*\"salary\" + 0.032*\"that\" + 0.029*\"fast\" + 0.025*\"must\" + 0.025*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #34 (0.010): 0.049*\"legal\" + 0.047*\"product\" + 0.043*\"happy\" + 0.029*\"written\" + 0.029*\"be\" + 0.027*\"passport\" + 0.025*\"expect\" + 0.024*\"core\" + 0.023*\"needs\" + 0.022*\"resolution\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.010): 0.089*\"my\" + 0.079*\"increase\" + 0.042*\"type\" + 0.038*\"height\" + 0.038*\"traffic\" + 0.035*\"get\" + 0.031*\"dog\" + 0.031*\"called\" + 0.028*\"function\" + 0.027*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic #91 (0.010): 0.071*\"even\" + 0.068*\"days\" + 0.053*\"with\" + 0.043*\"deal\" + 0.042*\"period\" + 0.039*\"pregnant\" + 0.034*\"get\" + 0.025*\"depression\" + 0.024*\"after\" + 0.021*\"within\"\n",
      "INFO:gensim.models.ldamodel:topic #46 (0.010): 0.059*\"family\" + 0.057*\"reduce\" + 0.053*\"apps\" + 0.050*\"air\" + 0.035*\"or\" + 0.034*\"uber\" + 0.022*\"convince\" + 0.021*\"special\" + 0.018*\"driver\" + 0.016*\"with\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.008947, rho=0.053376\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #357 = documents up to #716000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #358 = documents up to #718000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #61 (0.010): 0.129*\"thing\" + 0.058*\"you\" + 0.053*\"demonetization\" + 0.042*\"that\" + 0.040*\"given\" + 0.034*\"most\" + 0.029*\"advantages\" + 0.028*\"calculate\" + 0.027*\"second\" + 0.023*\"taken\"\n",
      "INFO:gensim.models.ldamodel:topic #25 (0.010): 0.052*\"girl\" + 0.049*\"friends\" + 0.048*\"tell\" + 0.047*\"guy\" + 0.044*\"eat\" + 0.039*\"mind\" + 0.035*\"american\" + 0.033*\"woman\" + 0.030*\"common\" + 0.028*\"that\"\n",
      "INFO:gensim.models.ldamodel:topic #47 (0.010): 0.127*\"does\" + 0.123*\"mean\" + 0.070*\"it\" + 0.045*\"too\" + 0.031*\"when\" + 0.030*\"call\" + 0.028*\"plan\" + 0.026*\"found\" + 0.023*\"says\" + 0.021*\"line\"\n",
      "INFO:gensim.models.ldamodel:topic #34 (0.010): 0.049*\"legal\" + 0.045*\"product\" + 0.043*\"happy\" + 0.029*\"be\" + 0.029*\"written\" + 0.026*\"passport\" + 0.025*\"expect\" + 0.025*\"core\" + 0.023*\"needs\" + 0.022*\"resolution\"\n",
      "INFO:gensim.models.ldamodel:topic #86 (0.010): 0.131*\"books\" + 0.095*\"read\" + 0.067*\"very\" + 0.051*\"fat\" + 0.035*\"theory\" + 0.033*\"some\" + 0.027*\"belly\" + 0.025*\"moment\" + 0.024*\"good\" + 0.023*\"you\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.008405, rho=0.053225\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #359 = documents up to #720000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #360 = documents up to #722000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #80 (0.010): 0.078*\"write\" + 0.073*\"card\" + 0.065*\"differences\" + 0.062*\"body\" + 0.047*\"program\" + 0.043*\"medical\" + 0.035*\"credit\" + 0.032*\"basic\" + 0.020*\"pressure\" + 0.020*\"works\"\n",
      "INFO:gensim.models.ldamodel:topic #40 (0.010): 0.176*\"much\" + 0.066*\"live\" + 0.055*\"does\" + 0.050*\"during\" + 0.050*\"it\" + 0.045*\"cost\" + 0.043*\"future\" + 0.028*\"behind\" + 0.025*\"so\" + 0.024*\"small\"\n",
      "INFO:gensim.models.ldamodel:topic #37 (0.010): 0.229*\"has\" + 0.049*\"next\" + 0.046*\"been\" + 0.036*\"apple\" + 0.026*\"size\" + 0.025*\"set\" + 0.024*\"often\" + 0.022*\"already\" + 0.022*\"quality\" + 0.020*\"when\"\n",
      "INFO:gensim.models.ldamodel:topic #47 (0.010): 0.129*\"does\" + 0.124*\"mean\" + 0.069*\"it\" + 0.044*\"too\" + 0.031*\"when\" + 0.030*\"call\" + 0.028*\"plan\" + 0.026*\"found\" + 0.023*\"says\" + 0.021*\"line\"\n",
      "INFO:gensim.models.ldamodel:topic #48 (0.010): 0.154*\"other\" + 0.057*\"government\" + 0.051*\"against\" + 0.043*\"india\" + 0.041*\"each\" + 0.024*\"products\" + 0.022*\"any\" + 0.022*\"not\" + 0.022*\"text\" + 0.021*\"numbers\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.008067, rho=0.053074\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #361 = documents up to #724000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #362 = documents up to #726000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #44 (0.010): 0.196*\"about\" + 0.156*\"you\" + 0.124*\"think\" + 0.059*\"stop\" + 0.050*\"people\" + 0.040*\"know\" + 0.033*\"that\" + 0.021*\"last\" + 0.019*\"indians\" + 0.018*\"not\"\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.010): 0.095*\"look\" + 0.058*\"note\" + 0.048*\"currency\" + 0.047*\"ban\" + 0.037*\"does\" + 0.035*\"address\" + 0.030*\"like\" + 0.026*\"corruption\" + 0.023*\"forgot\" + 0.022*\"building\"\n",
      "INFO:gensim.models.ldamodel:topic #97 (0.010): 0.166*\"more\" + 0.157*\"than\" + 0.067*\"study\" + 0.056*\"give\" + 0.030*\"or\" + 0.024*\"2015\" + 0.023*\"germany\" + 0.018*\"exams\" + 0.016*\"please\" + 0.013*\"modern\"\n",
      "INFO:gensim.models.ldamodel:topic #53 (0.010): 0.153*\"system\" + 0.050*\"biggest\" + 0.046*\"operating\" + 0.039*\"similar\" + 0.034*\"personal\" + 0.028*\"pain\" + 0.027*\"buying\" + 0.026*\"fake\" + 0.025*\"device\" + 0.018*\"amazing\"\n",
      "INFO:gensim.models.ldamodel:topic #45 (0.010): 0.054*\"hard\" + 0.052*\"percent\" + 0.036*\"choose\" + 0.035*\"group\" + 0.034*\"single\" + 0.027*\"it\" + 0.024*\"eating\" + 0.023*\"paper\" + 0.022*\"grow\" + 0.021*\"loss\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.008296, rho=0.052926\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #363 = documents up to #728000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #364 = documents up to #730000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #81 (0.010): 0.076*\"10\" + 0.052*\"windows\" + 0.042*\"problem\" + 0.028*\"solve\" + 0.028*\"words\" + 0.026*\"following\" + 0.024*\"on\" + 0.023*\"this\" + 0.023*\"explain\" + 0.022*\"it\"\n",
      "INFO:gensim.models.ldamodel:topic #79 (0.010): 0.153*\"2016\" + 0.066*\"kind\" + 0.047*\"overcome\" + 0.029*\"cut\" + 0.029*\"fear\" + 0.028*\"beginner\" + 0.020*\"expected\" + 0.019*\"designer\" + 0.019*\"off\" + 0.014*\"was\"\n",
      "INFO:gensim.models.ldamodel:topic #49 (0.010): 0.094*\"computer\" + 0.084*\"science\" + 0.077*\"data\" + 0.044*\"history\" + 0.031*\"both\" + 0.030*\"canada\" + 0.029*\"from\" + 0.027*\"ms\" + 0.025*\"others\" + 0.019*\"difficult\"\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.010): 0.093*\"look\" + 0.058*\"note\" + 0.048*\"currency\" + 0.046*\"ban\" + 0.037*\"does\" + 0.035*\"address\" + 0.030*\"like\" + 0.026*\"corruption\" + 0.023*\"forgot\" + 0.022*\"building\"\n",
      "INFO:gensim.models.ldamodel:topic #34 (0.010): 0.049*\"legal\" + 0.047*\"product\" + 0.045*\"happy\" + 0.029*\"be\" + 0.029*\"written\" + 0.027*\"expect\" + 0.025*\"core\" + 0.025*\"passport\" + 0.022*\"needs\" + 0.020*\"resolution\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.008460, rho=0.052778\n",
      "INFO:gensim.models.ldamodel:-8.091 per-word bound, 272.6 perplexity estimate based on a held-out corpus of 2000 documents with 15674 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #365 = documents up to #732000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #92 (0.010): 0.153*\"become\" + 0.051*\"come\" + 0.042*\"create\" + 0.034*\"jobs\" + 0.031*\"an\" + 0.029*\"sleep\" + 0.028*\"from\" + 0.025*\"does\" + 0.025*\"drive\" + 0.023*\"did\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.100*\"before\" + 0.097*\"over\" + 0.062*\"bing\" + 0.035*\"class\" + 0.033*\"short\" + 0.031*\"correct\" + 0.027*\"red\" + 0.024*\"structure\" + 0.022*\"get\" + 0.020*\"because\"\n",
      "INFO:gensim.models.ldamodel:topic #79 (0.010): 0.153*\"2016\" + 0.066*\"kind\" + 0.049*\"overcome\" + 0.030*\"fear\" + 0.029*\"cut\" + 0.027*\"beginner\" + 0.019*\"designer\" + 0.019*\"expected\" + 0.018*\"off\" + 0.014*\"was\"\n",
      "INFO:gensim.models.ldamodel:topic #71 (0.010): 0.062*\"score\" + 0.057*\"private\" + 0.050*\"startup\" + 0.041*\"advice\" + 0.040*\"get\" + 0.035*\"engine\" + 0.031*\"paid\" + 0.030*\"islam\" + 0.027*\"gre\" + 0.025*\"eyes\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.010): 0.198*\"if\" + 0.167*\"would\" + 0.067*\"be\" + 0.064*\"you\" + 0.037*\"happen\" + 0.034*\"it\" + 0.030*\"will\" + 0.030*\"car\" + 0.024*\"then\" + 0.019*\"could\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.008676, rho=0.052632\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #366 = documents up to #734000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #367 = documents up to #736000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #368 = documents up to #738000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #77 (0.010): 0.114*\"change\" + 0.051*\"around\" + 0.048*\"popular\" + 0.035*\"decision\" + 0.032*\"views\" + 0.028*\"let\" + 0.026*\"it\" + 0.023*\"news\" + 0.022*\"!\" + 0.022*\"linux\"\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.010): 0.091*\"look\" + 0.060*\"note\" + 0.049*\"currency\" + 0.044*\"ban\" + 0.038*\"does\" + 0.033*\"address\" + 0.029*\"like\" + 0.027*\"corruption\" + 0.022*\"hp\" + 0.022*\"forgot\"\n",
      "INFO:gensim.models.ldamodel:topic #19 (0.010): 0.069*\"myself\" + 0.046*\"center\" + 0.045*\"drug\" + 0.042*\"alcohol\" + 0.040*\"value\" + 0.038*\"started\" + 0.032*\"mass\" + 0.031*\"near\" + 0.029*\"county\" + 0.028*\"rehab\"\n",
      "INFO:gensim.models.ldamodel:topic #15 (0.010): 0.200*\"we\" + 0.055*\"women\" + 0.048*\"our\" + 0.044*\"made\" + 0.042*\"men\" + 0.040*\"say\" + 0.040*\"now\" + 0.040*\"right\" + 0.037*\"china\" + 0.029*\"happens\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.010): 0.133*\"go\" + 0.047*\"skills\" + 0.039*\"writing\" + 0.035*\"causes\" + 0.035*\"show\" + 0.033*\"stay\" + 0.032*\"wear\" + 0.026*\"required\" + 0.026*\"pro\" + 0.023*\"macbook\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.008416, rho=0.052486\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #369 = documents up to #740000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #370 = documents up to #742000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #53 (0.010): 0.151*\"system\" + 0.052*\"biggest\" + 0.046*\"operating\" + 0.040*\"similar\" + 0.032*\"personal\" + 0.028*\"pain\" + 0.026*\"buying\" + 0.025*\"fake\" + 0.023*\"device\" + 0.017*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #63 (0.010): 0.147*\"like\" + 0.099*\"it\" + 0.081*\"feel\" + 0.070*\"person\" + 0.055*\"sex\" + 0.050*\"does\" + 0.041*\"be\" + 0.038*\"earth\" + 0.028*\"having\" + 0.022*\"purpose\"\n",
      "INFO:gensim.models.ldamodel:topic #72 (0.010): 0.123*\"their\" + 0.098*\"first\" + 0.086*\"day\" + 0.082*\"things\" + 0.074*\"into\" + 0.062*\"going\" + 0.058*\"know\" + 0.041*\"some\" + 0.041*\"should\" + 0.031*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #55 (0.010): 0.119*\"number\" + 0.066*\"tech\" + 0.050*\"list\" + 0.038*\"from\" + 0.037*\"m\" + 0.036*\"remove\" + 0.029*\"exactly\" + 0.021*\"after\" + 0.019*\"father\" + 0.018*\"does\"\n",
      "INFO:gensim.models.ldamodel:topic #46 (0.010): 0.058*\"family\" + 0.057*\"reduce\" + 0.051*\"apps\" + 0.050*\"air\" + 0.039*\"uber\" + 0.036*\"or\" + 0.024*\"special\" + 0.020*\"convince\" + 0.019*\"driver\" + 0.017*\"with\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.008156, rho=0.052342\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #371 = documents up to #744000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #372 = documents up to #746000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #77 (0.010): 0.113*\"change\" + 0.052*\"around\" + 0.047*\"popular\" + 0.036*\"decision\" + 0.032*\"views\" + 0.028*\"let\" + 0.025*\"it\" + 0.024*\"news\" + 0.023*\"!\" + 0.022*\"linux\"\n",
      "INFO:gensim.models.ldamodel:topic #92 (0.010): 0.154*\"become\" + 0.053*\"come\" + 0.042*\"create\" + 0.035*\"jobs\" + 0.030*\"an\" + 0.029*\"sleep\" + 0.028*\"from\" + 0.025*\"does\" + 0.024*\"drive\" + 0.022*\"did\"\n",
      "INFO:gensim.models.ldamodel:topic #88 (0.010): 0.160*\"many\" + 0.085*\"years\" + 0.051*\"5\" + 0.039*\"dollar\" + 0.038*\"so\" + 0.026*\"there\" + 0.025*\"per\" + 0.023*\"20\" + 0.022*\"week\" + 0.022*\"hours\"\n",
      "INFO:gensim.models.ldamodel:topic #74 (0.010): 0.047*\"star\" + 0.039*\"industry\" + 0.038*\"moon\" + 0.038*\"does\" + 0.031*\"option\" + 0.029*\"sound\" + 0.028*\"sun\" + 0.026*\"wars\" + 0.021*\"php\" + 0.021*\"gravity\"\n",
      "INFO:gensim.models.ldamodel:topic #98 (0.010): 0.094*\"its\" + 0.062*\"download\" + 0.051*\"site\" + 0.042*\"less\" + 0.034*\"form\" + 0.028*\"develop\" + 0.027*\"office\" + 0.023*\"charge\" + 0.022*\"from\" + 0.019*\"india\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.008064, rho=0.052200\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #373 = documents up to #748000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #374 = documents up to #750000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #37 (0.010): 0.232*\"has\" + 0.049*\"next\" + 0.045*\"been\" + 0.033*\"apple\" + 0.028*\"size\" + 0.024*\"set\" + 0.022*\"often\" + 0.021*\"quality\" + 0.021*\"when\" + 0.020*\"already\"\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.010): 0.119*\"my\" + 0.096*\"account\" + 0.082*\"facebook\" + 0.041*\"password\" + 0.039*\"email\" + 0.030*\"gmail\" + 0.029*\"from\" + 0.027*\"delete\" + 0.024*\"recover\" + 0.019*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic #17 (0.010): 0.073*\"no\" + 0.052*\"energy\" + 0.041*\"believe\" + 0.040*\"god\" + 0.036*\"there\" + 0.036*\"that\" + 0.035*\"actually\" + 0.032*\"if\" + 0.029*\"dark\" + 0.027*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic #22 (0.010): 0.103*\"see\" + 0.100*\"instagram\" + 0.063*\"hair\" + 0.062*\"on\" + 0.058*\"youtube\" + 0.032*\"who\" + 0.030*\"my\" + 0.025*\"beautiful\" + 0.020*\"currently\" + 0.020*\"most\"\n",
      "INFO:gensim.models.ldamodel:topic #48 (0.010): 0.154*\"other\" + 0.059*\"government\" + 0.047*\"against\" + 0.041*\"india\" + 0.040*\"each\" + 0.023*\"products\" + 0.023*\"any\" + 0.022*\"numbers\" + 0.021*\"there\" + 0.021*\"not\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.007555, rho=0.052058\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #375 = documents up to #752000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #376 = documents up to #754000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #42 (0.010): 0.105*\"different\" + 0.094*\"help\" + 0.066*\"companies\" + 0.049*\"white\" + 0.044*\"culture\" + 0.041*\"self\" + 0.037*\"songs\" + 0.031*\"gain\" + 0.021*\"like\" + 0.019*\"some\"\n",
      "INFO:gensim.models.ldamodel:topic #39 (0.010): 0.108*\"top\" + 0.093*\"own\" + 0.043*\"normal\" + 0.040*\"bollywood\" + 0.036*\"page\" + 0.035*\"green\" + 0.029*\"on\" + 0.026*\"who\" + 0.026*\"hollywood\" + 0.024*\"tea\"\n",
      "INFO:gensim.models.ldamodel:topic #23 (0.010): 0.140*\"world\" + 0.078*\"war\" + 0.066*\"3\" + 0.051*\"mobile\" + 0.041*\"countries\" + 0.037*\"off\" + 0.026*\"successful\" + 0.021*\"who\" + 0.020*\"turn\" + 0.020*\"will\"\n",
      "INFO:gensim.models.ldamodel:topic #21 (0.010): 0.270*\"/\" + 0.050*\"math\" + 0.049*\"exam\" + 0.049*\"1\" + 0.039*\"[\" + 0.039*\"]\" + 0.034*\"x\" + 0.026*\"games\" + 0.024*\"=\" + 0.023*\"gate\"\n",
      "INFO:gensim.models.ldamodel:topic #31 (0.010): 0.122*\"indian\" + 0.080*\"notes\" + 0.078*\"1000\" + 0.078*\"500\" + 0.058*\"black\" + 0.050*\"rs\" + 0.040*\"will\" + 0.038*\"anyone\" + 0.037*\"rupee\" + 0.029*\"great\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.007428, rho=0.051917\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #377 = documents up to #756000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #378 = documents up to #758000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #95 (0.010): 0.179*\"work\" + 0.067*\"does\" + 0.036*\"at\" + 0.035*\"apply\" + 0.032*\"bangalore\" + 0.031*\"differ\" + 0.031*\"4\" + 0.028*\"videos\" + 0.025*\"vote\" + 0.022*\"marks\"\n",
      "INFO:gensim.models.ldamodel:topic #20 (0.010): 0.067*\"place\" + 0.062*\"usa\" + 0.060*\"places\" + 0.056*\"visit\" + 0.043*\"public\" + 0.042*\"visa\" + 0.032*\"india\" + 0.024*\"interested\" + 0.023*\"estate\" + 0.023*\"real\"\n",
      "INFO:gensim.models.ldamodel:topic #55 (0.010): 0.118*\"number\" + 0.068*\"tech\" + 0.047*\"list\" + 0.037*\"m\" + 0.036*\"remove\" + 0.036*\"from\" + 0.029*\"exactly\" + 0.021*\"after\" + 0.019*\"does\" + 0.019*\"father\"\n",
      "INFO:gensim.models.ldamodel:topic #45 (0.010): 0.055*\"percent\" + 0.055*\"hard\" + 0.038*\"choose\" + 0.032*\"single\" + 0.031*\"group\" + 0.027*\"it\" + 0.025*\"eating\" + 0.023*\"grow\" + 0.022*\"paper\" + 0.021*\"loss\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.010): 0.247*\"where\" + 0.148*\"find\" + 0.051*\"get\" + 0.040*\"support\" + 0.025*\"times\" + 0.022*\"sim\" + 0.018*\"religion\" + 0.017*\"quickly\" + 0.017*\"out\" + 0.016*\"you\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.007544, rho=0.051778\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #379 = documents up to #760000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #380 = documents up to #762000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #67 (0.010): 0.075*\"prepare\" + 0.062*\"water\" + 0.056*\"bank\" + 0.035*\"cat\" + 0.034*\"mechanical\" + 0.033*\"england\" + 0.032*\"education\" + 0.032*\"should\" + 0.027*\"again\" + 0.025*\"invest\"\n",
      "INFO:gensim.models.ldamodel:topic #86 (0.010): 0.131*\"books\" + 0.093*\"read\" + 0.065*\"very\" + 0.052*\"fat\" + 0.034*\"theory\" + 0.033*\"some\" + 0.026*\"belly\" + 0.025*\"moment\" + 0.024*\"good\" + 0.022*\"close\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.313*\"your\" + 0.144*\"life\" + 0.112*\"you\" + 0.041*\"school\" + 0.036*\"high\" + 0.028*\"favorite\" + 0.019*\"join\" + 0.014*\"was\" + 0.013*\"understand\" + 0.013*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic #35 (0.010): 0.069*\"movies\" + 0.042*\"some\" + 0.038*\"iit\" + 0.036*\"down\" + 0.036*\"jee\" + 0.030*\"effect\" + 0.029*\"put\" + 0.029*\"project\" + 0.024*\"children\" + 0.022*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic #50 (0.010): 0.162*\"love\" + 0.139*\"used\" + 0.055*\"makes\" + 0.036*\"fall\" + 0.033*\"by\" + 0.031*\"on\" + 0.026*\"safety\" + 0.025*\"sentence\" + 0.023*\"proposed\" + 0.023*\"precautions\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.007795, rho=0.051640\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #381 = documents up to #764000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #382 = documents up to #766000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #59 (0.010): 0.142*\"were\" + 0.130*\"still\" + 0.037*\"amazon\" + 0.036*\"send\" + 0.033*\"on\" + 0.024*\"that\" + 0.023*\"did\" + 0.018*\"was\" + 0.017*\"who\" + 0.015*\"you\"\n",
      "INFO:gensim.models.ldamodel:topic #86 (0.010): 0.131*\"books\" + 0.094*\"read\" + 0.066*\"very\" + 0.051*\"fat\" + 0.034*\"theory\" + 0.033*\"some\" + 0.026*\"belly\" + 0.025*\"moment\" + 0.024*\"good\" + 0.022*\"close\"\n",
      "INFO:gensim.models.ldamodel:topic #46 (0.010): 0.058*\"reduce\" + 0.055*\"family\" + 0.053*\"air\" + 0.050*\"apps\" + 0.039*\"uber\" + 0.035*\"or\" + 0.025*\"special\" + 0.020*\"convince\" + 0.020*\"driver\" + 0.017*\"with\"\n",
      "INFO:gensim.models.ldamodel:topic #67 (0.010): 0.075*\"prepare\" + 0.061*\"water\" + 0.055*\"bank\" + 0.036*\"cat\" + 0.033*\"mechanical\" + 0.033*\"england\" + 0.033*\"education\" + 0.032*\"should\" + 0.027*\"again\" + 0.025*\"invest\"\n",
      "INFO:gensim.models.ldamodel:topic #32 (0.010): 0.145*\"really\" + 0.054*\"exist\" + 0.044*\"hate\" + 0.039*\"does\" + 0.030*\"that\" + 0.026*\"amount\" + 0.025*\"people\" + 0.024*\"once\" + 0.019*\"an\" + 0.019*\"there\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.007446, rho=0.051503\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #383 = documents up to #768000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #384 = documents up to #770000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #72 (0.010): 0.125*\"their\" + 0.103*\"first\" + 0.087*\"day\" + 0.081*\"things\" + 0.074*\"into\" + 0.060*\"going\" + 0.057*\"know\" + 0.042*\"some\" + 0.040*\"should\" + 0.031*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #61 (0.010): 0.133*\"thing\" + 0.055*\"you\" + 0.053*\"demonetization\" + 0.041*\"given\" + 0.040*\"that\" + 0.032*\"most\" + 0.030*\"second\" + 0.029*\"advantages\" + 0.027*\"calculate\" + 0.023*\"taken\"\n",
      "INFO:gensim.models.ldamodel:topic #90 (0.010): 0.133*\"2\" + 0.116*\"+\" + 0.100*\"c\" + 0.074*\"home\" + 0.038*\"foreign\" + 0.024*\"n\" + 0.021*\"good\" + 0.021*\"d\" + 0.018*\"bring\" + 0.018*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #74 (0.010): 0.045*\"star\" + 0.040*\"industry\" + 0.039*\"does\" + 0.038*\"moon\" + 0.029*\"option\" + 0.028*\"sound\" + 0.028*\"sun\" + 0.025*\"wars\" + 0.023*\"gravity\" + 0.021*\"php\"\n",
      "INFO:gensim.models.ldamodel:topic #46 (0.010): 0.058*\"reduce\" + 0.055*\"family\" + 0.054*\"air\" + 0.049*\"apps\" + 0.038*\"uber\" + 0.034*\"or\" + 0.026*\"special\" + 0.021*\"driver\" + 0.020*\"convince\" + 0.016*\"with\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.008028, rho=0.051367\n",
      "INFO:gensim.models.ldamodel:-8.135 per-word bound, 281.1 perplexity estimate based on a held-out corpus of 2000 documents with 14911 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #385 = documents up to #772000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.137*\"ways\" + 0.078*\"get\" + 0.060*\"some\" + 0.056*\"rid\" + 0.031*\"face\" + 0.029*\"on\" + 0.028*\"impact\" + 0.026*\"daily\" + 0.022*\"twitter\" + 0.021*\"photo\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.010): 0.083*\"increase\" + 0.082*\"my\" + 0.041*\"type\" + 0.038*\"traffic\" + 0.037*\"height\" + 0.035*\"get\" + 0.031*\"dog\" + 0.029*\"on\" + 0.028*\"called\" + 0.027*\"party\"\n",
      "INFO:gensim.models.ldamodel:topic #62 (0.010): 0.100*\"engineering\" + 0.058*\"student\" + 0.055*\"university\" + 0.053*\"getting\" + 0.048*\"an\" + 0.037*\"students\" + 0.031*\"post\" + 0.029*\"civil\" + 0.024*\"after\" + 0.024*\"etc\"\n",
      "INFO:gensim.models.ldamodel:topic #55 (0.010): 0.126*\"number\" + 0.068*\"tech\" + 0.048*\"list\" + 0.037*\"remove\" + 0.036*\"from\" + 0.035*\"m\" + 0.029*\"exactly\" + 0.021*\"after\" + 0.019*\"father\" + 0.019*\"does\"\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.010): 0.121*\"my\" + 0.096*\"account\" + 0.083*\"facebook\" + 0.040*\"email\" + 0.039*\"password\" + 0.029*\"gmail\" + 0.028*\"from\" + 0.026*\"delete\" + 0.023*\"recover\" + 0.021*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.007423, rho=0.051232\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #386 = documents up to #774000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #387 = documents up to #776000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #388 = documents up to #778000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.059*\"real\" + 0.058*\"average\" + 0.052*\"america\" + 0.050*\"non\" + 0.048*\"food\" + 0.042*\"age\" + 0.039*\"able\" + 0.033*\"child\" + 0.026*\"there\" + 0.025*\"marriage\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.010): 0.245*\"where\" + 0.149*\"find\" + 0.051*\"get\" + 0.039*\"support\" + 0.025*\"times\" + 0.020*\"sim\" + 0.019*\"quickly\" + 0.018*\"out\" + 0.017*\"religion\" + 0.016*\"you\"\n",
      "INFO:gensim.models.ldamodel:topic #93 (0.010): 0.141*\"free\" + 0.048*\"also\" + 0.033*\"share\" + 0.033*\"reading\" + 0.026*\"be\" + 0.025*\"allowed\" + 0.024*\"attack\" + 0.021*\"should\" + 0.021*\"not\" + 0.019*\"banned\"\n",
      "INFO:gensim.models.ldamodel:topic #71 (0.010): 0.065*\"score\" + 0.056*\"private\" + 0.051*\"startup\" + 0.039*\"get\" + 0.039*\"advice\" + 0.037*\"engine\" + 0.032*\"paid\" + 0.028*\"islam\" + 0.026*\"eyes\" + 0.026*\"gre\"\n",
      "INFO:gensim.models.ldamodel:topic #95 (0.010): 0.180*\"work\" + 0.068*\"does\" + 0.035*\"at\" + 0.033*\"apply\" + 0.032*\"differ\" + 0.031*\"bangalore\" + 0.029*\"4\" + 0.027*\"videos\" + 0.026*\"vote\" + 0.023*\"marks\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.007365, rho=0.051098\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #389 = documents up to #780000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #39 (0.010): 0.109*\"top\" + 0.091*\"own\" + 0.042*\"normal\" + 0.041*\"bollywood\" + 0.039*\"green\" + 0.035*\"page\" + 0.029*\"on\" + 0.027*\"who\" + 0.026*\"hollywood\" + 0.024*\"tea\"\n",
      "INFO:gensim.models.ldamodel:topic #79 (0.010): 0.162*\"2016\" + 0.062*\"kind\" + 0.051*\"overcome\" + 0.031*\"cut\" + 0.029*\"fear\" + 0.023*\"beginner\" + 0.021*\"expected\" + 0.020*\"off\" + 0.020*\"designer\" + 0.014*\"percentile\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.010): 0.244*\"where\" + 0.147*\"find\" + 0.051*\"get\" + 0.039*\"support\" + 0.025*\"times\" + 0.020*\"sim\" + 0.020*\"quickly\" + 0.018*\"out\" + 0.017*\"religion\" + 0.015*\"jio\"\n",
      "INFO:gensim.models.ldamodel:topic #96 (0.010): 0.405*\"have\" + 0.077*\"you\" + 0.059*\"had\" + 0.031*\"been\" + 0.026*\"if\" + 0.022*\"not\" + 0.018*\"that\" + 0.018*\"any\" + 0.016*\"international\" + 0.015*\"night\"\n",
      "INFO:gensim.models.ldamodel:topic #71 (0.010): 0.065*\"score\" + 0.055*\"private\" + 0.051*\"startup\" + 0.039*\"get\" + 0.039*\"advice\" + 0.037*\"engine\" + 0.031*\"paid\" + 0.030*\"islam\" + 0.027*\"eyes\" + 0.026*\"gre\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.007362, rho=0.050965\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #390 = documents up to #782000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #391 = documents up to #784000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #392 = documents up to #786000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.010): 0.182*\"learn\" + 0.163*\"start\" + 0.049*\"should\" + 0.034*\"idea\" + 0.034*\"python\" + 0.032*\"technology\" + 0.029*\"order\" + 0.023*\"sell\" + 0.022*\"learning\" + 0.020*\"enough\"\n",
      "INFO:gensim.models.ldamodel:topic #87 (0.010): 0.067*\"parents\" + 0.065*\"date\" + 0.030*\"knowledge\" + 0.029*\"with\" + 0.027*\"land\" + 0.024*\"kids\" + 0.018*\"candidate\" + 0.018*\"on\" + 0.015*\"usb\" + 0.014*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic #44 (0.010): 0.192*\"about\" + 0.156*\"you\" + 0.121*\"think\" + 0.061*\"stop\" + 0.047*\"people\" + 0.042*\"know\" + 0.034*\"that\" + 0.022*\"last\" + 0.020*\"indians\" + 0.019*\"not\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.102*\"over\" + 0.093*\"before\" + 0.065*\"bing\" + 0.038*\"class\" + 0.034*\"correct\" + 0.034*\"short\" + 0.027*\"red\" + 0.023*\"get\" + 0.021*\"structure\" + 0.020*\"because\"\n",
      "INFO:gensim.models.ldamodel:topic #12 (0.010): 0.462*\".\" + 0.035*\"u\" + 0.035*\"b\" + 0.029*\"girls\" + 0.024*\"answers\" + 0.016*\"guys\" + 0.015*\"this\" + 0.015*\"it\" + 0.013*\"japan\" + 0.013*\"rate\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.007054, rho=0.050833\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #393 = documents up to #788000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #394 = documents up to #790000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #33 (0.010): 0.058*\"2017\" + 0.055*\"music\" + 0.049*\"power\" + 0.038*\"management\" + 0.035*\"move\" + 0.034*\"compared\" + 0.033*\"new\" + 0.033*\"field\" + 0.030*\"offer\" + 0.027*\"past\"\n",
      "INFO:gensim.models.ldamodel:topic #48 (0.010): 0.157*\"other\" + 0.059*\"government\" + 0.050*\"against\" + 0.041*\"india\" + 0.037*\"each\" + 0.024*\"products\" + 0.023*\"any\" + 0.023*\"numbers\" + 0.023*\"not\" + 0.022*\"there\"\n",
      "INFO:gensim.models.ldamodel:topic #56 (0.010): 0.066*\"some\" + 0.048*\"interesting\" + 0.048*\"about\" + 0.038*\"based\" + 0.035*\"facts\" + 0.034*\"known\" + 0.030*\"australia\" + 0.028*\"model\" + 0.026*\"india\" + 0.022*\"japanese\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.311*\"your\" + 0.145*\"life\" + 0.113*\"you\" + 0.040*\"school\" + 0.038*\"high\" + 0.028*\"favorite\" + 0.019*\"join\" + 0.013*\"most\" + 0.013*\"was\" + 0.013*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic #77 (0.010): 0.107*\"change\" + 0.053*\"around\" + 0.045*\"popular\" + 0.036*\"decision\" + 0.032*\"views\" + 0.025*\"news\" + 0.024*\"it\" + 0.023*\"let\" + 0.023*\"europe\" + 0.023*\"linux\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.007103, rho=0.050702\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #395 = documents up to #792000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #396 = documents up to #794000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #30 (0.010): 0.328*\"make\" + 0.038*\"degree\" + 0.035*\"happened\" + 0.034*\"current\" + 0.034*\"you\" + 0.026*\"full\" + 0.022*\"does\" + 0.021*\"obama\" + 0.019*\"master\" + 0.017*\"french\"\n",
      "INFO:gensim.models.ldamodel:topic #62 (0.010): 0.101*\"engineering\" + 0.059*\"student\" + 0.054*\"university\" + 0.052*\"getting\" + 0.047*\"an\" + 0.037*\"students\" + 0.030*\"post\" + 0.029*\"civil\" + 0.025*\"after\" + 0.025*\"get\"\n",
      "INFO:gensim.models.ldamodel:topic #31 (0.010): 0.121*\"indian\" + 0.081*\"notes\" + 0.078*\"1000\" + 0.078*\"500\" + 0.062*\"black\" + 0.051*\"rs\" + 0.040*\"will\" + 0.038*\"anyone\" + 0.035*\"rupee\" + 0.030*\"great\"\n",
      "INFO:gensim.models.ldamodel:topic #97 (0.010): 0.163*\"more\" + 0.155*\"than\" + 0.067*\"study\" + 0.056*\"give\" + 0.031*\"or\" + 0.025*\"2015\" + 0.025*\"germany\" + 0.018*\"exams\" + 0.017*\"please\" + 0.013*\"mix\"\n",
      "INFO:gensim.models.ldamodel:topic #70 (0.010): 0.175*\"quora\" + 0.107*\"on\" + 0.067*\"questions\" + 0.050*\"question\" + 0.043*\"ask\" + 0.031*\"people\" + 0.030*\"answer\" + 0.025*\"effects\" + 0.021*\"as\" + 0.021*\"asked\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.006842, rho=0.050572\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #397 = documents up to #796000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #52 (0.010): 0.132*\"possible\" + 0.113*\"it\" + 0.054*\"travel\" + 0.054*\"career\" + 0.028*\"humans\" + 0.027*\"house\" + 0.024*\"options\" + 0.023*\"chemical\" + 0.019*\"after\" + 0.018*\"taking\"\n",
      "INFO:gensim.models.ldamodel:topic #40 (0.010): 0.177*\"much\" + 0.063*\"live\" + 0.052*\"during\" + 0.051*\"does\" + 0.046*\"it\" + 0.042*\"cost\" + 0.042*\"future\" + 0.029*\"behind\" + 0.027*\"small\" + 0.026*\"so\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.132*\"ways\" + 0.081*\"get\" + 0.060*\"some\" + 0.059*\"rid\" + 0.032*\"face\" + 0.028*\"on\" + 0.027*\"impact\" + 0.026*\"daily\" + 0.023*\"twitter\" + 0.022*\"photo\"\n",
      "INFO:gensim.models.ldamodel:topic #60 (0.010): 0.101*\"trump\" + 0.079*\"us\" + 0.073*\"take\" + 0.066*\"donald\" + 0.054*\"will\" + 0.046*\"president\" + 0.041*\"clinton\" + 0.039*\"win\" + 0.038*\"hillary\" + 0.036*\"who\"\n",
      "INFO:gensim.models.ldamodel:topic #79 (0.010): 0.165*\"2016\" + 0.061*\"kind\" + 0.052*\"overcome\" + 0.032*\"cut\" + 0.028*\"fear\" + 0.025*\"beginner\" + 0.022*\"expected\" + 0.020*\"off\" + 0.020*\"designer\" + 0.014*\"percentile\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.007135, rho=0.050443\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #398 = documents up to #798000/808580, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #399 = documents up to #800000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #400 = documents up to #802000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #72 (0.010): 0.124*\"their\" + 0.101*\"first\" + 0.086*\"day\" + 0.083*\"things\" + 0.071*\"into\" + 0.060*\"going\" + 0.055*\"know\" + 0.042*\"some\" + 0.040*\"should\" + 0.032*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #86 (0.010): 0.134*\"books\" + 0.088*\"read\" + 0.069*\"very\" + 0.053*\"fat\" + 0.035*\"theory\" + 0.030*\"some\" + 0.027*\"moment\" + 0.026*\"belly\" + 0.024*\"good\" + 0.022*\"close\"\n",
      "INFO:gensim.models.ldamodel:topic #29 (0.010): 0.062*\"build\" + 0.057*\"run\" + 0.048*\"death\" + 0.040*\"security\" + 0.036*\"dogs\" + 0.034*\"suicide\" + 0.027*\"least\" + 0.021*\"flat\" + 0.021*\"masters\" + 0.020*\"commit\"\n",
      "INFO:gensim.models.ldamodel:topic #52 (0.010): 0.132*\"possible\" + 0.113*\"it\" + 0.054*\"travel\" + 0.053*\"career\" + 0.028*\"house\" + 0.027*\"humans\" + 0.024*\"options\" + 0.023*\"chemical\" + 0.019*\"after\" + 0.018*\"animals\"\n",
      "INFO:gensim.models.ldamodel:topic #61 (0.010): 0.138*\"thing\" + 0.055*\"demonetization\" + 0.053*\"you\" + 0.040*\"given\" + 0.038*\"that\" + 0.034*\"most\" + 0.029*\"second\" + 0.028*\"advantages\" + 0.026*\"calculate\" + 0.025*\"taken\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.007108, rho=0.050315\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #401 = documents up to #804000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #402 = documents up to #806000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #76 (0.010): 0.071*\"watch\" + 0.052*\"something\" + 0.047*\"seen\" + 0.030*\"you\" + 0.030*\"tax\" + 0.025*\"on\" + 0.024*\"season\" + 0.023*\"movies\" + 0.022*\"an\" + 0.021*\"interest\"\n",
      "INFO:gensim.models.ldamodel:topic #36 (0.010): 0.134*\"year\" + 0.105*\"old\" + 0.059*\"it\" + 0.051*\"true\" + 0.038*\"worth\" + 0.036*\"salary\" + 0.030*\"that\" + 0.027*\"fast\" + 0.026*\"must\" + 0.026*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.010): 0.081*\"increase\" + 0.076*\"my\" + 0.042*\"type\" + 0.038*\"traffic\" + 0.037*\"height\" + 0.035*\"get\" + 0.033*\"dog\" + 0.029*\"on\" + 0.029*\"blog\" + 0.028*\"called\"\n",
      "INFO:gensim.models.ldamodel:topic #32 (0.010): 0.153*\"really\" + 0.057*\"exist\" + 0.042*\"hate\" + 0.040*\"does\" + 0.029*\"that\" + 0.026*\"once\" + 0.024*\"people\" + 0.024*\"amount\" + 0.020*\"an\" + 0.020*\"there\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.134*\"ways\" + 0.080*\"get\" + 0.059*\"some\" + 0.058*\"rid\" + 0.032*\"face\" + 0.028*\"daily\" + 0.028*\"on\" + 0.026*\"impact\" + 0.023*\"twitter\" + 0.022*\"photo\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.007180, rho=0.050189\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #403 = documents up to #808000/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #404 = documents up to #808580/808580, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #77 (0.010): 0.106*\"change\" + 0.052*\"around\" + 0.046*\"popular\" + 0.035*\"decision\" + 0.031*\"views\" + 0.027*\"news\" + 0.025*\"let\" + 0.024*\"it\" + 0.023*\"linux\" + 0.023*\"europe\"\n",
      "INFO:gensim.models.ldamodel:topic #87 (0.010): 0.066*\"parents\" + 0.065*\"date\" + 0.030*\"knowledge\" + 0.028*\"with\" + 0.026*\"kids\" + 0.025*\"land\" + 0.019*\"on\" + 0.018*\"candidate\" + 0.016*\"usb\" + 0.014*\"or\"\n",
      "INFO:gensim.models.ldamodel:topic #86 (0.010): 0.133*\"books\" + 0.091*\"read\" + 0.069*\"very\" + 0.054*\"fat\" + 0.036*\"theory\" + 0.031*\"some\" + 0.027*\"moment\" + 0.026*\"belly\" + 0.023*\"good\" + 0.021*\"close\"\n",
      "INFO:gensim.models.ldamodel:topic #30 (0.010): 0.326*\"make\" + 0.038*\"happened\" + 0.036*\"degree\" + 0.033*\"current\" + 0.033*\"you\" + 0.024*\"full\" + 0.022*\"does\" + 0.021*\"obama\" + 0.019*\"master\" + 0.018*\"french\"\n",
      "INFO:gensim.models.ldamodel:topic #94 (0.010): 0.225*\"'\" + 0.079*\"pakistan\" + 0.071*\"meaning\" + 0.063*\"word\" + 0.037*\"india\" + 0.031*\"universe\" + 0.029*\"hindi\" + 0.018*\"ticket\" + 0.018*\"minimum\" + 0.014*\"certificate\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.007029, rho=0.050063\n",
      "INFO:gensim.models.ldamodel:-8.075 per-word bound, 269.7 perplexity estimate based on a held-out corpus of 580 documents with 4897 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #44 (0.010): 0.193*\"about\" + 0.156*\"you\" + 0.118*\"think\" + 0.060*\"stop\" + 0.049*\"people\" + 0.045*\"know\" + 0.035*\"that\" + 0.023*\"last\" + 0.019*\"not\" + 0.019*\"indians\"\n",
      "INFO:gensim.models.ldamodel:topic #30 (0.010): 0.325*\"make\" + 0.038*\"happened\" + 0.035*\"degree\" + 0.034*\"you\" + 0.034*\"current\" + 0.024*\"full\" + 0.022*\"does\" + 0.022*\"obama\" + 0.019*\"master\" + 0.018*\"french\"\n",
      "INFO:gensim.models.ldamodel:topic #42 (0.010): 0.105*\"different\" + 0.090*\"help\" + 0.067*\"companies\" + 0.049*\"white\" + 0.045*\"culture\" + 0.040*\"self\" + 0.039*\"songs\" + 0.033*\"gain\" + 0.020*\"like\" + 0.020*\"at\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.010): 0.246*\"where\" + 0.147*\"find\" + 0.052*\"get\" + 0.039*\"support\" + 0.023*\"times\" + 0.021*\"sim\" + 0.019*\"quickly\" + 0.018*\"out\" + 0.017*\"jio\" + 0.017*\"religion\"\n",
      "INFO:gensim.models.ldamodel:topic #75 (0.010): 0.093*\"while\" + 0.070*\"doing\" + 0.054*\"internet\" + 0.041*\"wrong\" + 0.038*\"modi\" + 0.038*\"part\" + 0.031*\"studying\" + 0.024*\"sydney\" + 0.024*\"narendra\" + 0.022*\"property\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.006855, rho=0.049938\n",
      "INFO:gensim.models.ldamodel:merging changes from 4000 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #54 (0.010): 0.122*\"weight\" + 0.111*\"being\" + 0.104*\"lose\" + 0.054*\"man\" + 0.038*\"die\" + 0.037*\"way\" + 0.035*\"websites\" + 0.030*\"easiest\" + 0.019*\"porn\" + 0.018*\"you\"\n",
      "INFO:gensim.models.ldamodel:topic #98 (0.010): 0.103*\"its\" + 0.057*\"download\" + 0.054*\"site\" + 0.041*\"less\" + 0.035*\"form\" + 0.030*\"develop\" + 0.027*\"office\" + 0.021*\"charge\" + 0.021*\"from\" + 0.017*\"cheap\"\n",
      "INFO:gensim.models.ldamodel:topic #36 (0.010): 0.135*\"year\" + 0.105*\"old\" + 0.059*\"it\" + 0.051*\"true\" + 0.038*\"worth\" + 0.036*\"salary\" + 0.029*\"that\" + 0.027*\"fast\" + 0.026*\"must\" + 0.026*\"an\"\n",
      "INFO:gensim.models.ldamodel:topic #24 (0.010): 0.191*\")\" + 0.190*\"(\" + 0.106*\":\" + 0.081*\"better\" + 0.071*\"or\" + 0.047*\"which\" + 0.033*\"long\" + 0.019*\"mba\" + 0.018*\"quoted_item\" + 0.014*\"main\"\n",
      "INFO:gensim.models.ldamodel:topic #71 (0.010): 0.064*\"score\" + 0.057*\"private\" + 0.054*\"startup\" + 0.040*\"get\" + 0.037*\"advice\" + 0.035*\"engine\" + 0.031*\"paid\" + 0.028*\"islam\" + 0.026*\"gre\" + 0.025*\"eyes\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.007021, rho=0.049814\n",
      "INFO:gensim.models.ldamodel:merging changes from 580 documents into a model of 808580 documents\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.010): 0.117*\"my\" + 0.095*\"account\" + 0.084*\"facebook\" + 0.039*\"password\" + 0.038*\"email\" + 0.030*\"gmail\" + 0.027*\"delete\" + 0.027*\"from\" + 0.021*\"recover\" + 0.021*\"on\"\n",
      "INFO:gensim.models.ldamodel:topic #20 (0.010): 0.063*\"place\" + 0.060*\"usa\" + 0.058*\"places\" + 0.053*\"visit\" + 0.048*\"visa\" + 0.040*\"public\" + 0.034*\"india\" + 0.024*\"interested\" + 0.021*\"real\" + 0.021*\"estate\"\n",
      "INFO:gensim.models.ldamodel:topic #60 (0.010): 0.096*\"trump\" + 0.083*\"us\" + 0.075*\"take\" + 0.062*\"donald\" + 0.052*\"will\" + 0.047*\"president\" + 0.042*\"clinton\" + 0.039*\"hillary\" + 0.037*\"win\" + 0.035*\"who\"\n",
      "INFO:gensim.models.ldamodel:topic #39 (0.010): 0.110*\"top\" + 0.088*\"own\" + 0.044*\"normal\" + 0.042*\"bollywood\" + 0.038*\"green\" + 0.033*\"page\" + 0.030*\"hollywood\" + 0.028*\"who\" + 0.027*\"on\" + 0.024*\"movies\"\n",
      "INFO:gensim.models.ldamodel:topic #84 (0.010): 0.108*\"book\" + 0.074*\"name\" + 0.064*\"tv\" + 0.050*\"series\" + 0.035*\"ias\" + 0.029*\"left\" + 0.022*\"officer\" + 0.021*\"an\" + 0.020*\"positive\" + 0.020*\"gas\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.012872, rho=0.049690\n",
      "INFO:gensim.models.ldamodel:-7.887 per-word bound, 236.7 perplexity estimate based on a held-out corpus of 580 documents with 4897 words\n"
     ]
    }
   ],
   "source": [
    "lda = gensim.models.ldamulticore.LdaMulticore(questions, id2word=vectorizer, num_topics=100, workers=2, passes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:saving LdaState object under models/lda_question.pickle.state, separately None\n",
      "INFO:gensim.utils:saved models/lda_question.pickle.state\n",
      "INFO:gensim.utils:saving LdaMulticore object under models/lda_question.pickle, separately ['expElogbeta', 'sstats']\n",
      "INFO:gensim.utils:not storing attribute state\n",
      "INFO:gensim.utils:not storing attribute dispatcher\n",
      "INFO:gensim.utils:not storing attribute id2word\n",
      "INFO:gensim.utils:storing np array 'expElogbeta' to models/lda_question.pickle.expElogbeta.npy\n",
      "INFO:gensim.utils:saved models/lda_question.pickle\n"
     ]
    }
   ],
   "source": [
    "lda.save(\"models/lda_question.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading LdaMulticore object from models/lda_question.pickle\n",
      "INFO:gensim.utils:loading expElogbeta from models/lda_question.pickle.expElogbeta.npy with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute state to None\n",
      "INFO:gensim.utils:setting ignored attribute dispatcher to None\n",
      "INFO:gensim.utils:setting ignored attribute id2word to None\n",
      "INFO:gensim.utils:loaded models/lda_question.pickle\n",
      "INFO:gensim.utils:loading LdaMulticore object from models/lda_question.pickle.state\n",
      "INFO:gensim.utils:loaded models/lda_question.pickle.state\n"
     ]
    }
   ],
   "source": [
    "lda = gensim.models.ldamulticore.LdaMulticore.load(\"models/lda_question.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lda_pipe(x):\n",
    "    sparse = vectorizer.doc2bow(x)\n",
    "    lda_sparse = lda[sparse]\n",
    "    return lda_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "25300\n",
      "63200\n",
      "12700\n",
      "88500\n",
      "50600\n",
      "38000\n",
      "100\n",
      "75900\n",
      "25400\n",
      "63300\n",
      "12800\n",
      "88600\n",
      "50700\n",
      "38100\n",
      "200\n",
      "76000\n",
      "25500\n",
      "63400\n",
      "12900\n",
      "88700\n",
      "50800\n",
      "38200\n",
      "300\n",
      "76100\n",
      "25600\n",
      "63500\n",
      "13000\n",
      "88800\n",
      "50900\n",
      "38300\n",
      "400\n",
      "76200\n",
      "25700\n",
      "63600\n",
      "13100\n",
      "88900\n",
      "51000\n",
      "38400\n",
      "500\n",
      "76300\n",
      "25800\n",
      "63700\n",
      "13200\n",
      "89000\n",
      "51100\n",
      "38500\n",
      "600\n",
      "76400\n",
      "25900\n",
      "63800\n",
      "13300\n",
      "89100\n",
      "51200\n",
      "700\n",
      "38600\n",
      "76500\n",
      "26000\n",
      "63900\n",
      "13400\n",
      "89200\n",
      "51300\n",
      "800\n",
      "38700\n",
      "76600\n",
      "26100\n",
      "64000\n",
      "13500\n",
      "89300\n",
      "51400\n",
      "900\n",
      "38800\n",
      "76700\n",
      "64100\n",
      "26200\n",
      "13600\n",
      "89400\n",
      "51500\n",
      "1000\n",
      "76800\n",
      "38900\n",
      "64200\n",
      "26300\n",
      "13700\n",
      "89500\n",
      "51600\n",
      "76900\n",
      "1100\n",
      "39000\n",
      "64300\n",
      "26400\n",
      "13800\n",
      "89600\n",
      "51700\n",
      "77000\n",
      "1200\n",
      "39100\n",
      "64400\n",
      "26500\n",
      "13900\n",
      "89700\n",
      "51800\n",
      "77100\n",
      "1300\n",
      "39200\n",
      "64500\n",
      "26600\n",
      "14000\n",
      "89800\n",
      "51900\n",
      "77200\n",
      "1400\n",
      "39300\n",
      "64600\n",
      "26700\n",
      "14100\n",
      "89900\n",
      "52000\n",
      "77300\n",
      "1500\n",
      "39400\n",
      "64700\n",
      "26800\n",
      "14200\n",
      "90000\n",
      "52100\n",
      "77400\n",
      "1600\n",
      "39500\n",
      "64800\n",
      "26900\n",
      "14300\n",
      "90100\n",
      "52200\n",
      "77500\n",
      "1700\n",
      "39600\n",
      "64900\n",
      "27000\n",
      "14400\n",
      "90200\n",
      "52300\n",
      "77600\n",
      "1800\n",
      "39700\n",
      "65000\n",
      "27100\n",
      "14500\n",
      "90300\n",
      "52400\n",
      "77700\n",
      "1900\n",
      "65100\n",
      "39800\n",
      "27200\n",
      "14600\n",
      "90400\n",
      "52500\n",
      "77800\n",
      "2000\n",
      "65200\n",
      "39900\n",
      "27300\n",
      "14700\n",
      "90500\n",
      "52600\n",
      "77900\n",
      "2100\n",
      "65300\n",
      "40000\n",
      "27400\n",
      "14800\n",
      "90600\n",
      "52700\n",
      "78000\n",
      "2200\n",
      "65400\n",
      "40100\n",
      "27500\n",
      "14900\n",
      "90700\n",
      "52800\n",
      "78100\n",
      "2300\n",
      "65500\n",
      "40200\n",
      "27600\n",
      "15000\n",
      "90800\n",
      "78200\n",
      "52900\n",
      "2400\n",
      "65600\n",
      "40300\n",
      "27700\n",
      "15100\n",
      "90900\n",
      "78300\n",
      "53000\n",
      "2500\n",
      "65700\n",
      "40400\n",
      "27800\n",
      "15200\n",
      "91000\n",
      "78400\n",
      "53100\n",
      "2600\n",
      "65800\n",
      "40500\n",
      "27900\n",
      "15300\n",
      "91100\n",
      "78500\n",
      "53200\n",
      "2700\n",
      "65900\n",
      "40600\n",
      "28000\n",
      "15400\n",
      "91200\n",
      "78600\n",
      "53300\n",
      "2800\n",
      "66000\n",
      "40700\n",
      "15500\n",
      "28100\n",
      "91300\n",
      "78700\n",
      "2900\n",
      "53400\n",
      "66100\n",
      "40800\n",
      "28200\n",
      "15600\n",
      "91400\n",
      "78800\n",
      "3000\n",
      "53500\n",
      "66200\n",
      "28300\n",
      "15700\n",
      "40900\n",
      "91500\n",
      "78900\n",
      "3100\n",
      "53600\n",
      "66300\n",
      "28400\n",
      "15800\n",
      "41000\n",
      "91600\n",
      "79000\n",
      "3200\n",
      "53700\n",
      "66400\n",
      "28500\n",
      "15900\n",
      "41100\n",
      "91700\n",
      "79100\n",
      "3300\n",
      "53800\n",
      "66500\n",
      "28600\n",
      "16000\n",
      "41200\n",
      "91800\n",
      "79200\n",
      "3400\n",
      "53900\n",
      "66600\n",
      "28700\n",
      "16100\n",
      "41300\n",
      "91900\n",
      "79300\n",
      "3500\n",
      "54000\n",
      "66700\n",
      "28800\n",
      "16200\n",
      "41400\n",
      "79400\n",
      "92000\n",
      "3600\n",
      "54100\n",
      "66800\n",
      "28900\n",
      "16300\n",
      "41500\n",
      "79500\n",
      "92100\n",
      "3700\n",
      "54200\n",
      "66900\n",
      "29000\n",
      "41600\n",
      "16400\n",
      "79600\n",
      "92200\n",
      "3800\n",
      "54300\n",
      "67000\n",
      "29100\n",
      "16500\n",
      "41700\n",
      "79700\n",
      "92300\n",
      "3900\n",
      "54400\n",
      "67100\n",
      "29200\n",
      "16600\n",
      "41800\n",
      "79800\n",
      "4000\n",
      "92400\n",
      "54500\n",
      "67200\n",
      "29300\n",
      "16700\n",
      "41900\n",
      "79900\n",
      "4100\n",
      "92500\n",
      "54600\n",
      "67300\n",
      "29400\n",
      "16800\n",
      "42000\n",
      "80000\n",
      "4200\n",
      "92600\n",
      "54700\n",
      "67400\n",
      "29500\n",
      "16900\n",
      "42100\n",
      "80100\n",
      "4300\n",
      "92700\n",
      "54800\n",
      "67500\n",
      "29600\n",
      "17000\n",
      "42200\n",
      "80200\n",
      "4400\n",
      "92800\n",
      "54900\n",
      "67600\n",
      "29700\n",
      "17100\n",
      "42300\n",
      "80300\n",
      "4500\n",
      "92900\n",
      "55000\n",
      "67700\n",
      "29800\n",
      "17200\n",
      "42400\n",
      "80400\n",
      "4600\n",
      "93000\n",
      "67800\n",
      "55100\n",
      "29900\n",
      "17300\n",
      "42500\n",
      "80500\n",
      "4700\n",
      "93100\n",
      "67900\n",
      "55200\n",
      "30000\n",
      "17400\n",
      "42600\n",
      "80600\n",
      "4800\n",
      "93200\n",
      "68000\n",
      "55300\n",
      "30100\n",
      "17500\n",
      "42700\n",
      "80700\n",
      "4900\n",
      "93300\n",
      "68100\n",
      "55400\n",
      "30200\n",
      "17600\n",
      "42800\n",
      "80800\n",
      "5000\n",
      "93400\n",
      "68200\n",
      "55500\n",
      "30300\n",
      "17700\n",
      "42900\n",
      "80900\n",
      "5100\n",
      "93500\n",
      "68300\n",
      "55600\n",
      "30400\n",
      "17800\n",
      "43000\n",
      "81000\n",
      "5200\n",
      "93600\n",
      "68400\n",
      "55700\n",
      "30500\n",
      "17900\n",
      "43100\n",
      "81100\n",
      "5300\n",
      "93700\n",
      "68500\n",
      "55800\n",
      "30600\n",
      "18000\n",
      "43200\n",
      "81200\n",
      "5400\n",
      "93800\n",
      "68600\n",
      "55900\n",
      "30700\n",
      "18100\n",
      "43300\n",
      "81300\n",
      "5500\n",
      "93900\n",
      "68700\n",
      "30800\n",
      "56000\n",
      "18200\n",
      "43400\n",
      "81400\n",
      "5600\n",
      "94000\n",
      "68800\n",
      "30900\n",
      "56100\n",
      "18300\n",
      "43500\n",
      "81500\n",
      "5700\n",
      "94100\n",
      "68900\n",
      "31000\n",
      "56200\n",
      "18400\n",
      "43600\n",
      "81600\n",
      "5800\n",
      "69000\n",
      "94200\n",
      "31100\n",
      "56300\n",
      "18500\n",
      "43700\n",
      "81700\n",
      "5900\n",
      "69100\n",
      "94300\n",
      "31200\n",
      "56400\n",
      "18600\n",
      "43800\n",
      "81800\n",
      "6000\n",
      "69200\n",
      "94400\n",
      "31300\n",
      "56500\n",
      "18700\n",
      "81900\n",
      "43900\n",
      "6100\n",
      "69300\n",
      "31400\n",
      "94500\n",
      "56600\n",
      "18800\n",
      "6200\n",
      "82000\n",
      "44000\n",
      "69400\n",
      "31500\n",
      "94600\n",
      "56700\n",
      "18900\n",
      "6300\n",
      "82100\n",
      "44100\n",
      "69500\n",
      "31600\n",
      "94700\n",
      "56800\n",
      "19000\n",
      "6400\n",
      "82200\n",
      "44200\n",
      "69600\n",
      "31700\n",
      "94800\n",
      "56900\n",
      "19100\n",
      "6500\n",
      "82300\n",
      "44300\n",
      "69700\n",
      "94900\n",
      "31800\n",
      "57000\n",
      "19200\n",
      "6600\n",
      "82400\n",
      "44400\n",
      "69800\n",
      "31900\n",
      "95000\n",
      "57100\n",
      "19300\n",
      "6700\n",
      "82500\n",
      "44500\n",
      "69900\n",
      "32000\n",
      "95100\n",
      "57200\n",
      "19400\n",
      "6800\n",
      "82600\n",
      "44600\n",
      "70000\n",
      "32100\n",
      "95200\n",
      "57300\n",
      "19500\n",
      "6900\n",
      "82700\n",
      "44700\n",
      "70100\n",
      "32200\n",
      "95300\n",
      "57400\n",
      "19600\n",
      "7000\n",
      "82800\n",
      "44800\n",
      "70200\n",
      "32300\n",
      "95400\n",
      "57500\n",
      "19700\n",
      "7100\n",
      "82900\n",
      "44900\n",
      "70300\n",
      "32400\n",
      "95500\n",
      "57600\n",
      "19800\n",
      "7200\n",
      "83000\n",
      "45000\n",
      "70400\n",
      "95600\n",
      "32500\n",
      "57700\n",
      "19900\n",
      "7300\n",
      "83100\n",
      "45100\n",
      "70500\n",
      "95700\n",
      "32600\n",
      "57800\n",
      "20000\n",
      "7400\n",
      "83200\n",
      "45200\n",
      "70600\n",
      "32700\n",
      "95800\n",
      "57900\n",
      "20100\n",
      "7500\n",
      "83300\n",
      "45300\n",
      "70700\n",
      "32800\n",
      "95900\n",
      "58000\n",
      "20200\n",
      "7600\n",
      "83400\n",
      "45400\n",
      "70800\n",
      "32900\n",
      "96000\n",
      "58100\n",
      "20300\n",
      "7700\n",
      "83500\n",
      "45500\n",
      "70900\n",
      "33000\n",
      "96100\n",
      "58200\n",
      "20400\n",
      "7800\n",
      "83600\n",
      "45600\n",
      "71000\n",
      "33100\n",
      "96200\n",
      "58300\n",
      "20500\n",
      "7900\n",
      "83700\n",
      "45700\n",
      "71100\n",
      "33200\n",
      "96300\n",
      "58400\n",
      "20600\n",
      "8000\n",
      "83800\n",
      "45800\n",
      "71200\n",
      "33300\n",
      "96400\n",
      "58500\n",
      "20700\n",
      "8100\n",
      "83900\n",
      "45900\n",
      "71300\n",
      "96500\n",
      "33400\n",
      "58600\n",
      "20800\n",
      "8200\n",
      "84000\n",
      "46000\n",
      "71400\n",
      "33500\n",
      "96600\n",
      "58700\n",
      "20900\n",
      "8300\n",
      "84100\n",
      "46100\n",
      "71500\n",
      "96700\n",
      "33600\n",
      "58800\n",
      "21000\n",
      "8400\n",
      "84200\n",
      "46200\n",
      "71600\n",
      "96800\n",
      "33700\n",
      "58900\n",
      "21100\n",
      "8500\n",
      "84300\n",
      "46300\n",
      "71700\n",
      "96900\n",
      "33800\n",
      "59000\n",
      "21200\n",
      "8600\n",
      "84400\n",
      "46400\n",
      "71800\n",
      "33900\n",
      "97000\n",
      "59100\n",
      "21300\n",
      "8700\n",
      "84500\n",
      "46500\n",
      "71900\n",
      "34000\n",
      "97100\n",
      "59200\n",
      "21400\n",
      "8800\n",
      "84600\n",
      "46600\n",
      "72000\n",
      "97200\n",
      "34100\n",
      "59300\n",
      "21500\n",
      "8900\n",
      "84700\n",
      "46700\n",
      "72100\n",
      "34200\n",
      "97300\n",
      "59400\n",
      "21600\n",
      "9000\n",
      "84800\n",
      "46800\n",
      "34300\n",
      "72200\n",
      "97400\n",
      "59500\n",
      "21700\n",
      "9100\n",
      "84900\n",
      "46900\n",
      "72300\n",
      "34400\n",
      "97500\n",
      "59600\n",
      "21800\n",
      "9200\n",
      "85000\n",
      "72400\n",
      "34500\n",
      "47000\n",
      "97600\n",
      "59700\n",
      "21900\n",
      "9300\n",
      "85100\n",
      "72500\n",
      "34600\n",
      "47100\n",
      "97700\n",
      "59800\n",
      "22000\n",
      "9400\n",
      "85200\n",
      "34700\n",
      "47200\n",
      "72600\n",
      "97800\n",
      "59900\n",
      "22100\n",
      "9500\n",
      "85300\n",
      "47300\n",
      "72700\n",
      "34800\n",
      "97900\n",
      "60000\n",
      "22200\n",
      "9600\n",
      "85400\n",
      "47400\n",
      "34900\n",
      "72800\n",
      "98000\n",
      "60100\n",
      "22300\n",
      "9700\n",
      "85500\n",
      "72900\n",
      "35000\n",
      "47500\n",
      "98100\n",
      "60200\n",
      "22400\n",
      "9800\n",
      "85600\n",
      "73000\n",
      "98200\n",
      "47600\n",
      "35100\n",
      "60300\n",
      "22500\n",
      "9900\n",
      "85700\n",
      "73100\n",
      "98300\n",
      "35200\n",
      "47700\n",
      "60400\n",
      "22600\n",
      "10000\n",
      "85800\n",
      "73200\n",
      "98400\n",
      "35300\n",
      "47800\n",
      "60500\n",
      "22700\n",
      "10100\n",
      "85900\n",
      "73300\n",
      "98500\n",
      "47900\n",
      "35400\n",
      "60600\n",
      "22800\n",
      "10200\n",
      "86000\n",
      "98600\n",
      "73400\n",
      "35500\n",
      "48000\n",
      "60700\n",
      "22900\n",
      "10300\n",
      "86100\n",
      "98700\n",
      "48100\n",
      "73500\n",
      "35600\n",
      "60800\n",
      "23000\n",
      "10400\n",
      "86200\n",
      "98800\n",
      "48200\n",
      "35700\n",
      "73600\n",
      "23100\n",
      "60900\n",
      "10500\n",
      "86300\n",
      "98900\n",
      "35800\n",
      "48300\n",
      "73700\n",
      "23200\n",
      "61000\n",
      "10600\n",
      "86400\n",
      "99000\n",
      "35900\n",
      "73800\n",
      "48400\n",
      "23300\n",
      "86500\n",
      "10700\n",
      "61100\n",
      "99100\n",
      "36000\n",
      "73900\n",
      "23400\n",
      "48500\n",
      "61200\n",
      "10800\n",
      "86600\n",
      "99200\n",
      "36100\n",
      "74000\n",
      "23500\n",
      "61300\n",
      "48600\n",
      "86700\n",
      "10900\n",
      "99300\n",
      "36200\n",
      "74100\n",
      "23600\n",
      "61400\n",
      "48700\n",
      "86800\n",
      "11000\n",
      "99400\n",
      "36300\n",
      "74200\n",
      "23700\n",
      "61500\n",
      "48800\n",
      "86900\n",
      "11100\n",
      "99500\n",
      "36400\n",
      "74300\n",
      "23800\n",
      "61600\n",
      "48900\n",
      "87000\n",
      "11200\n",
      "99600\n",
      "36500\n",
      "23900\n",
      "74400\n",
      "49000\n",
      "87100\n",
      "61700\n",
      "11300\n",
      "99700\n",
      "36600\n",
      "24000\n",
      "74500\n",
      "87200\n",
      "61800\n",
      "49100\n",
      "11400\n",
      "36700\n",
      "99800\n",
      "74600\n",
      "24100\n",
      "87300\n",
      "61900\n",
      "49200\n",
      "11500\n",
      "99900\n",
      "36800\n",
      "24200\n",
      "74700\n",
      "87400\n",
      "62000\n",
      "49300\n",
      "11600\n",
      "100000\n",
      "36900\n",
      "24300\n",
      "74800\n",
      "87500\n",
      "62100\n",
      "49400\n",
      "11700\n",
      "100100\n",
      "37000\n",
      "24400\n",
      "74900\n",
      "87600\n",
      "62200\n",
      "49500\n",
      "11800\n",
      "100200\n",
      "37100\n",
      "24500\n",
      "75000\n",
      "87700\n",
      "62300\n",
      "11900\n",
      "49600\n",
      "100300\n",
      "37200\n",
      "24600\n",
      "75100\n",
      "87800\n",
      "62400\n",
      "49700\n",
      "12000\n",
      "100400\n",
      "24700\n",
      "37300\n",
      "75200\n",
      "87900\n",
      "62500\n",
      "12100\n",
      "49800\n",
      "100500\n",
      "24800\n",
      "37400\n",
      "75300\n",
      "88000\n",
      "62600\n",
      "12200\n",
      "49900\n",
      "100600\n",
      "24900\n",
      "37500\n",
      "75400\n",
      "88100\n",
      "62700\n",
      "12300\n",
      "50000\n",
      "100700\n",
      "25000\n",
      "37600\n",
      "75500\n",
      "88200\n",
      "62800\n",
      "12400\n",
      "50100\n",
      "100800\n",
      "25100\n",
      "37700\n",
      "75600\n",
      "88300\n",
      "12500\n",
      "62900\n",
      "50200\n",
      "100900\n",
      "25200\n",
      "37800\n",
      "75700\n",
      "88400\n",
      "63000\n",
      "12600\n",
      "50300\n",
      "101000\n",
      "37900\n",
      "75800\n",
      "101100\n",
      "63100\n",
      "50400\n",
      "139000\n",
      "126400\n",
      "113800\n",
      "101200\n",
      "50500\n",
      "164300\n",
      "151700\n",
      "139100\n",
      "176900\n",
      "126500\n",
      "113900\n",
      "101300\n",
      "164400\n",
      "151800\n",
      "177000\n",
      "139200\n",
      "126600\n",
      "114000\n",
      "189600\n",
      "101400\n",
      "164500\n",
      "151900\n",
      "177100\n",
      "139300\n",
      "126700\n",
      "114100\n",
      "189700\n",
      "101500\n",
      "164600\n",
      "152000\n",
      "139400\n",
      "177200\n",
      "126800\n",
      "114200\n",
      "189800\n",
      "101600\n",
      "164700\n",
      "152100\n",
      "139500\n",
      "177300\n",
      "126900\n",
      "114300\n",
      "189900\n",
      "101700\n",
      "164800\n",
      "152200\n",
      "139600\n",
      "127000\n",
      "177400\n",
      "114400\n",
      "190000\n",
      "101800\n",
      "164900\n",
      "152300\n",
      "139700\n",
      "127100\n",
      "177500\n",
      "114500\n",
      "190100\n",
      "101900\n",
      "165000\n",
      "152400\n",
      "139800\n",
      "177600\n",
      "127200\n",
      "114600\n",
      "190200\n",
      "102000\n",
      "165100\n",
      "152500\n",
      "139900\n",
      "127300\n",
      "177700\n",
      "190300\n",
      "114700\n",
      "102100\n",
      "152600\n",
      "165200\n",
      "140000\n",
      "127400\n",
      "177800\n",
      "190400\n",
      "102200\n",
      "114800\n",
      "140100\n",
      "152700\n",
      "165300\n",
      "177900\n",
      "127500\n",
      "190500\n",
      "114900\n",
      "102300\n",
      "140200\n",
      "165400\n",
      "152800\n",
      "127600\n",
      "178000\n",
      "190600\n",
      "102400\n",
      "115000\n",
      "140300\n",
      "165500\n",
      "152900\n",
      "127700\n",
      "190700\n",
      "102500\n",
      "178100\n",
      "115100\n",
      "165600\n",
      "153000\n",
      "140400\n",
      "127800\n",
      "190800\n",
      "102600\n",
      "178200\n",
      "115200\n",
      "165700\n",
      "153100\n",
      "140500\n",
      "127900\n",
      "190900\n",
      "178300\n",
      "102700\n",
      "115300\n",
      "165800\n",
      "153200\n",
      "140600\n",
      "191000\n",
      "128000\n",
      "102800\n",
      "178400\n",
      "115400\n",
      "165900\n",
      "153300\n",
      "140700\n",
      "191100\n",
      "128100\n",
      "178500\n",
      "102900\n",
      "115500\n",
      "166000\n",
      "153400\n",
      "140800\n",
      "191200\n",
      "128200\n",
      "103000\n",
      "178600\n",
      "115600\n",
      "153500\n",
      "166100\n",
      "140900\n",
      "191300\n",
      "103100\n",
      "115700\n",
      "178700\n",
      "128300\n",
      "153600\n",
      "166200\n",
      "141000\n",
      "191400\n",
      "103200\n",
      "178800\n",
      "115800\n",
      "128400\n",
      "153700\n",
      "166300\n",
      "141100\n",
      "191500\n",
      "103300\n",
      "115900\n",
      "128500\n",
      "178900\n",
      "153800\n",
      "166400\n",
      "141200\n",
      "191600\n",
      "103400\n",
      "116000\n",
      "179000\n",
      "128600\n",
      "153900\n",
      "166500\n",
      "141300\n",
      "191700\n",
      "103500\n",
      "179100\n",
      "116100\n",
      "128700\n",
      "154000\n",
      "166600\n",
      "141400\n",
      "191800\n",
      "103600\n",
      "179200\n",
      "116200\n",
      "128800\n",
      "154100\n",
      "166700\n",
      "141500\n",
      "191900\n",
      "103700\n",
      "179300\n",
      "128900\n",
      "116300\n",
      "154200\n",
      "166800\n",
      "141600\n",
      "103800\n",
      "192000\n",
      "179400\n",
      "129000\n",
      "116400\n",
      "154300\n",
      "166900\n",
      "141700\n",
      "103900\n",
      "192100\n",
      "116500\n",
      "179500\n",
      "129100\n",
      "154400\n",
      "167000\n",
      "141800\n",
      "104000\n",
      "192200\n",
      "179600\n",
      "116600\n",
      "129200\n",
      "154500\n",
      "167100\n",
      "141900\n",
      "104100\n",
      "179700\n",
      "116700\n",
      "192300\n",
      "129300\n",
      "154600\n",
      "142000\n",
      "167200\n",
      "104200\n",
      "192400\n",
      "179800\n",
      "116800\n",
      "129400\n",
      "154700\n",
      "142100\n",
      "104300\n",
      "167300\n",
      "192500\n",
      "116900\n",
      "179900\n",
      "129500\n",
      "154800\n",
      "142200\n",
      "104400\n",
      "167400\n",
      "192600\n",
      "117000\n",
      "180000\n",
      "129600\n",
      "154900\n",
      "142300\n",
      "104500\n",
      "167500\n",
      "192700\n",
      "117100\n",
      "180100\n",
      "129700\n",
      "142400\n",
      "155000\n",
      "104600\n",
      "167600\n",
      "180200\n",
      "192800\n",
      "117200\n",
      "129800\n",
      "142500\n",
      "155100\n",
      "104700\n",
      "167700\n",
      "180300\n",
      "117300\n",
      "192900\n",
      "129900\n",
      "142600\n",
      "155200\n",
      "104800\n",
      "167800\n",
      "180400\n",
      "130000\n",
      "117400\n",
      "193000\n",
      "142700\n",
      "155300\n",
      "104900\n",
      "167900\n",
      "180500\n",
      "117500\n",
      "130100\n",
      "193100\n",
      "155400\n",
      "142800\n",
      "105000\n",
      "168000\n",
      "180600\n",
      "117600\n",
      "130200\n",
      "193200\n",
      "155500\n",
      "142900\n",
      "105100\n",
      "168100\n",
      "180700\n",
      "117700\n",
      "193300\n",
      "130300\n",
      "143000\n",
      "155600\n",
      "105200\n",
      "180800\n",
      "168200\n",
      "193400\n",
      "117800\n",
      "130400\n",
      "143100\n",
      "155700\n",
      "105300\n",
      "168300\n",
      "180900\n",
      "117900\n",
      "193500\n",
      "130500\n",
      "105400\n",
      "143200\n",
      "155800\n",
      "168400\n",
      "181000\n",
      "193600\n",
      "118000\n",
      "130600\n",
      "105500\n",
      "155900\n",
      "143300\n",
      "168500\n",
      "181100\n",
      "118100\n",
      "193700\n",
      "130700\n",
      "105600\n",
      "143400\n",
      "156000\n",
      "168600\n",
      "181200\n",
      "193800\n",
      "118200\n",
      "130800\n",
      "105700\n",
      "143500\n",
      "156100\n",
      "168700\n",
      "181300\n",
      "193900\n",
      "118300\n",
      "130900\n",
      "105800\n",
      "143600\n",
      "156200\n",
      "168800\n",
      "181400\n",
      "194000\n",
      "118400\n",
      "131000\n",
      "105900\n",
      "143700\n",
      "168900\n",
      "156300\n",
      "118500\n",
      "181500\n",
      "194100\n",
      "106000\n",
      "131100\n",
      "143800\n",
      "169000\n",
      "156400\n",
      "118600\n",
      "194200\n",
      "181600\n",
      "131200\n",
      "106100\n",
      "169100\n",
      "143900\n",
      "156500\n",
      "118700\n",
      "181700\n",
      "194300\n",
      "106200\n",
      "131300\n",
      "169200\n",
      "144000\n",
      "156600\n",
      "118800\n",
      "181800\n",
      "194400\n",
      "106300\n",
      "169300\n",
      "131400\n",
      "144100\n",
      "156700\n",
      "118900\n",
      "181900\n",
      "106400\n",
      "194500\n",
      "169400\n",
      "131500\n",
      "144200\n",
      "156800\n",
      "119000\n",
      "182000\n",
      "106500\n",
      "194600\n",
      "169500\n",
      "144300\n",
      "131600\n",
      "156900\n",
      "119100\n",
      "182100\n",
      "106600\n",
      "194700\n",
      "169600\n",
      "144400\n",
      "131700\n",
      "157000\n",
      "119200\n",
      "182200\n",
      "106700\n",
      "194800\n",
      "144500\n",
      "169700\n",
      "131800\n",
      "157100\n",
      "119300\n",
      "182300\n",
      "106800\n",
      "194900\n",
      "144600\n",
      "169800\n",
      "131900\n",
      "157200\n",
      "119400\n",
      "182400\n",
      "106900\n",
      "144700\n",
      "195000\n",
      "169900\n",
      "132000\n",
      "157300\n",
      "119500\n",
      "182500\n",
      "107000\n",
      "144800\n",
      "195100\n",
      "170000\n",
      "132100\n",
      "157400\n",
      "119600\n",
      "182600\n",
      "107100\n",
      "144900\n",
      "195200\n",
      "170100\n",
      "132200\n",
      "119700\n",
      "157500\n",
      "182700\n",
      "107200\n",
      "145000\n",
      "195300\n",
      "170200\n",
      "132300\n",
      "119800\n",
      "157600\n",
      "182800\n",
      "107300\n",
      "145100\n",
      "170300\n",
      "195400\n",
      "132400\n",
      "157700\n",
      "119900\n",
      "107400\n",
      "182900\n",
      "145200\n",
      "195500\n",
      "170400\n",
      "132500\n",
      "157800\n",
      "107500\n",
      "120000\n",
      "183000\n",
      "145300\n",
      "195600\n",
      "170500\n",
      "132600\n",
      "157900\n",
      "120100\n",
      "107600\n",
      "183100\n",
      "145400\n",
      "195700\n",
      "170600\n",
      "132700\n",
      "158000\n",
      "120200\n",
      "107700\n",
      "183200\n",
      "145500\n",
      "195800\n",
      "170700\n",
      "132800\n",
      "158100\n",
      "107800\n",
      "120300\n",
      "183300\n",
      "145600\n",
      "195900\n",
      "170800\n",
      "132900\n",
      "158200\n",
      "120400\n",
      "107900\n",
      "183400\n",
      "145700\n",
      "196000\n",
      "170900\n",
      "120500\n",
      "158300\n",
      "108000\n",
      "133000\n",
      "183500\n",
      "145800\n",
      "196100\n",
      "171000\n",
      "120600\n",
      "158400\n",
      "108100\n",
      "133100\n",
      "183600\n",
      "145900\n",
      "196200\n",
      "171100\n",
      "120700\n",
      "158500\n",
      "133200\n",
      "108200\n",
      "183700\n",
      "146000\n",
      "196300\n",
      "171200\n",
      "120800\n",
      "158600\n",
      "108300\n",
      "133300\n",
      "183800\n",
      "146100\n",
      "196400\n",
      "171300\n",
      "120900\n",
      "108400\n",
      "158700\n",
      "133400\n",
      "183900\n",
      "146200\n",
      "196500\n",
      "171400\n",
      "121000\n",
      "108500\n",
      "158800\n",
      "133500\n",
      "184000\n",
      "146300\n",
      "196600\n",
      "171500\n",
      "121100\n",
      "108600\n",
      "158900\n",
      "133600\n",
      "184100\n",
      "146400\n",
      "196700\n",
      "171600\n",
      "121200\n",
      "108700\n",
      "159000\n",
      "133700\n",
      "184200\n",
      "146500\n",
      "196800\n",
      "171700\n",
      "121300\n",
      "108800\n",
      "159100\n",
      "133800\n",
      "184300\n",
      "146600\n",
      "171800\n",
      "196900\n",
      "121400\n",
      "108900\n",
      "159200\n",
      "133900\n",
      "184400\n",
      "146700\n",
      "197000\n",
      "171900\n",
      "121500\n",
      "109000\n",
      "159300\n",
      "134000\n",
      "184500\n",
      "146800\n",
      "197100\n",
      "172000\n",
      "121600\n",
      "109100\n",
      "159400\n",
      "134100\n",
      "184600\n",
      "146900\n",
      "197200\n",
      "109200\n",
      "121700\n",
      "172100\n",
      "159500\n",
      "134200\n",
      "184700\n",
      "147000\n",
      "197300\n",
      "172200\n",
      "121800\n",
      "109300\n",
      "134300\n",
      "159600\n",
      "184800\n",
      "147100\n",
      "197400\n",
      "109400\n",
      "121900\n",
      "134400\n",
      "172300\n",
      "159700\n",
      "184900\n",
      "147200\n",
      "197500\n",
      "109500\n",
      "122000\n",
      "134500\n",
      "172400\n",
      "159800\n",
      "185000\n",
      "147300\n",
      "197600\n",
      "109600\n",
      "122100\n",
      "172500\n",
      "134600\n",
      "159900\n",
      "185100\n",
      "147400\n",
      "109700\n",
      "197700\n",
      "122200\n",
      "172600\n",
      "134700\n",
      "160000\n",
      "185200\n",
      "147500\n",
      "109800\n",
      "197800\n",
      "122300\n",
      "134800\n",
      "172700\n",
      "160100\n",
      "185300\n",
      "147600\n",
      "109900\n",
      "197900\n",
      "122400\n",
      "134900\n",
      "172800\n",
      "160200\n",
      "185400\n",
      "147700\n",
      "110000\n",
      "198000\n",
      "122500\n",
      "135000\n",
      "172900\n",
      "160300\n",
      "147800\n",
      "185500\n",
      "110100\n",
      "198100\n",
      "135100\n",
      "173000\n",
      "122600\n",
      "160400\n",
      "185600\n",
      "147900\n",
      "110200\n",
      "198200\n",
      "135200\n",
      "173100\n",
      "122700\n",
      "160500\n",
      "185700\n",
      "148000\n",
      "110300\n",
      "198300\n",
      "135300\n",
      "173200\n",
      "122800\n",
      "160600\n",
      "185800\n",
      "148100\n",
      "110400\n",
      "198400\n",
      "135400\n",
      "173300\n",
      "122900\n",
      "160700\n",
      "185900\n",
      "148200\n",
      "110500\n",
      "198500\n",
      "135500\n",
      "123000\n",
      "173400\n",
      "160800\n",
      "186000\n",
      "148300\n",
      "110600\n",
      "198600\n",
      "135600\n",
      "123100\n",
      "173500\n",
      "160900\n",
      "186100\n",
      "148400\n",
      "110700\n",
      "198700\n",
      "135700\n",
      "173600\n",
      "123200\n",
      "161000\n",
      "148500\n",
      "186200\n",
      "110800\n",
      "198800\n",
      "135800\n",
      "123300\n",
      "173700\n",
      "161100\n",
      "148600\n",
      "186300\n",
      "110900\n",
      "198900\n",
      "135900\n",
      "123400\n",
      "173800\n",
      "161200\n",
      "148700\n",
      "186400\n",
      "111000\n",
      "199000\n",
      "136000\n",
      "173900\n",
      "123500\n",
      "161300\n",
      "148800\n",
      "186500\n",
      "111100\n",
      "199100\n",
      "174000\n",
      "136100\n",
      "123600\n",
      "161400\n",
      "148900\n",
      "186600\n",
      "111200\n",
      "199200\n",
      "174100\n",
      "136200\n",
      "123700\n",
      "161500\n",
      "149000\n",
      "186700\n",
      "111300\n",
      "199300\n",
      "123800\n",
      "174200\n",
      "136300\n",
      "161600\n",
      "149100\n",
      "186800\n",
      "111400\n",
      "199400\n",
      "123900\n",
      "174300\n",
      "136400\n",
      "149200\n",
      "161700\n",
      "111500\n",
      "186900\n",
      "124000\n",
      "199500\n",
      "174400\n",
      "136500\n",
      "149300\n",
      "161800\n",
      "111600\n",
      "187000\n",
      "124100\n",
      "199600\n",
      "174500\n",
      "136600\n",
      "149400\n",
      "161900\n",
      "187100\n",
      "111700\n",
      "124200\n",
      "199700\n",
      "174600\n",
      "136700\n",
      "149500\n",
      "162000\n",
      "187200\n",
      "111800\n",
      "124300\n",
      "199800\n",
      "174700\n",
      "136800\n",
      "149600\n",
      "162100\n",
      "187300\n",
      "111900\n",
      "124400\n",
      "199900\n",
      "174800\n",
      "136900\n",
      "149700\n",
      "162200\n",
      "187400\n",
      "112000\n",
      "124500\n",
      "174900\n",
      "200000\n",
      "137000\n",
      "149800\n",
      "162300\n",
      "187500\n",
      "112100\n",
      "124600\n",
      "175000\n",
      "200100\n",
      "137100\n",
      "149900\n",
      "162400\n",
      "187600\n",
      "112200\n",
      "124700\n",
      "175100\n",
      "200200\n",
      "150000\n",
      "137200\n",
      "162500\n",
      "187700\n",
      "112300\n",
      "124800\n",
      "175200\n",
      "200300\n",
      "150100\n",
      "137300\n",
      "187800\n",
      "162600\n",
      "112400\n",
      "124900\n",
      "175300\n",
      "200400\n",
      "150200\n",
      "137400\n",
      "187900\n",
      "162700\n",
      "112500\n",
      "125000\n",
      "175400\n",
      "200500\n",
      "150300\n",
      "137500\n",
      "188000\n",
      "112600\n",
      "162800\n",
      "125100\n",
      "175500\n",
      "200600\n",
      "150400\n",
      "137600\n",
      "188100\n",
      "112700\n",
      "162900\n",
      "125200\n",
      "175600\n",
      "200700\n",
      "150500\n",
      "137700\n",
      "188200\n",
      "112800\n",
      "163000\n",
      "125300\n",
      "200800\n",
      "175700\n",
      "150600\n",
      "137800\n",
      "188300\n",
      "112900\n",
      "163100\n",
      "125400\n",
      "200900\n",
      "175800\n",
      "150700\n",
      "137900\n",
      "188400\n",
      "113000\n",
      "163200\n",
      "125500\n",
      "201000\n",
      "175900\n",
      "150800\n",
      "138000\n",
      "188500\n",
      "113100\n",
      "163300\n",
      "125600\n",
      "176000\n",
      "201100\n",
      "150900\n",
      "138100\n",
      "188600\n",
      "113200\n",
      "163400\n",
      "125700\n",
      "176100\n",
      "201200\n",
      "151000\n",
      "138200\n",
      "188700\n",
      "113300\n",
      "163500\n",
      "125800\n",
      "201300\n",
      "176200\n",
      "151100\n",
      "138300\n",
      "113400\n",
      "188800\n",
      "163600\n",
      "125900\n",
      "201400\n",
      "176300\n",
      "151200\n",
      "138400\n",
      "113500\n",
      "188900\n",
      "163700\n",
      "126000\n",
      "201500\n",
      "176400\n",
      "138500\n",
      "151300\n",
      "113600\n",
      "189000\n",
      "163800\n",
      "126100\n",
      "201600\n",
      "176500\n",
      "151400\n",
      "138600\n",
      "113700\n",
      "189100\n",
      "163900\n",
      "126200\n",
      "201700\n",
      "151500\n",
      "176600\n",
      "138700\n",
      "202200\n",
      "189200\n",
      "164000\n",
      "126300\n",
      "201800\n",
      "176700\n",
      "138800\n",
      "151600\n",
      "202300\n",
      "214800\n",
      "164100\n",
      "189300\n",
      "176800\n",
      "201900\n",
      "138900\n",
      "202400\n",
      "214900\n",
      "227500\n",
      "189400\n",
      "164200\n",
      "202000\n",
      "252700\n",
      "202500\n",
      "215000\n",
      "189500\n",
      "227600\n",
      "240100\n",
      "202100\n",
      "265400\n",
      "252800\n",
      "202600\n",
      "278000\n",
      "215100\n",
      "227700\n",
      "240200\n",
      "265500\n",
      "252900\n",
      "202700\n",
      "278100\n",
      "215200\n",
      "227800\n",
      "240300\n",
      "290700\n",
      "265600\n",
      "253000\n",
      "202800\n",
      "278200\n",
      "215300\n",
      "227900\n",
      "240400\n",
      "290800\n",
      "265700\n",
      "253100\n",
      "202900\n",
      "215400\n",
      "278300\n",
      "228000\n",
      "240500\n",
      "290900\n",
      "265800\n",
      "253200\n",
      "203000\n",
      "215500\n",
      "278400\n",
      "228100\n",
      "240600\n",
      "291000\n",
      "265900\n",
      "253300\n",
      "203100\n",
      "215600\n",
      "278500\n",
      "228200\n",
      "240700\n",
      "291100\n",
      "266000\n",
      "253400\n",
      "203200\n",
      "215700\n",
      "278600\n",
      "228300\n",
      "240800\n",
      "291200\n",
      "266100\n",
      "253500\n",
      "203300\n",
      "215800\n",
      "278700\n",
      "228400\n",
      "240900\n",
      "291300\n",
      "266200\n",
      "253600\n",
      "203400\n",
      "215900\n",
      "278800\n",
      "228500\n",
      "241000\n",
      "291400\n",
      "266300\n",
      "253700\n",
      "203500\n",
      "216000\n",
      "278900\n",
      "228600\n",
      "241100\n",
      "291500\n",
      "266400\n",
      "253800\n",
      "203600\n",
      "216100\n",
      "279000\n",
      "228700\n",
      "241200\n",
      "291600\n",
      "266500\n",
      "253900\n",
      "203700\n",
      "279100\n",
      "216200\n",
      "228800\n",
      "241300\n",
      "291700\n",
      "266600\n",
      "254000\n",
      "203800\n",
      "279200\n",
      "216300\n",
      "228900\n",
      "241400\n",
      "291800\n",
      "266700\n",
      "254100\n",
      "203900\n",
      "279300\n",
      "216400\n",
      "229000\n",
      "241500\n",
      "291900\n",
      "266800\n",
      "254200\n",
      "204000\n",
      "279400\n",
      "216500\n",
      "229100\n",
      "241600\n",
      "292000\n",
      "266900\n",
      "204100\n",
      "254300\n",
      "279500\n",
      "216600\n",
      "229200\n",
      "241700\n",
      "292100\n",
      "267000\n",
      "204200\n",
      "279600\n",
      "254400\n",
      "216700\n",
      "229300\n",
      "241800\n",
      "292200\n",
      "267100\n",
      "279700\n",
      "204300\n",
      "216800\n",
      "254500\n",
      "229400\n",
      "241900\n",
      "292300\n",
      "267200\n",
      "279800\n",
      "204400\n",
      "216900\n",
      "254600\n",
      "229500\n",
      "242000\n",
      "292400\n",
      "267300\n",
      "279900\n",
      "254700\n",
      "217000\n",
      "229600\n",
      "204500\n",
      "242100\n",
      "292500\n",
      "267400\n",
      "280000\n",
      "217100\n",
      "254800\n",
      "229700\n",
      "204600\n",
      "242200\n",
      "292600\n",
      "267500\n",
      "280100\n",
      "217200\n",
      "254900\n",
      "229800\n",
      "204700\n",
      "242300\n",
      "292700\n",
      "267600\n",
      "280200\n",
      "217300\n",
      "255000\n",
      "229900\n",
      "204800\n",
      "242400\n",
      "292800\n",
      "267700\n",
      "280300\n",
      "217400\n",
      "230000\n",
      "255100\n",
      "204900\n",
      "242500\n",
      "292900\n",
      "267800\n",
      "280400\n",
      "217500\n",
      "255200\n",
      "230100\n",
      "205000\n",
      "242600\n",
      "293000\n",
      "267900\n",
      "280500\n",
      "217600\n",
      "230200\n",
      "255300\n",
      "242700\n",
      "205100\n",
      "293100\n",
      "280600\n",
      "268000\n",
      "217700\n",
      "230300\n",
      "255400\n",
      "242800\n",
      "205200\n",
      "293200\n",
      "280700\n",
      "268100\n",
      "217800\n",
      "230400\n",
      "255500\n",
      "242900\n",
      "205300\n",
      "293300\n",
      "280800\n",
      "268200\n",
      "217900\n",
      "230500\n",
      "255600\n",
      "243000\n",
      "205400\n",
      "293400\n",
      "268300\n",
      "280900\n",
      "218000\n",
      "230600\n",
      "255700\n",
      "243100\n",
      "205500\n",
      "293500\n",
      "281000\n",
      "268400\n",
      "218100\n",
      "230700\n",
      "255800\n",
      "243200\n",
      "205600\n",
      "293600\n",
      "281100\n",
      "268500\n",
      "218200\n",
      "230800\n",
      "255900\n",
      "243300\n",
      "293700\n",
      "205700\n",
      "281200\n",
      "268600\n",
      "230900\n",
      "218300\n",
      "256000\n",
      "243400\n",
      "293800\n",
      "205800\n",
      "281300\n",
      "268700\n",
      "231000\n",
      "218400\n",
      "256100\n",
      "243500\n",
      "293900\n",
      "205900\n",
      "281400\n",
      "268800\n",
      "231100\n",
      "218500\n",
      "256200\n",
      "243600\n",
      "294000\n",
      "206000\n",
      "281500\n",
      "268900\n",
      "231200\n",
      "218600\n",
      "256300\n",
      "294100\n",
      "243700\n",
      "206100\n",
      "281600\n",
      "231300\n",
      "269000\n",
      "218700\n",
      "294200\n",
      "256400\n",
      "243800\n",
      "206200\n",
      "281700\n",
      "231400\n",
      "269100\n",
      "218800\n",
      "294300\n",
      "256500\n",
      "243900\n",
      "206300\n",
      "281800\n",
      "231500\n",
      "269200\n",
      "218900\n",
      "294400\n",
      "256600\n",
      "244000\n",
      "206400\n",
      "281900\n",
      "231600\n",
      "219000\n",
      "269300\n",
      "294500\n",
      "256700\n",
      "244100\n",
      "206500\n",
      "282000\n",
      "231700\n",
      "219100\n",
      "269400\n",
      "294600\n",
      "256800\n",
      "244200\n",
      "206600\n",
      "282100\n",
      "231800\n",
      "269500\n",
      "219200\n",
      "294700\n",
      "256900\n",
      "244300\n",
      "206700\n",
      "282200\n",
      "231900\n",
      "269600\n",
      "219300\n",
      "294800\n",
      "257000\n",
      "244400\n",
      "206800\n",
      "232000\n",
      "282300\n",
      "269700\n",
      "219400\n",
      "294900\n",
      "257100\n",
      "244500\n",
      "206900\n",
      "282400\n",
      "232100\n",
      "269800\n",
      "219500\n",
      "295000\n",
      "257200\n",
      "244600\n",
      "207000\n",
      "232200\n",
      "282500\n",
      "269900\n",
      "219600\n",
      "295100\n",
      "257300\n",
      "244700\n",
      "207100\n",
      "282600\n",
      "232300\n",
      "270000\n",
      "219700\n",
      "295200\n",
      "257400\n",
      "244800\n",
      "207200\n",
      "282700\n",
      "232400\n",
      "270100\n",
      "219800\n",
      "295300\n",
      "257500\n",
      "244900\n",
      "207300\n",
      "282800\n",
      "232500\n",
      "270200\n",
      "219900\n",
      "295400\n",
      "257600\n",
      "245000\n",
      "207400\n",
      "282900\n",
      "232600\n",
      "270300\n",
      "220000\n",
      "295500\n",
      "257700\n",
      "245100\n",
      "207500\n",
      "283000\n",
      "232700\n",
      "220100\n",
      "270400\n",
      "295600\n",
      "257800\n",
      "245200\n",
      "207600\n",
      "283100\n",
      "232800\n",
      "220200\n",
      "270500\n",
      "295700\n",
      "257900\n",
      "245300\n",
      "207700\n",
      "283200\n",
      "232900\n",
      "220300\n",
      "270600\n",
      "295800\n",
      "258000\n",
      "245400\n",
      "207800\n",
      "283300\n",
      "233000\n",
      "220400\n",
      "270700\n",
      "295900\n",
      "258100\n",
      "245500\n",
      "207900\n",
      "283400\n",
      "220500\n",
      "233100\n",
      "296000\n",
      "270800\n",
      "258200\n",
      "245600\n",
      "208000\n",
      "283500\n",
      "220600\n",
      "233200\n",
      "296100\n",
      "270900\n",
      "258300\n",
      "245700\n",
      "208100\n",
      "283600\n",
      "220700\n",
      "233300\n",
      "296200\n",
      "271000\n",
      "258400\n",
      "245800\n",
      "208200\n",
      "283700\n",
      "220800\n",
      "233400\n",
      "296300\n",
      "271100\n",
      "258500\n",
      "245900\n",
      "208300\n",
      "283800\n",
      "220900\n",
      "296400\n",
      "233500\n",
      "271200\n",
      "258600\n",
      "246000\n",
      "208400\n",
      "283900\n",
      "221000\n",
      "296500\n",
      "233600\n",
      "271300\n",
      "258700\n",
      "246100\n",
      "208500\n",
      "284000\n",
      "221100\n",
      "233700\n",
      "296600\n",
      "271400\n",
      "258800\n",
      "246200\n",
      "208600\n",
      "221200\n",
      "284100\n",
      "233800\n",
      "296700\n",
      "271500\n",
      "258900\n",
      "246300\n",
      "208700\n",
      "221300\n",
      "284200\n",
      "296800\n",
      "233900\n",
      "271600\n",
      "259000\n",
      "246400\n",
      "208800\n",
      "221400\n",
      "284300\n",
      "296900\n",
      "234000\n",
      "271700\n",
      "259100\n",
      "246500\n",
      "208900\n",
      "221500\n",
      "284400\n",
      "297000\n",
      "234100\n",
      "271800\n",
      "259200\n",
      "246600\n",
      "209000\n",
      "221600\n",
      "234200\n",
      "297100\n",
      "284500\n",
      "271900\n",
      "259300\n",
      "246700\n",
      "209100\n",
      "221700\n",
      "284600\n",
      "234300\n",
      "297200\n",
      "272000\n",
      "259400\n",
      "246800\n",
      "209200\n",
      "221800\n",
      "284700\n",
      "297300\n",
      "234400\n",
      "272100\n",
      "259500\n",
      "246900\n",
      "209300\n",
      "221900\n",
      "284800\n",
      "297400\n",
      "234500\n",
      "272200\n",
      "259600\n",
      "247000\n",
      "209400\n",
      "222000\n",
      "284900\n",
      "234600\n",
      "297500\n",
      "272300\n",
      "259700\n",
      "247100\n",
      "209500\n",
      "222100\n",
      "285000\n",
      "234700\n",
      "297600\n",
      "272400\n",
      "259800\n",
      "247200\n",
      "209600\n",
      "222200\n",
      "285100\n",
      "297700\n",
      "234800\n",
      "272500\n",
      "259900\n",
      "247300\n",
      "209700\n",
      "222300\n",
      "285200\n",
      "234900\n",
      "297800\n",
      "272600\n",
      "260000\n",
      "247400\n",
      "209800\n",
      "222400\n",
      "285300\n",
      "235000\n",
      "297900\n",
      "272700\n",
      "247500\n",
      "260100\n",
      "209900\n",
      "222500\n",
      "285400\n",
      "235100\n",
      "298000\n",
      "272800\n",
      "247600\n",
      "260200\n",
      "210000\n",
      "285500\n",
      "222600\n",
      "235200\n",
      "298100\n",
      "272900\n",
      "247700\n",
      "260300\n",
      "210100\n",
      "285600\n",
      "222700\n",
      "235300\n",
      "298200\n",
      "273000\n",
      "247800\n",
      "260400\n",
      "210200\n",
      "285700\n",
      "235400\n",
      "222800\n",
      "298300\n",
      "273100\n",
      "247900\n",
      "260500\n",
      "210300\n",
      "285800\n",
      "222900\n",
      "235500\n",
      "298400\n",
      "273200\n",
      "248000\n",
      "260600\n",
      "210400\n",
      "285900\n",
      "223000\n",
      "235600\n",
      "298500\n",
      "273300\n",
      "248100\n",
      "260700\n",
      "210500\n",
      "286000\n",
      "223100\n",
      "235700\n",
      "298600\n",
      "273400\n",
      "248200\n",
      "260800\n",
      "210600\n",
      "286100\n",
      "223200\n",
      "235800\n",
      "298700\n",
      "273500\n",
      "248300\n",
      "260900\n",
      "210700\n",
      "286200\n",
      "223300\n",
      "235900\n",
      "298800\n",
      "273600\n",
      "248400\n",
      "261000\n",
      "210800\n",
      "286300\n",
      "223400\n",
      "236000\n",
      "298900\n",
      "273700\n",
      "248500\n",
      "261100\n",
      "286400\n",
      "210900\n",
      "223500\n",
      "236100\n",
      "299000\n",
      "273800\n",
      "248600\n",
      "261200\n",
      "211000\n",
      "286500\n",
      "223600\n",
      "236200\n",
      "299100\n",
      "273900\n",
      "248700\n",
      "261300\n",
      "286600\n",
      "211100\n",
      "223700\n",
      "236300\n",
      "299200\n",
      "274000\n",
      "248800\n",
      "261400\n",
      "223800\n",
      "286700\n",
      "211200\n",
      "236400\n",
      "299300\n",
      "274100\n",
      "248900\n",
      "261500\n",
      "223900\n",
      "286800\n",
      "211300\n",
      "236500\n",
      "299400\n",
      "274200\n",
      "249000\n",
      "261600\n",
      "224000\n",
      "286900\n",
      "211400\n",
      "236600\n",
      "299500\n",
      "274300\n",
      "249100\n",
      "261700\n",
      "287000\n",
      "224100\n",
      "211500\n",
      "236700\n",
      "299600\n",
      "274400\n",
      "249200\n",
      "287100\n",
      "261800\n",
      "224200\n",
      "211600\n",
      "236800\n",
      "299700\n",
      "274500\n",
      "249300\n",
      "287200\n",
      "261900\n",
      "224300\n",
      "211700\n",
      "236900\n",
      "299800\n",
      "274600\n",
      "249400\n",
      "287300\n",
      "262000\n",
      "224400\n",
      "211800\n",
      "237000\n",
      "299900\n",
      "274700\n",
      "249500\n",
      "287400\n",
      "262100\n",
      "224500\n",
      "237100\n",
      "211900\n",
      "300000\n",
      "274800\n",
      "249600\n",
      "287500\n",
      "262200\n",
      "224600\n",
      "237200\n",
      "212000\n",
      "300100\n",
      "274900\n",
      "249700\n",
      "287600\n",
      "262300\n",
      "224700\n",
      "237300\n",
      "212100\n",
      "300200\n",
      "275000\n",
      "249800\n",
      "287700\n",
      "262400\n",
      "224800\n",
      "237400\n",
      "212200\n",
      "300300\n",
      "275100\n",
      "249900\n",
      "287800\n",
      "224900\n",
      "262500\n",
      "237500\n",
      "212300\n",
      "300400\n",
      "275200\n",
      "250000\n",
      "287900\n",
      "225000\n",
      "262600\n",
      "237600\n",
      "212400\n",
      "300500\n",
      "275300\n",
      "288000\n",
      "250100\n",
      "225100\n",
      "262700\n",
      "237700\n",
      "300600\n",
      "212500\n",
      "250200\n",
      "288100\n",
      "275400\n",
      "225200\n",
      "262800\n",
      "300700\n",
      "237800\n",
      "212600\n",
      "250300\n",
      "288200\n",
      "275500\n",
      "225300\n",
      "262900\n",
      "300800\n",
      "237900\n",
      "212700\n",
      "250400\n",
      "288300\n",
      "275600\n",
      "225400\n",
      "263000\n",
      "300900\n",
      "238000\n",
      "212800\n",
      "250500\n",
      "288400\n",
      "275700\n",
      "225500\n",
      "238100\n",
      "301000\n",
      "263100\n",
      "212900\n",
      "250600\n",
      "288500\n",
      "275800\n",
      "225600\n",
      "238200\n",
      "263200\n",
      "301100\n",
      "213000\n",
      "250700\n",
      "288600\n",
      "275900\n",
      "225700\n",
      "263300\n",
      "238300\n",
      "301200\n",
      "213100\n",
      "250800\n",
      "288700\n",
      "276000\n",
      "225800\n",
      "238400\n",
      "263400\n",
      "301300\n",
      "213200\n",
      "288800\n",
      "250900\n",
      "276100\n",
      "225900\n",
      "238500\n",
      "263500\n",
      "213300\n",
      "301400\n",
      "251000\n",
      "288900\n",
      "276200\n",
      "226000\n",
      "238600\n",
      "213400\n",
      "263600\n",
      "301500\n",
      "251100\n",
      "289000\n",
      "276300\n",
      "226100\n",
      "238700\n",
      "213500\n",
      "301600\n",
      "263700\n",
      "289100\n",
      "251200\n",
      "276400\n",
      "226200\n",
      "238800\n",
      "213600\n",
      "301700\n",
      "263800\n",
      "289200\n",
      "251300\n",
      "276500\n",
      "226300\n",
      "238900\n",
      "301800\n",
      "213700\n",
      "263900\n",
      "289300\n",
      "251400\n",
      "276600\n",
      "226400\n",
      "239000\n",
      "301900\n",
      "213800\n",
      "264000\n",
      "289400\n",
      "251500\n",
      "276700\n",
      "226500\n",
      "239100\n",
      "302000\n",
      "213900\n",
      "264100\n",
      "289500\n",
      "276800\n",
      "251600\n",
      "226600\n",
      "239200\n",
      "302100\n",
      "214000\n",
      "264200\n",
      "289600\n",
      "276900\n",
      "251700\n",
      "226700\n",
      "239300\n",
      "302200\n",
      "214100\n",
      "264300\n",
      "289700\n",
      "277000\n",
      "251800\n",
      "226800\n",
      "302300\n",
      "239400\n",
      "214200\n",
      "264400\n",
      "289800\n",
      "277100\n",
      "251900\n",
      "226900\n",
      "302400\n",
      "239500\n",
      "214300\n",
      "264500\n",
      "289900\n",
      "277200\n",
      "252000\n",
      "227000\n",
      "302500\n",
      "239600\n",
      "264600\n",
      "214400\n",
      "290000\n",
      "277300\n",
      "252100\n",
      "227100\n",
      "302600\n",
      "239700\n",
      "214500\n",
      "264700\n",
      "290100\n",
      "277400\n",
      "252200\n",
      "227200\n",
      "302700\n",
      "239800\n",
      "214600\n",
      "264800\n",
      "290200\n",
      "277500\n",
      "252300\n",
      "227300\n",
      "302800\n",
      "239900\n",
      "214700\n",
      "264900\n",
      "290300\n",
      "277600\n",
      "252400\n",
      "227400\n",
      "302900\n",
      "240000\n",
      "265000\n",
      "290400\n",
      "252500\n",
      "277700\n",
      "315900\n",
      "303000\n",
      "303300\n",
      "290500\n",
      "265100\n",
      "277800\n",
      "252600\n",
      "328600\n",
      "316000\n",
      "303100\n",
      "303400\n",
      "265200\n",
      "290600\n",
      "277900\n",
      "316100\n",
      "328700\n",
      "303200\n",
      "303500\n",
      "353800\n",
      "265300\n",
      "341200\n",
      "316200\n",
      "366500\n",
      "328800\n",
      "303600\n",
      "391700\n",
      "379100\n",
      "353900\n",
      "341300\n",
      "316300\n",
      "328900\n",
      "303700\n",
      "391800\n",
      "379200\n",
      "354000\n",
      "341400\n",
      "366600\n",
      "316400\n",
      "329000\n",
      "303800\n",
      "391900\n",
      "379300\n",
      "354100\n",
      "341500\n",
      "366700\n",
      "329100\n",
      "316500\n",
      "303900\n",
      "392000\n",
      "379400\n",
      "354200\n",
      "341600\n",
      "366800\n",
      "329200\n",
      "316600\n",
      "304000\n",
      "392100\n",
      "354300\n",
      "341700\n",
      "379500\n",
      "366900\n",
      "329300\n",
      "316700\n",
      "304100\n",
      "379600\n",
      "341800\n",
      "392200\n",
      "354400\n",
      "367000\n",
      "329400\n",
      "316800\n",
      "304200\n",
      "341900\n",
      "379700\n",
      "392300\n",
      "354500\n",
      "367100\n",
      "329500\n",
      "304300\n",
      "316900\n",
      "342000\n",
      "354600\n",
      "379800\n",
      "392400\n",
      "367200\n",
      "329600\n",
      "304400\n",
      "317000\n",
      "342100\n",
      "354700\n",
      "379900\n",
      "392500\n",
      "367300\n",
      "329700\n",
      "304500\n",
      "317100\n",
      "342200\n",
      "380000\n",
      "354800\n",
      "392600\n",
      "367400\n",
      "329800\n",
      "304600\n",
      "342300\n",
      "354900\n",
      "317200\n",
      "380100\n",
      "392700\n",
      "367500\n",
      "329900\n",
      "304700\n",
      "342400\n",
      "355000\n",
      "317300\n",
      "380200\n",
      "392800\n",
      "367600\n",
      "330000\n",
      "304800\n",
      "342500\n",
      "355100\n",
      "380300\n",
      "317400\n",
      "392900\n",
      "367700\n",
      "330100\n",
      "304900\n",
      "342600\n",
      "355200\n",
      "380400\n",
      "317500\n",
      "393000\n",
      "367800\n",
      "330200\n",
      "305000\n",
      "342700\n",
      "355300\n",
      "380500\n",
      "317600\n",
      "393100\n",
      "367900\n",
      "330300\n",
      "305100\n",
      "342800\n",
      "355400\n",
      "380600\n",
      "317700\n",
      "393200\n",
      "368000\n",
      "330400\n",
      "305200\n",
      "342900\n",
      "380700\n",
      "355500\n",
      "317800\n",
      "393300\n",
      "368100\n",
      "330500\n",
      "305300\n",
      "343000\n",
      "355600\n",
      "380800\n",
      "317900\n",
      "393400\n",
      "368200\n",
      "330600\n",
      "305400\n",
      "343100\n",
      "380900\n",
      "355700\n",
      "393500\n",
      "318000\n",
      "368300\n",
      "305500\n",
      "330700\n",
      "343200\n",
      "381000\n",
      "355800\n",
      "393600\n",
      "318100\n",
      "368400\n",
      "330800\n",
      "305600\n",
      "343300\n",
      "381100\n",
      "355900\n",
      "393700\n",
      "318200\n",
      "368500\n",
      "330900\n",
      "305700\n",
      "343400\n",
      "381200\n",
      "356000\n",
      "393800\n",
      "318300\n",
      "368600\n",
      "305800\n",
      "331000\n",
      "343500\n",
      "381300\n",
      "356100\n",
      "393900\n",
      "318400\n",
      "368700\n",
      "305900\n",
      "331100\n",
      "343600\n",
      "381400\n",
      "356200\n",
      "394000\n",
      "318500\n",
      "368800\n",
      "306000\n",
      "331200\n",
      "343700\n",
      "381500\n",
      "356300\n",
      "394100\n",
      "318600\n",
      "368900\n",
      "306100\n",
      "331300\n",
      "343800\n",
      "381600\n",
      "356400\n",
      "394200\n",
      "318700\n",
      "369000\n",
      "306200\n",
      "343900\n",
      "331400\n",
      "381700\n",
      "356500\n",
      "394300\n",
      "318800\n",
      "369100\n",
      "306300\n",
      "344000\n",
      "331500\n",
      "381800\n",
      "356600\n",
      "394400\n",
      "318900\n",
      "369200\n",
      "306400\n",
      "344100\n",
      "331600\n",
      "381900\n",
      "356700\n",
      "394500\n",
      "319000\n",
      "369300\n",
      "306500\n",
      "344200\n",
      "331700\n",
      "382000\n",
      "356800\n",
      "394600\n",
      "319100\n",
      "369400\n",
      "306600\n",
      "344300\n",
      "331800\n",
      "382100\n",
      "356900\n",
      "394700\n",
      "319200\n",
      "369500\n",
      "306700\n",
      "344400\n",
      "331900\n",
      "382200\n",
      "357000\n",
      "394800\n",
      "319300\n",
      "369600\n",
      "306800\n",
      "344500\n",
      "332000\n",
      "382300\n",
      "357100\n",
      "394900\n",
      "369700\n",
      "319400\n",
      "306900\n",
      "344600\n",
      "332100\n",
      "382400\n",
      "395000\n",
      "357200\n",
      "369800\n",
      "319500\n",
      "307000\n",
      "344700\n",
      "332200\n",
      "382500\n",
      "395100\n",
      "357300\n",
      "369900\n",
      "319600\n",
      "307100\n",
      "344800\n",
      "332300\n",
      "382600\n",
      "395200\n",
      "357400\n",
      "370000\n",
      "319700\n",
      "307200\n",
      "344900\n",
      "332400\n",
      "382700\n",
      "357500\n",
      "395300\n",
      "370100\n",
      "319800\n",
      "307300\n",
      "345000\n",
      "332500\n",
      "382800\n",
      "395400\n",
      "357600\n",
      "370200\n",
      "319900\n",
      "307400\n",
      "345100\n",
      "332600\n",
      "382900\n",
      "395500\n",
      "357700\n",
      "370300\n",
      "320000\n",
      "307500\n",
      "345200\n",
      "332700\n",
      "383000\n",
      "395600\n",
      "357800\n",
      "370400\n",
      "320100\n",
      "307600\n",
      "345300\n",
      "332800\n",
      "383100\n",
      "395700\n",
      "357900\n",
      "370500\n",
      "320200\n",
      "307700\n",
      "345400\n",
      "332900\n",
      "383200\n",
      "395800\n",
      "358000\n",
      "370600\n",
      "307800\n",
      "320300\n",
      "345500\n",
      "383300\n",
      "333000\n",
      "358100\n",
      "395900\n",
      "370700\n",
      "307900\n",
      "320400\n",
      "345600\n",
      "383400\n",
      "333100\n",
      "358200\n",
      "396000\n",
      "370800\n",
      "345700\n",
      "320500\n",
      "308000\n",
      "383500\n",
      "333200\n",
      "358300\n",
      "396100\n",
      "370900\n",
      "345800\n",
      "308100\n",
      "320600\n",
      "383600\n",
      "333300\n",
      "358400\n",
      "396200\n",
      "371000\n",
      "345900\n",
      "320700\n",
      "308200\n",
      "383700\n",
      "333400\n",
      "358500\n",
      "396300\n",
      "371100\n",
      "346000\n",
      "320800\n",
      "308300\n",
      "383800\n",
      "333500\n",
      "358600\n",
      "396400\n",
      "371200\n",
      "346100\n",
      "320900\n",
      "308400\n",
      "383900\n",
      "333600\n",
      "358700\n",
      "396500\n",
      "371300\n",
      "346200\n",
      "321000\n",
      "308500\n",
      "384000\n",
      "333700\n",
      "358800\n",
      "396600\n",
      "371400\n",
      "346300\n",
      "321100\n",
      "384100\n",
      "308600\n",
      "333800\n",
      "358900\n",
      "396700\n",
      "371500\n",
      "346400\n",
      "321200\n",
      "308700\n",
      "384200\n",
      "333900\n",
      "359000\n",
      "396800\n",
      "371600\n",
      "346500\n",
      "321300\n",
      "308800\n",
      "384300\n",
      "334000\n",
      "359100\n",
      "396900\n",
      "346600\n",
      "371700\n",
      "321400\n",
      "308900\n",
      "384400\n",
      "334100\n",
      "359200\n",
      "397000\n",
      "346700\n",
      "371800\n",
      "321500\n",
      "334200\n",
      "309000\n",
      "384500\n",
      "359300\n",
      "397100\n",
      "346800\n",
      "371900\n",
      "321600\n",
      "384600\n",
      "309100\n",
      "334300\n",
      "359400\n",
      "397200\n",
      "346900\n",
      "372000\n",
      "321700\n",
      "384700\n",
      "309200\n",
      "334400\n",
      "359500\n",
      "397300\n",
      "347000\n",
      "372100\n",
      "321800\n",
      "384800\n",
      "309300\n",
      "334500\n",
      "359600\n",
      "397400\n",
      "347100\n",
      "372200\n",
      "321900\n",
      "384900\n",
      "309400\n",
      "334600\n",
      "359700\n",
      "347200\n",
      "397500\n",
      "372300\n",
      "322000\n",
      "385000\n",
      "309500\n",
      "334700\n",
      "359800\n",
      "347300\n",
      "397600\n",
      "372400\n",
      "385100\n",
      "322100\n",
      "309600\n",
      "334800\n",
      "359900\n",
      "347400\n",
      "397700\n",
      "372500\n",
      "385200\n",
      "322200\n",
      "309700\n",
      "334900\n",
      "360000\n",
      "347500\n",
      "397800\n",
      "372600\n",
      "385300\n",
      "322300\n",
      "309800\n",
      "335000\n",
      "360100\n",
      "347600\n",
      "372700\n",
      "397900\n",
      "322400\n",
      "385400\n",
      "309900\n",
      "335100\n",
      "347700\n",
      "360200\n",
      "372800\n",
      "398000\n",
      "322500\n",
      "385500\n",
      "310000\n",
      "335200\n",
      "347800\n",
      "360300\n",
      "372900\n",
      "398100\n",
      "322600\n",
      "385600\n",
      "310100\n",
      "335300\n",
      "347900\n",
      "360400\n",
      "373000\n",
      "398200\n",
      "385700\n",
      "322700\n",
      "310200\n",
      "335400\n",
      "348000\n",
      "360500\n",
      "373100\n",
      "398300\n",
      "385800\n",
      "322800\n",
      "310300\n",
      "335500\n",
      "348100\n",
      "360600\n",
      "373200\n",
      "398400\n",
      "385900\n",
      "322900\n",
      "310400\n",
      "335600\n",
      "348200\n",
      "360700\n",
      "373300\n",
      "398500\n",
      "386000\n",
      "323000\n",
      "310500\n",
      "335700\n",
      "348300\n",
      "360800\n",
      "398600\n",
      "373400\n",
      "386100\n",
      "323100\n",
      "310600\n",
      "335800\n",
      "348400\n",
      "360900\n",
      "398700\n",
      "373500\n",
      "386200\n",
      "323200\n",
      "310700\n",
      "335900\n",
      "348500\n",
      "361000\n",
      "398800\n",
      "373600\n",
      "386300\n",
      "323300\n",
      "310800\n",
      "336000\n",
      "348600\n",
      "361100\n",
      "373700\n",
      "398900\n",
      "386400\n",
      "323400\n",
      "310900\n",
      "336100\n",
      "348700\n",
      "361200\n",
      "373800\n",
      "399000\n",
      "386500\n",
      "323500\n",
      "311000\n",
      "336200\n",
      "348800\n",
      "361300\n",
      "373900\n",
      "399100\n",
      "386600\n",
      "323600\n",
      "311100\n",
      "336300\n",
      "348900\n",
      "374000\n",
      "399200\n",
      "361400\n",
      "386700\n",
      "323700\n",
      "311200\n",
      "336400\n",
      "349000\n",
      "374100\n",
      "361500\n",
      "399300\n",
      "386800\n",
      "323800\n",
      "311300\n",
      "336500\n",
      "349100\n",
      "374200\n",
      "361600\n",
      "399400\n",
      "386900\n",
      "323900\n",
      "311400\n",
      "336600\n",
      "349200\n",
      "374300\n",
      "399500\n",
      "361700\n",
      "387000\n",
      "324000\n",
      "311500\n",
      "336700\n",
      "349300\n",
      "374400\n",
      "361800\n",
      "399600\n",
      "387100\n",
      "311600\n",
      "324100\n",
      "336800\n",
      "349400\n",
      "374500\n",
      "361900\n",
      "399700\n",
      "387200\n",
      "311700\n",
      "324200\n",
      "336900\n",
      "349500\n",
      "374600\n",
      "362000\n",
      "399800\n",
      "311800\n",
      "387300\n",
      "337000\n",
      "324300\n",
      "349600\n",
      "362100\n",
      "399900\n",
      "374700\n",
      "311900\n",
      "387400\n",
      "337100\n",
      "324400\n",
      "349700\n",
      "362200\n",
      "400000\n",
      "374800\n",
      "312000\n",
      "337200\n",
      "387500\n",
      "324500\n",
      "349800\n",
      "362300\n",
      "400100\n",
      "374900\n",
      "312100\n",
      "337300\n",
      "387600\n",
      "324600\n",
      "349900\n",
      "362400\n",
      "375000\n",
      "400200\n",
      "312200\n",
      "337400\n",
      "387700\n",
      "324700\n",
      "350000\n",
      "362500\n",
      "375100\n",
      "400300\n",
      "312300\n",
      "337500\n",
      "387800\n",
      "324800\n",
      "350100\n",
      "362600\n",
      "400400\n",
      "375200\n",
      "312400\n",
      "337600\n",
      "387900\n",
      "324900\n",
      "350200\n",
      "362700\n",
      "400500\n",
      "375300\n",
      "312500\n",
      "337700\n",
      "388000\n",
      "325000\n",
      "350300\n",
      "362800\n",
      "400600\n",
      "312600\n",
      "375400\n",
      "337800\n",
      "388100\n",
      "325100\n",
      "350400\n",
      "362900\n",
      "400700\n",
      "375500\n",
      "312700\n",
      "337900\n",
      "388200\n",
      "325200\n",
      "350500\n",
      "363000\n",
      "400800\n",
      "375600\n",
      "312800\n",
      "388300\n",
      "338000\n",
      "325300\n",
      "350600\n",
      "363100\n",
      "400900\n",
      "375700\n",
      "312900\n",
      "388400\n",
      "338100\n",
      "325400\n",
      "350700\n",
      "363200\n",
      "401000\n",
      "375800\n",
      "313000\n",
      "388500\n",
      "338200\n",
      "325500\n",
      "350800\n",
      "363300\n",
      "401100\n",
      "375900\n",
      "313100\n",
      "388600\n",
      "338300\n",
      "325600\n",
      "350900\n",
      "363400\n",
      "401200\n",
      "376000\n",
      "388700\n",
      "313200\n",
      "338400\n",
      "325700\n",
      "351000\n",
      "363500\n",
      "376100\n",
      "401300\n",
      "313300\n",
      "388800\n",
      "338500\n",
      "325800\n",
      "351100\n",
      "363600\n",
      "376200\n",
      "401400\n",
      "313400\n",
      "388900\n",
      "338600\n",
      "325900\n",
      "351200\n",
      "363700\n",
      "401500\n",
      "376300\n",
      "313500\n",
      "389000\n",
      "338700\n",
      "326000\n",
      "351300\n",
      "363800\n",
      "401600\n",
      "376400\n",
      "389100\n",
      "313600\n",
      "338800\n",
      "326100\n",
      "351400\n",
      "363900\n",
      "401700\n",
      "376500\n",
      "389200\n",
      "313700\n",
      "338900\n",
      "326200\n",
      "351500\n",
      "364000\n",
      "376600\n",
      "401800\n",
      "389300\n",
      "313800\n",
      "339000\n",
      "326300\n",
      "351600\n",
      "364100\n",
      "376700\n",
      "401900\n",
      "389400\n",
      "339100\n",
      "313900\n",
      "326400\n",
      "351700\n",
      "364200\n",
      "376800\n",
      "402000\n",
      "389500\n",
      "339200\n",
      "314000\n",
      "326500\n",
      "351800\n",
      "364300\n",
      "376900\n",
      "402100\n",
      "389600\n",
      "339300\n",
      "314100\n",
      "326600\n",
      "351900\n",
      "364400\n",
      "377000\n",
      "389700\n",
      "402200\n",
      "339400\n",
      "314200\n",
      "326700\n",
      "352000\n",
      "364500\n",
      "377100\n",
      "389800\n",
      "402300\n",
      "339500\n",
      "314300\n",
      "352100\n",
      "326800\n",
      "364600\n",
      "377200\n",
      "389900\n",
      "402400\n",
      "339600\n",
      "314400\n",
      "352200\n",
      "326900\n",
      "364700\n",
      "377300\n",
      "390000\n",
      "402500\n",
      "339700\n",
      "314500\n",
      "327000\n",
      "352300\n",
      "364800\n",
      "377400\n",
      "390100\n",
      "402600\n",
      "339800\n",
      "314600\n",
      "327100\n",
      "352400\n",
      "364900\n",
      "377500\n",
      "390200\n",
      "402700\n",
      "339900\n",
      "327200\n",
      "314700\n",
      "352500\n",
      "365000\n",
      "377600\n",
      "390300\n",
      "402800\n",
      "340000\n",
      "327300\n",
      "314800\n",
      "352600\n",
      "365100\n",
      "377700\n",
      "390400\n",
      "402900\n",
      "340100\n",
      "327400\n",
      "314900\n",
      "352700\n",
      "365200\n",
      "390500\n",
      "377800\n",
      "403000\n",
      "340200\n",
      "327500\n",
      "315000\n",
      "352800\n",
      "365300\n",
      "390600\n",
      "377900\n",
      "403100\n",
      "340300\n",
      "327600\n",
      "315100\n",
      "352900\n",
      "390700\n",
      "365400\n",
      "378000\n",
      "403200\n",
      "340400\n",
      "327700\n",
      "315200\n",
      "353000\n",
      "390800\n",
      "378100\n",
      "365500\n",
      "403300\n",
      "340500\n",
      "327800\n",
      "353100\n",
      "315300\n",
      "390900\n",
      "378200\n",
      "365600\n",
      "403400\n",
      "340600\n",
      "327900\n",
      "353200\n",
      "315400\n",
      "391000\n",
      "378300\n",
      "365700\n",
      "403500\n",
      "340700\n",
      "328000\n",
      "353300\n",
      "315500\n",
      "391100\n",
      "378400\n",
      "365800\n",
      "340800\n",
      "403600\n",
      "328100\n",
      "353400\n",
      "315600\n",
      "391200\n",
      "378500\n",
      "365900\n",
      "340900\n",
      "403700\n",
      "328200\n",
      "353500\n",
      "315700\n",
      "391300\n",
      "378600\n",
      "366000\n",
      "341000\n",
      "403800\n",
      "328300\n",
      "353600\n",
      "315800\n",
      "391400\n",
      "378700\n",
      "366100\n",
      "341100\n",
      "403900\n",
      "328400\n",
      "353700\n",
      "391500\n",
      "378800\n",
      "404000\n",
      "366200\n",
      "328500\n",
      "391600\n",
      "378900\n",
      "366300\n",
      "404100\n",
      "379000\n",
      "404200\n",
      "366400\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def pipe(pom):\n",
    "    i = pom[0]\n",
    "    q1 = pom[1][0]\n",
    "    q2 = pom[1][1]\n",
    "    q1 = lda_pipe(q1)\n",
    "    q2 = lda_pipe(q2)\n",
    "    if not i%100:\n",
    "        print(i)\n",
    "    return [q1, q2]\n",
    "\n",
    "pool    = Pool(processes=8)\n",
    "\n",
    "results = pool.map(pipe, enumerate(zip(data.question1, data.question2)))\n",
    "#results = pool.map(pipe, enumerate(islice(zip(data.question1, data.question2), 1000)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(results, open(\"data/lda_100_embeded.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = islice(zip(data.question1, data.question2),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n"
     ]
    }
   ],
   "source": [
    "lda_X = sps.lil_matrix((Y.size, 100))\n",
    "for i, (q1, q2) in enumerate(results):\n",
    "    qq1 = dict(q1)\n",
    "    qq2 = dict(q2)\n",
    "    nq1 = sum(qq1.values())\n",
    "    nq2 = sum(qq2.values())\n",
    "    indices = []\n",
    "    values = []\n",
    "    for sk in set(qq1.keys())&set(qq2.keys()):\n",
    "        indices.append(sk)\n",
    "        values.append((qq1[sk]*qq2[sk])/(nq1+nq2))\n",
    "    lda_X[i, [indices]] = values\n",
    "    \n",
    "    if not i%10000:\n",
    "        print(i)\n",
    "        \n",
    "lda_X = lda_X.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n",
      "[CV] activation=identity, alpha=0.0001, hidden_layer_sizes=10 ........\n",
      "[CV] activation=identity, alpha=0.0001, hidden_layer_sizes=10 ........\n",
      "Iteration 1, loss = 0.64854507\n",
      "Iteration 1, loss = 0.64882224\n",
      "Iteration 2, loss = 0.61692151\n",
      "Iteration 2, loss = 0.61726957\n",
      "Iteration 3, loss = 0.59997032\n",
      "Iteration 3, loss = 0.60030712\n",
      "Iteration 4, loss = 0.59591274\n",
      "Iteration 4, loss = 0.59629194\n",
      "Iteration 5, loss = 0.59515977\n",
      "Iteration 5, loss = 0.59556380\n",
      "Iteration 6, loss = 0.59499065\n",
      "Iteration 6, loss = 0.59536959\n",
      "Iteration 7, loss = 0.59485455\n",
      "Iteration 7, loss = 0.59533080\n",
      "Iteration 8, loss = 0.59488946\n",
      "Iteration 8, loss = 0.59530432\n",
      "Iteration 9, loss = 0.59489618\n",
      "Iteration 9, loss = 0.59532859\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=identity, alpha=0.0001, hidden_layer_sizes=10, score=0.666747, total=   4.4s\n",
      "[CV] activation=identity, alpha=0.0001, hidden_layer_sizes=100 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    4.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, loss = 0.59482590\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=identity, alpha=0.0001, hidden_layer_sizes=10, score=0.665415, total=   5.0s\n",
      "[CV] activation=identity, alpha=0.0001, hidden_layer_sizes=100 .......\n",
      "Iteration 1, loss = 0.62855424\n",
      "Iteration 1, loss = 0.63456191\n",
      "Iteration 2, loss = 0.59671354\n",
      "Iteration 2, loss = 0.59801816\n",
      "Iteration 3, loss = 0.59558070\n",
      "Iteration 3, loss = 0.59603902\n",
      "Iteration 4, loss = 0.59554789\n",
      "Iteration 4, loss = 0.59589978\n",
      "Iteration 5, loss = 0.59557162\n",
      "Iteration 5, loss = 0.59592214\n",
      "Iteration 6, loss = 0.59548869\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=identity, alpha=0.0001, hidden_layer_sizes=100, score=0.668354, total=  11.9s\n",
      "[CV] activation=identity, alpha=0.001, hidden_layer_sizes=10 .........\n",
      "Iteration 6, loss = 0.59591968\n",
      "Iteration 1, loss = 0.65190756\n",
      "Iteration 7, loss = 0.59593432\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 2, loss = 0.62281285\n",
      "[CV]  activation=identity, alpha=0.0001, hidden_layer_sizes=100, score=0.666461, total=  13.2s\n",
      "[CV] activation=identity, alpha=0.001, hidden_layer_sizes=10 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   18.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.60320381\n",
      "Iteration 1, loss = 0.66280704\n",
      "Iteration 4, loss = 0.59818626\n",
      "Iteration 2, loss = 0.63774853\n",
      "Iteration 5, loss = 0.59713714\n",
      "Iteration 3, loss = 0.61313920\n",
      "Iteration 6, loss = 0.59687450\n",
      "Iteration 4, loss = 0.60161650\n",
      "Iteration 7, loss = 0.59668818\n",
      "Iteration 5, loss = 0.59861006\n",
      "Iteration 8, loss = 0.59672917\n",
      "Iteration 6, loss = 0.59796351\n",
      "Iteration 9, loss = 0.59666672\n",
      "Iteration 7, loss = 0.59769186\n",
      "Iteration 10, loss = 0.59659455\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=identity, alpha=0.001, hidden_layer_sizes=10, score=0.667681, total=   5.4s\n",
      "[CV] activation=identity, alpha=0.001, hidden_layer_sizes=100 ........\n",
      "Iteration 8, loss = 0.59757305\n",
      "Iteration 9, loss = 0.59752395\n",
      "Iteration 1, loss = 0.63186166\n",
      "Iteration 10, loss = 0.59743521\n",
      "Iteration 11, loss = 0.59738945\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 2, loss = 0.60025569\n",
      "[CV]  activation=identity, alpha=0.001, hidden_layer_sizes=10, score=0.666381, total=   6.2s\n",
      "[CV] activation=identity, alpha=0.001, hidden_layer_sizes=100 ........\n",
      "Iteration 1, loss = 0.63390854\n",
      "Iteration 3, loss = 0.59837822\n",
      "Iteration 2, loss = 0.60049831\n",
      "Iteration 4, loss = 0.59801591\n",
      "Iteration 3, loss = 0.59864644\n",
      "Iteration 5, loss = 0.59781283\n",
      "Iteration 6, loss = 0.59765073\n",
      "Iteration 4, loss = 0.59846225\n",
      "Iteration 5, loss = 0.59806090\n",
      "Iteration 7, loss = 0.59768373\n",
      "Iteration 6, loss = 0.59823879\n",
      "Iteration 8, loss = 0.59736913\n",
      "Iteration 7, loss = 0.59796843\n",
      "Iteration 9, loss = 0.59757140\n",
      "Iteration 8, loss = 0.59794520\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 10, loss = 0.59736543\n",
      "[CV]  activation=identity, alpha=0.001, hidden_layer_sizes=100, score=0.659926, total=  17.4s\n",
      "[CV] activation=identity, alpha=0.01, hidden_layer_sizes=10 ..........\n",
      "Iteration 1, loss = 0.66168754\n",
      "Iteration 11, loss = 0.59725493\n",
      "Iteration 2, loss = 0.64320705\n",
      "Iteration 12, loss = 0.59741849\n",
      "Iteration 3, loss = 0.62668746\n",
      "Iteration 4, loss = 0.61637322\n",
      "Iteration 13, loss = 0.59722284\n",
      "Iteration 5, loss = 0.61179839\n",
      "Iteration 14, loss = 0.59726057\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 6, loss = 0.60956039\n",
      "[CV]  activation=identity, alpha=0.001, hidden_layer_sizes=100, score=0.664826, total=  26.3s\n",
      "[CV] activation=identity, alpha=0.01, hidden_layer_sizes=10 ..........\n",
      "Iteration 7, loss = 0.60839626\n",
      "Iteration 1, loss = 0.66287088\n",
      "Iteration 8, loss = 0.60746788\n",
      "Iteration 2, loss = 0.64463607\n",
      "Iteration 9, loss = 0.60683510\n",
      "Iteration 3, loss = 0.63121682\n",
      "Iteration 10, loss = 0.60636072\n",
      "Iteration 4, loss = 0.62084743\n",
      "Iteration 11, loss = 0.60602415\n",
      "Iteration 5, loss = 0.61520106\n",
      "Iteration 12, loss = 0.60571266\n",
      "Iteration 6, loss = 0.61208792\n",
      "Iteration 13, loss = 0.60550188\n",
      "Iteration 7, loss = 0.61032163\n",
      "Iteration 14, loss = 0.60528424\n",
      "Iteration 8, loss = 0.60908525\n",
      "Iteration 15, loss = 0.60510729\n",
      "Iteration 9, loss = 0.60821751\n",
      "Iteration 16, loss = 0.60507171\n",
      "Iteration 10, loss = 0.60762050\n",
      "Iteration 17, loss = 0.60492243\n",
      "Iteration 11, loss = 0.60717628\n",
      "Iteration 18, loss = 0.60486215\n",
      "Iteration 12, loss = 0.60672925\n",
      "Iteration 19, loss = 0.60478101\n",
      "Iteration 13, loss = 0.60642928\n",
      "Iteration 20, loss = 0.60468876\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=identity, alpha=0.01, hidden_layer_sizes=10, score=0.664544, total=  12.9s\n",
      "[CV] activation=identity, alpha=0.01, hidden_layer_sizes=100 .........\n",
      "Iteration 14, loss = 0.60611967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:   55.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15, loss = 0.60587661\n",
      "Iteration 16, loss = 0.60574462\n",
      "Iteration 1, loss = 0.64210770\n",
      "Iteration 17, loss = 0.60559077\n",
      "Iteration 2, loss = 0.61401337\n",
      "Iteration 18, loss = 0.60539764\n",
      "Iteration 19, loss = 0.60529887\n",
      "Iteration 3, loss = 0.60889168\n",
      "Iteration 20, loss = 0.60530325\n",
      "Iteration 4, loss = 0.60701236\n",
      "Iteration 21, loss = 0.60531247\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=identity, alpha=0.01, hidden_layer_sizes=10, score=0.664887, total=  12.9s\n",
      "[CV] activation=identity, alpha=0.01, hidden_layer_sizes=100 .........\n",
      "Iteration 5, loss = 0.60629058\n",
      "Iteration 1, loss = 0.64442741\n",
      "Iteration 6, loss = 0.60601910\n",
      "Iteration 7, loss = 0.60581844\n",
      "Iteration 2, loss = 0.61513189\n",
      "Iteration 8, loss = 0.60529930\n",
      "Iteration 3, loss = 0.60918660\n",
      "Iteration 4, loss = 0.60753007\n",
      "Iteration 9, loss = 0.60543315\n",
      "Iteration 5, loss = 0.60652522\n",
      "Iteration 10, loss = 0.60531104\n",
      "Iteration 6, loss = 0.60624635\n",
      "Iteration 11, loss = 0.60525863\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 7, loss = 0.60584380\n",
      "[CV]  activation=identity, alpha=0.01, hidden_layer_sizes=100, score=0.661502, total=  24.0s\n",
      "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=10 ........\n",
      "Iteration 1, loss = 0.66009751\n",
      "Iteration 8, loss = 0.60581021\n",
      "Iteration 2, loss = 0.65606051\n",
      "Iteration 3, loss = 0.65346481\n",
      "Iteration 9, loss = 0.60564550\n",
      "Iteration 4, loss = 0.64946582\n",
      "Iteration 10, loss = 0.60553957\n",
      "Iteration 5, loss = 0.64387727\n",
      "Iteration 6, loss = 0.63687472\n",
      "Iteration 7, loss = 0.62929522\n",
      "Iteration 11, loss = 0.60568934\n",
      "Iteration 8, loss = 0.62205220\n",
      "Iteration 9, loss = 0.61570417\n",
      "Iteration 12, loss = 0.60553992\n",
      "Iteration 10, loss = 0.61062617\n",
      "Iteration 11, loss = 0.60667077\n",
      "Iteration 12, loss = 0.60374977\n",
      "Iteration 13, loss = 0.60547448\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=identity, alpha=0.01, hidden_layer_sizes=100, score=0.663166, total=  29.5s\n",
      "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=10 ........\n",
      "Iteration 13, loss = 0.60157072\n",
      "Iteration 1, loss = 0.65786913\n",
      "Iteration 14, loss = 0.60002314\n",
      "Iteration 2, loss = 0.65613185\n",
      "Iteration 15, loss = 0.59894452\n",
      "Iteration 3, loss = 0.65350453\n",
      "Iteration 16, loss = 0.59815763\n",
      "Iteration 4, loss = 0.64938133\n",
      "Iteration 17, loss = 0.59750781\n",
      "Iteration 5, loss = 0.64368576\n",
      "Iteration 18, loss = 0.59705378\n",
      "Iteration 6, loss = 0.63672552\n",
      "Iteration 19, loss = 0.59672005\n",
      "Iteration 7, loss = 0.62926361\n",
      "Iteration 20, loss = 0.59643996\n",
      "Iteration 8, loss = 0.62206930\n",
      "Iteration 21, loss = 0.59625090\n",
      "Iteration 9, loss = 0.61580487\n",
      "Iteration 22, loss = 0.59601569\n",
      "Iteration 10, loss = 0.61072706\n",
      "Iteration 23, loss = 0.59588614\n",
      "Iteration 11, loss = 0.60683587\n",
      "Iteration 24, loss = 0.59575066\n",
      "Iteration 12, loss = 0.60399424\n",
      "Iteration 25, loss = 0.59564895\n",
      "Iteration 13, loss = 0.60189549\n",
      "Iteration 26, loss = 0.59555361\n",
      "Iteration 14, loss = 0.60036887\n",
      "Iteration 27, loss = 0.59539085\n",
      "Iteration 15, loss = 0.59925744\n",
      "Iteration 28, loss = 0.59536587\n",
      "Iteration 16, loss = 0.59846200\n",
      "Iteration 29, loss = 0.59526065\n",
      "Iteration 17, loss = 0.59780258\n",
      "Iteration 30, loss = 0.59524950\n",
      "Iteration 18, loss = 0.59735401\n",
      "Iteration 31, loss = 0.59513406\n",
      "Iteration 19, loss = 0.59703582\n",
      "Iteration 32, loss = 0.59506516\n",
      "Iteration 20, loss = 0.59676050\n",
      "Iteration 33, loss = 0.59502965\n",
      "Iteration 21, loss = 0.59656242\n",
      "Iteration 34, loss = 0.59491840\n",
      "Iteration 22, loss = 0.59638076\n",
      "Iteration 35, loss = 0.59486613\n",
      "Iteration 23, loss = 0.59621949\n",
      "Iteration 36, loss = 0.59484644\n",
      "Iteration 24, loss = 0.59609799\n",
      "Iteration 37, loss = 0.59473747\n",
      "Iteration 25, loss = 0.59596465\n",
      "Iteration 38, loss = 0.59469834\n",
      "Iteration 26, loss = 0.59585302\n",
      "Iteration 39, loss = 0.59463064\n",
      "Iteration 27, loss = 0.59580057\n",
      "Iteration 40, loss = 0.59456085\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=10, score=0.666014, total=  27.0s\n",
      "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=100 .......\n",
      "Iteration 28, loss = 0.59569902\n",
      "Iteration 29, loss = 0.59565225\n",
      "Iteration 30, loss = 0.59553996\n",
      "Iteration 1, loss = 0.65673200\n",
      "Iteration 31, loss = 0.59549222\n",
      "Iteration 32, loss = 0.59542715\n",
      "Iteration 2, loss = 0.65008066\n",
      "Iteration 33, loss = 0.59536114\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=10, score=0.667203, total=  21.6s\n",
      "[CV] activation=logistic, alpha=0.0001, hidden_layer_sizes=100 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  1.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.63838368\n",
      "Iteration 1, loss = 0.65786281\n",
      "Iteration 2, loss = 0.65086275\n",
      "Iteration 4, loss = 0.62464879\n",
      "Iteration 3, loss = 0.64002322\n",
      "Iteration 5, loss = 0.61397750\n",
      "Iteration 4, loss = 0.62647611\n",
      "Iteration 6, loss = 0.60783669\n",
      "Iteration 5, loss = 0.61555198\n",
      "Iteration 7, loss = 0.60471749\n",
      "Iteration 6, loss = 0.60900806\n",
      "Iteration 7, loss = 0.60551404\n",
      "Iteration 8, loss = 0.60308964\n",
      "Iteration 8, loss = 0.60364893\n",
      "Iteration 9, loss = 0.60217698\n",
      "Iteration 9, loss = 0.60275081\n",
      "Iteration 10, loss = 0.60153817\n",
      "Iteration 11, loss = 0.60122835\n",
      "Iteration 10, loss = 0.60216030\n",
      "Iteration 12, loss = 0.60087211\n",
      "Iteration 11, loss = 0.60164495\n",
      "Iteration 13, loss = 0.60066343\n",
      "Iteration 12, loss = 0.60140859\n",
      "Iteration 14, loss = 0.60046831\n",
      "Iteration 13, loss = 0.60119508\n",
      "Iteration 15, loss = 0.60053975\n",
      "Iteration 14, loss = 0.60100820\n",
      "Iteration 16, loss = 0.60017105\n",
      "Iteration 15, loss = 0.60084159\n",
      "Iteration 16, loss = 0.60066425\n",
      "Iteration 17, loss = 0.60018256\n",
      "Iteration 17, loss = 0.60054484\n",
      "Iteration 18, loss = 0.59995078\n",
      "Iteration 18, loss = 0.60049417\n",
      "Iteration 19, loss = 0.59991047\n",
      "Iteration 19, loss = 0.60037632\n",
      "Iteration 20, loss = 0.59980180\n",
      "Iteration 20, loss = 0.60022027\n",
      "Iteration 21, loss = 0.59976518\n",
      "Iteration 21, loss = 0.60020473\n",
      "Iteration 22, loss = 0.59956567\n",
      "Iteration 22, loss = 0.59999535\n",
      "Iteration 23, loss = 0.59950956\n",
      "Iteration 23, loss = 0.59983806\n",
      "Iteration 24, loss = 0.59938307\n",
      "Iteration 24, loss = 0.59992522\n",
      "Iteration 25, loss = 0.59921067\n",
      "Iteration 25, loss = 0.59973500\n",
      "Iteration 26, loss = 0.59925740\n",
      "Iteration 26, loss = 0.59974042\n",
      "Iteration 27, loss = 0.59931194\n",
      "Iteration 27, loss = 0.59961550\n",
      "Iteration 28, loss = 0.59901992\n",
      "Iteration 28, loss = 0.59952353\n",
      "Iteration 29, loss = 0.59904709\n",
      "Iteration 29, loss = 0.59945460\n",
      "Iteration 30, loss = 0.59899398\n",
      "Iteration 30, loss = 0.59951570\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=100, score=0.665773, total= 1.9min\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=10 .........\n",
      "Iteration 31, loss = 0.59904064\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.66656281\n",
      "Iteration 2, loss = 0.65712335\n",
      "[CV]  activation=logistic, alpha=0.0001, hidden_layer_sizes=100, score=0.669472, total= 2.1min\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=10 .........\n",
      "Iteration 3, loss = 0.65624432\n",
      "Iteration 1, loss = 0.65801389\n",
      "Iteration 4, loss = 0.65510002\n",
      "Iteration 2, loss = 0.65702559\n",
      "Iteration 5, loss = 0.65354681\n",
      "Iteration 3, loss = 0.65591608\n",
      "Iteration 6, loss = 0.65151925\n",
      "Iteration 4, loss = 0.65448060\n",
      "Iteration 7, loss = 0.64896730\n",
      "Iteration 5, loss = 0.65260390\n",
      "Iteration 8, loss = 0.64603084\n",
      "Iteration 6, loss = 0.65020507\n",
      "Iteration 9, loss = 0.64278534\n",
      "Iteration 7, loss = 0.64730080\n",
      "Iteration 10, loss = 0.63939575\n",
      "Iteration 8, loss = 0.64397934\n",
      "Iteration 11, loss = 0.63607437\n",
      "Iteration 9, loss = 0.64044130\n",
      "Iteration 12, loss = 0.63279058\n",
      "Iteration 10, loss = 0.63686061\n",
      "Iteration 13, loss = 0.62979883\n",
      "Iteration 11, loss = 0.63347866\n",
      "Iteration 14, loss = 0.62710567\n",
      "Iteration 12, loss = 0.63030866\n",
      "Iteration 15, loss = 0.62472833\n",
      "Iteration 13, loss = 0.62749254\n",
      "Iteration 16, loss = 0.62260414\n",
      "Iteration 14, loss = 0.62501281\n",
      "Iteration 17, loss = 0.62083665\n",
      "Iteration 15, loss = 0.62288133\n",
      "Iteration 18, loss = 0.61920530\n",
      "Iteration 16, loss = 0.62102988\n",
      "Iteration 19, loss = 0.61784457\n",
      "Iteration 17, loss = 0.61941455\n",
      "Iteration 20, loss = 0.61661135\n",
      "Iteration 18, loss = 0.61803486\n",
      "Iteration 21, loss = 0.61551666\n",
      "Iteration 19, loss = 0.61683185\n",
      "Iteration 22, loss = 0.61461786\n",
      "Iteration 20, loss = 0.61580457\n",
      "Iteration 23, loss = 0.61380577\n",
      "Iteration 21, loss = 0.61482768\n",
      "Iteration 24, loss = 0.61306344\n",
      "Iteration 22, loss = 0.61401784\n",
      "Iteration 25, loss = 0.61244648\n",
      "Iteration 23, loss = 0.61331761\n",
      "Iteration 26, loss = 0.61184358\n",
      "Iteration 24, loss = 0.61266188\n",
      "Iteration 27, loss = 0.61129091\n",
      "Iteration 25, loss = 0.61210844\n",
      "Iteration 28, loss = 0.61083425\n",
      "Iteration 26, loss = 0.61157652\n",
      "Iteration 29, loss = 0.61036915\n",
      "Iteration 27, loss = 0.61111817\n",
      "Iteration 30, loss = 0.60995105\n",
      "Iteration 28, loss = 0.61067016\n",
      "Iteration 31, loss = 0.60954475\n",
      "Iteration 29, loss = 0.61025534\n",
      "Iteration 32, loss = 0.60920126\n",
      "Iteration 30, loss = 0.60993579\n",
      "Iteration 33, loss = 0.60885513\n",
      "Iteration 31, loss = 0.60956841\n",
      "Iteration 34, loss = 0.60855394\n",
      "Iteration 32, loss = 0.60927343\n",
      "Iteration 35, loss = 0.60829290\n",
      "Iteration 33, loss = 0.60895221\n",
      "Iteration 36, loss = 0.60796922\n",
      "Iteration 34, loss = 0.60868135\n",
      "Iteration 37, loss = 0.60770150\n",
      "Iteration 35, loss = 0.60841721\n",
      "Iteration 38, loss = 0.60747835\n",
      "Iteration 36, loss = 0.60815901\n",
      "Iteration 39, loss = 0.60722697\n",
      "Iteration 37, loss = 0.60789615\n",
      "Iteration 40, loss = 0.60700870\n",
      "Iteration 38, loss = 0.60766392\n",
      "Iteration 41, loss = 0.60680054\n",
      "Iteration 39, loss = 0.60749776\n",
      "Iteration 42, loss = 0.60660962\n",
      "Iteration 40, loss = 0.60726131\n",
      "Iteration 43, loss = 0.60645204\n",
      "Iteration 41, loss = 0.60702931\n",
      "Iteration 44, loss = 0.60624602\n",
      "Iteration 42, loss = 0.60684176\n",
      "Iteration 45, loss = 0.60603460\n",
      "Iteration 43, loss = 0.60665308\n",
      "Iteration 46, loss = 0.60589409\n",
      "Iteration 44, loss = 0.60646631\n",
      "Iteration 47, loss = 0.60569622\n",
      "Iteration 45, loss = 0.60630668\n",
      "Iteration 48, loss = 0.60554420\n",
      "Iteration 46, loss = 0.60618754\n",
      "Iteration 49, loss = 0.60539984\n",
      "Iteration 47, loss = 0.60599262\n",
      "Iteration 50, loss = 0.60524934\n",
      "Iteration 48, loss = 0.60586206\n",
      "Iteration 51, loss = 0.60511463\n",
      "Iteration 49, loss = 0.60571718\n",
      "Iteration 52, loss = 0.60494761\n",
      "Iteration 50, loss = 0.60555375\n",
      "Iteration 53, loss = 0.60484904\n",
      "Iteration 51, loss = 0.60543445\n",
      "Iteration 54, loss = 0.60475259\n",
      "Iteration 52, loss = 0.60529329\n",
      "Iteration 55, loss = 0.60460774\n",
      "Iteration 53, loss = 0.60518890\n",
      "Iteration 56, loss = 0.60452036\n",
      "Iteration 54, loss = 0.60503373\n",
      "Iteration 57, loss = 0.60439794\n",
      "Iteration 55, loss = 0.60491667\n",
      "Iteration 58, loss = 0.60425189\n",
      "Iteration 56, loss = 0.60481264\n",
      "Iteration 59, loss = 0.60417955\n",
      "Iteration 57, loss = 0.60469687\n",
      "Iteration 60, loss = 0.60407402\n",
      "Iteration 58, loss = 0.60461648\n",
      "Iteration 61, loss = 0.60394816\n",
      "Iteration 59, loss = 0.60453218\n",
      "Iteration 62, loss = 0.60387492\n",
      "Iteration 60, loss = 0.60442055\n",
      "Iteration 63, loss = 0.60373096\n",
      "Iteration 61, loss = 0.60430587\n",
      "Iteration 64, loss = 0.60367945\n",
      "Iteration 62, loss = 0.60420921\n",
      "Iteration 65, loss = 0.60360844\n",
      "Iteration 63, loss = 0.60415867\n",
      "Iteration 66, loss = 0.60355145\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=10, score=0.666221, total=  35.4s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=100 ........\n",
      "Iteration 64, loss = 0.60404800\n",
      "Iteration 65, loss = 0.60392973\n",
      "Iteration 66, loss = 0.60389088\n",
      "Iteration 67, loss = 0.60376420\n",
      "Iteration 1, loss = 0.65786027\n",
      "Iteration 68, loss = 0.60369831\n",
      "Iteration 69, loss = 0.60362115\n",
      "Iteration 70, loss = 0.60355383\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=10, score=0.665916, total=  39.4s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=100 ........\n",
      "Iteration 2, loss = 0.65619184\n",
      "Iteration 1, loss = 0.65766953\n",
      "Iteration 3, loss = 0.65423412\n",
      "Iteration 2, loss = 0.65563880\n",
      "Iteration 4, loss = 0.65156055\n",
      "Iteration 3, loss = 0.65339095\n",
      "Iteration 5, loss = 0.64820389\n",
      "Iteration 4, loss = 0.65052243\n",
      "Iteration 6, loss = 0.64422633\n",
      "Iteration 5, loss = 0.64689518\n",
      "Iteration 7, loss = 0.64026470\n",
      "Iteration 6, loss = 0.64279314\n",
      "Iteration 8, loss = 0.63626328\n",
      "Iteration 9, loss = 0.63290843\n",
      "Iteration 7, loss = 0.63879659\n",
      "Iteration 10, loss = 0.62987616\n",
      "Iteration 8, loss = 0.63505460\n",
      "Iteration 11, loss = 0.62741325\n",
      "Iteration 9, loss = 0.63180478\n",
      "Iteration 12, loss = 0.62516293\n",
      "Iteration 10, loss = 0.62897131\n",
      "Iteration 11, loss = 0.62658207\n",
      "Iteration 13, loss = 0.62313904\n",
      "Iteration 14, loss = 0.62156501\n",
      "Iteration 12, loss = 0.62449406\n",
      "Iteration 13, loss = 0.62253836\n",
      "Iteration 15, loss = 0.62014428\n",
      "Iteration 14, loss = 0.62120610\n",
      "Iteration 16, loss = 0.61889740\n",
      "Iteration 15, loss = 0.61971500\n",
      "Iteration 17, loss = 0.61782667\n",
      "Iteration 16, loss = 0.61876943\n",
      "Iteration 18, loss = 0.61678276\n",
      "Iteration 17, loss = 0.61776104\n",
      "Iteration 19, loss = 0.61610590\n",
      "Iteration 20, loss = 0.61523737\n",
      "Iteration 18, loss = 0.61682425\n",
      "Iteration 21, loss = 0.61455464\n",
      "Iteration 19, loss = 0.61589092\n",
      "Iteration 22, loss = 0.61372313\n",
      "Iteration 20, loss = 0.61526980\n",
      "Iteration 23, loss = 0.61316135\n",
      "Iteration 21, loss = 0.61464535\n",
      "Iteration 24, loss = 0.61270574\n",
      "Iteration 22, loss = 0.61391093\n",
      "Iteration 25, loss = 0.61222441\n",
      "Iteration 23, loss = 0.61340246\n",
      "Iteration 26, loss = 0.61168241\n",
      "Iteration 24, loss = 0.61288561\n",
      "Iteration 27, loss = 0.61130473\n",
      "Iteration 25, loss = 0.61241739\n",
      "Iteration 26, loss = 0.61207363\n",
      "Iteration 28, loss = 0.61093550\n",
      "Iteration 27, loss = 0.61150425\n",
      "Iteration 29, loss = 0.61059257\n",
      "Iteration 28, loss = 0.61112382\n",
      "Iteration 30, loss = 0.61012041\n",
      "Iteration 29, loss = 0.61081286\n",
      "Iteration 31, loss = 0.60980572\n",
      "Iteration 30, loss = 0.61045882\n",
      "Iteration 32, loss = 0.60945229\n",
      "Iteration 33, loss = 0.60926851\n",
      "Iteration 31, loss = 0.61017893\n",
      "Iteration 34, loss = 0.60899399\n",
      "Iteration 32, loss = 0.60986133\n",
      "Iteration 35, loss = 0.60880363\n",
      "Iteration 33, loss = 0.60950803\n",
      "Iteration 36, loss = 0.60846818\n",
      "Iteration 34, loss = 0.60933994\n",
      "Iteration 37, loss = 0.60829912\n",
      "Iteration 35, loss = 0.60908018\n",
      "Iteration 38, loss = 0.60819113\n",
      "Iteration 36, loss = 0.60874953\n",
      "Iteration 39, loss = 0.60790435\n",
      "Iteration 37, loss = 0.60852634\n",
      "Iteration 40, loss = 0.60778749\n",
      "Iteration 38, loss = 0.60864833\n",
      "Iteration 41, loss = 0.60736257\n",
      "Iteration 39, loss = 0.60821531\n",
      "Iteration 42, loss = 0.60738461\n",
      "Iteration 40, loss = 0.60800521\n",
      "Iteration 43, loss = 0.60723029\n",
      "Iteration 41, loss = 0.60776400\n",
      "Iteration 44, loss = 0.60699641\n",
      "Iteration 42, loss = 0.60769691\n",
      "Iteration 45, loss = 0.60676334\n",
      "Iteration 43, loss = 0.60749263\n",
      "Iteration 46, loss = 0.60663490\n",
      "Iteration 44, loss = 0.60728117\n",
      "Iteration 47, loss = 0.60657452\n",
      "Iteration 45, loss = 0.60720666\n",
      "Iteration 48, loss = 0.60628324\n",
      "Iteration 46, loss = 0.60712596\n",
      "Iteration 49, loss = 0.60631721\n",
      "Iteration 47, loss = 0.60681593\n",
      "Iteration 50, loss = 0.60603317\n",
      "Iteration 48, loss = 0.60680434\n",
      "Iteration 51, loss = 0.60596464\n",
      "Iteration 49, loss = 0.60672202\n",
      "Iteration 52, loss = 0.60578074\n",
      "Iteration 50, loss = 0.60647332\n",
      "Iteration 53, loss = 0.60573149\n",
      "Iteration 54, loss = 0.60561065\n",
      "Iteration 51, loss = 0.60623684\n",
      "Iteration 55, loss = 0.60549900\n",
      "Iteration 52, loss = 0.60625125\n",
      "Iteration 56, loss = 0.60529761\n",
      "Iteration 53, loss = 0.60611420\n",
      "Iteration 57, loss = 0.60523851\n",
      "Iteration 54, loss = 0.60600917\n",
      "Iteration 58, loss = 0.60529214\n",
      "Iteration 55, loss = 0.60593230\n",
      "Iteration 59, loss = 0.60534418\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=100, score=0.662031, total= 3.8min\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=10 ..........\n",
      "Iteration 1, loss = 0.67532513\n",
      "Iteration 56, loss = 0.60579193\n",
      "Iteration 2, loss = 0.65836322\n",
      "Iteration 3, loss = 0.65837084\n",
      "Iteration 4, loss = 0.65835671\n",
      "Iteration 57, loss = 0.60566391\n",
      "Iteration 5, loss = 0.65831341\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=10, score=0.630801, total=   5.2s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=10 ..........\n",
      "Iteration 1, loss = 0.66129639\n",
      "Iteration 58, loss = 0.60566730\n",
      "Iteration 2, loss = 0.65829276\n",
      "Iteration 3, loss = 0.65828812\n",
      "Iteration 4, loss = 0.65825536\n",
      "Iteration 5, loss = 0.65826408\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 59, loss = 0.60550433\n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=10, score=0.630803, total=   5.3s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=100 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  8.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 60, loss = 0.60530237\n",
      "Iteration 1, loss = 0.65955490\n",
      "Iteration 61, loss = 0.60529679\n",
      "Iteration 2, loss = 0.65852747\n",
      "Iteration 62, loss = 0.60516011\n",
      "Iteration 3, loss = 0.65875239\n",
      "Iteration 63, loss = 0.60527185\n",
      "Iteration 4, loss = 0.65859624\n",
      "Iteration 64, loss = 0.60490188\n",
      "Iteration 5, loss = 0.65848044\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 65, loss = 0.60488779\n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=100, score=0.630801, total=  22.7s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=100 .........\n",
      "Iteration 66, loss = 0.60491853\n",
      "Iteration 1, loss = 0.65879548\n",
      "Iteration 67, loss = 0.60470384\n",
      "Iteration 2, loss = 0.65868071\n",
      "Iteration 68, loss = 0.60471733\n",
      "Iteration 69, loss = 0.60471802\n",
      "Iteration 3, loss = 0.65861034\n",
      "Iteration 70, loss = 0.60481048\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 4, loss = 0.65870425\n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=100, score=0.662557, total= 4.6min\n",
      "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=10 ............\n",
      "Iteration 1, loss = 0.65392028\n",
      "Iteration 2, loss = 0.62701099\n",
      "Iteration 5, loss = 0.65864689\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 3, loss = 0.60372340\n",
      "Iteration 4, loss = 0.59670213\n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=100, score=0.630803, total=  22.6s\n",
      "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=10 ............\n",
      "Iteration 5, loss = 0.59526748\n",
      "Iteration 1, loss = 0.65343043\n",
      "Iteration 6, loss = 0.59489596\n",
      "Iteration 2, loss = 0.62845123\n",
      "Iteration 7, loss = 0.59485791\n",
      "Iteration 3, loss = 0.60463740\n",
      "Iteration 8, loss = 0.59480130\n",
      "Iteration 4, loss = 0.59719776\n",
      "Iteration 9, loss = 0.59474300\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=10, score=0.664817, total=   5.8s\n",
      "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=100 ...........\n",
      "Iteration 5, loss = 0.59557302\n",
      "Iteration 6, loss = 0.59519041\n",
      "Iteration 7, loss = 0.59511307\n",
      "Iteration 1, loss = 0.63061497\n",
      "Iteration 8, loss = 0.59501087\n",
      "Iteration 9, loss = 0.59498531\n",
      "Iteration 10, loss = 0.59498278\n",
      "Iteration 2, loss = 0.59710227\n",
      "Iteration 11, loss = 0.59506406\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=10, score=0.666080, total=   8.5s\n",
      "[CV] activation=tanh, alpha=0.0001, hidden_layer_sizes=100 ...........\n",
      "Iteration 3, loss = 0.59554001\n",
      "Iteration 1, loss = 0.63346867\n",
      "Iteration 4, loss = 0.59549947\n",
      "Iteration 2, loss = 0.59768120\n",
      "Iteration 5, loss = 0.59548081\n",
      "Iteration 3, loss = 0.59592435\n",
      "Iteration 6, loss = 0.59546985\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 4, loss = 0.59607230\n",
      "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=100, score=0.663515, total=  21.0s\n",
      "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=10 .............\n",
      "Iteration 1, loss = 0.65981348\n",
      "Iteration 2, loss = 0.63596839\n",
      "Iteration 5, loss = 0.59591823\n",
      "Iteration 3, loss = 0.61234933\n",
      "Iteration 4, loss = 0.60113253\n",
      "Iteration 6, loss = 0.59593492\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 0.59814797\n",
      "Iteration 6, loss = 0.59736539\n",
      "[CV]  activation=tanh, alpha=0.0001, hidden_layer_sizes=100, score=0.666441, total=  20.9s\n",
      "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=10 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  9.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.59714305\n",
      "Iteration 1, loss = 0.65244111\n",
      "Iteration 8, loss = 0.59702571\n",
      "Iteration 2, loss = 0.62959660\n",
      "Iteration 9, loss = 0.59686584\n",
      "Iteration 3, loss = 0.60834166\n",
      "Iteration 10, loss = 0.59684335\n",
      "Iteration 4, loss = 0.60017727\n",
      "Iteration 11, loss = 0.59679826\n",
      "Iteration 5, loss = 0.59809487\n",
      "Iteration 12, loss = 0.59676418\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=10, score=0.665000, total=   9.0s\n",
      "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=100 ............\n",
      "Iteration 6, loss = 0.59755869\n",
      "Iteration 7, loss = 0.59734997\n",
      "Iteration 8, loss = 0.59729506\n",
      "Iteration 9, loss = 0.59724112\n",
      "Iteration 1, loss = 0.63327614\n",
      "Iteration 10, loss = 0.59714479\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=10, score=0.662849, total=   6.9s\n",
      "[CV] activation=tanh, alpha=0.001, hidden_layer_sizes=100 ............\n",
      "Iteration 2, loss = 0.59985716\n",
      "Iteration 1, loss = 0.63213919\n",
      "Iteration 3, loss = 0.59808153\n",
      "Iteration 2, loss = 0.60047784\n",
      "Iteration 4, loss = 0.59796003\n",
      "Iteration 3, loss = 0.59871387\n",
      "Iteration 5, loss = 0.59765129\n",
      "Iteration 6, loss = 0.59753290\n",
      "Iteration 4, loss = 0.59831826\n",
      "Iteration 7, loss = 0.59746560\n",
      "Iteration 5, loss = 0.59814191\n",
      "Iteration 8, loss = 0.59736203\n",
      "Iteration 6, loss = 0.59815938\n",
      "Iteration 9, loss = 0.59725821\n",
      "Iteration 7, loss = 0.59803026\n",
      "Iteration 10, loss = 0.59732197\n",
      "Iteration 8, loss = 0.59789725\n",
      "Iteration 11, loss = 0.59711084\n",
      "Iteration 9, loss = 0.59780111\n",
      "Iteration 12, loss = 0.59696133\n",
      "Iteration 10, loss = 0.59777899\n",
      "Iteration 13, loss = 0.59697475\n",
      "Iteration 11, loss = 0.59777513\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 14, loss = 0.59704175\n",
      "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=100, score=0.666970, total=  44.5s\n",
      "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=10 ..............\n",
      "Iteration 1, loss = 0.65420155\n",
      "Iteration 2, loss = 0.63837234\n",
      "Iteration 15, loss = 0.59695991\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 3, loss = 0.62147116\n",
      "Iteration 4, loss = 0.61324919\n",
      "[CV]  activation=tanh, alpha=0.001, hidden_layer_sizes=100, score=0.659578, total=  52.4s\n",
      "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=10 ..............\n",
      "Iteration 5, loss = 0.60985289\n",
      "Iteration 1, loss = 0.65328071\n",
      "Iteration 6, loss = 0.60815424\n",
      "Iteration 2, loss = 0.63349927\n",
      "Iteration 7, loss = 0.60712714\n",
      "Iteration 3, loss = 0.61725731\n",
      "Iteration 8, loss = 0.60650842\n",
      "Iteration 4, loss = 0.61086332\n",
      "Iteration 9, loss = 0.60597237\n",
      "Iteration 5, loss = 0.60848330\n",
      "Iteration 10, loss = 0.60561774\n",
      "Iteration 6, loss = 0.60722262\n",
      "Iteration 11, loss = 0.60543321\n",
      "Iteration 7, loss = 0.60661318\n",
      "Iteration 12, loss = 0.60513751\n",
      "Iteration 8, loss = 0.60617880\n",
      "Iteration 13, loss = 0.60502049\n",
      "Iteration 9, loss = 0.60582434\n",
      "Iteration 14, loss = 0.60484807\n",
      "Iteration 10, loss = 0.60550368\n",
      "Iteration 15, loss = 0.60474559\n",
      "Iteration 11, loss = 0.60550346\n",
      "Iteration 16, loss = 0.60469595\n",
      "Iteration 12, loss = 0.60526439\n",
      "Iteration 17, loss = 0.60450785\n",
      "Iteration 13, loss = 0.60503400\n",
      "Iteration 18, loss = 0.60447749\n",
      "Iteration 14, loss = 0.60503257\n",
      "Iteration 19, loss = 0.60442327\n",
      "Iteration 15, loss = 0.60482145\n",
      "Iteration 20, loss = 0.60444253\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 16, loss = 0.60492229\n",
      "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=10, score=0.668462, total=  12.3s\n",
      "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=100 .............\n",
      "Iteration 17, loss = 0.60479796\n",
      "Iteration 18, loss = 0.60474871\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=10, score=0.667851, total=  10.9s\n",
      "[CV] activation=tanh, alpha=0.01, hidden_layer_sizes=100 .............\n",
      "Iteration 1, loss = 0.64197997\n",
      "Iteration 1, loss = 0.64375185\n",
      "Iteration 2, loss = 0.61466093\n",
      "Iteration 2, loss = 0.61563174\n",
      "Iteration 3, loss = 0.60906625\n",
      "Iteration 3, loss = 0.60954055\n",
      "Iteration 4, loss = 0.60723663\n",
      "Iteration 4, loss = 0.60773491\n",
      "Iteration 5, loss = 0.60630162\n",
      "Iteration 6, loss = 0.60596901\n",
      "Iteration 5, loss = 0.60670485\n",
      "Iteration 7, loss = 0.60552796\n",
      "Iteration 6, loss = 0.60637996\n",
      "Iteration 8, loss = 0.60552474\n",
      "Iteration 7, loss = 0.60583072\n",
      "Iteration 9, loss = 0.60534128\n",
      "Iteration 8, loss = 0.60584456\n",
      "Iteration 10, loss = 0.60512310\n",
      "Iteration 9, loss = 0.60576837\n",
      "Iteration 10, loss = 0.60564078\n",
      "Iteration 11, loss = 0.60518561\n",
      "Iteration 11, loss = 0.60552604\n",
      "Iteration 12, loss = 0.60518259\n",
      "Iteration 13, loss = 0.60499128\n",
      "Iteration 12, loss = 0.60547940\n",
      "Iteration 14, loss = 0.60489664\n",
      "Iteration 13, loss = 0.60532535\n",
      "Iteration 15, loss = 0.60516183\n",
      "Iteration 14, loss = 0.60531778\n",
      "Iteration 15, loss = 0.60532487\n",
      "Iteration 16, loss = 0.60503082\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=100, score=0.661398, total= 1.0min\n",
      "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=10 ............\n",
      "Iteration 16, loss = 0.60549593\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.65113857\n",
      "Iteration 2, loss = 0.62346192\n",
      "[CV]  activation=tanh, alpha=0.01, hidden_layer_sizes=100, score=0.653440, total= 1.0min\n",
      "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=10 ............\n",
      "Iteration 3, loss = 0.60385290\n",
      "Iteration 1, loss = 0.65338460\n",
      "Iteration 4, loss = 0.59701411\n",
      "Iteration 2, loss = 0.63108618\n",
      "Iteration 5, loss = 0.59449017\n",
      "Iteration 3, loss = 0.60585002\n",
      "Iteration 6, loss = 0.59281954\n",
      "Iteration 4, loss = 0.59003414\n",
      "Iteration 7, loss = 0.59125463\n",
      "Iteration 5, loss = 0.58010763\n",
      "Iteration 8, loss = 0.58959184\n",
      "Iteration 6, loss = 0.57281912\n",
      "Iteration 9, loss = 0.58774905\n",
      "Iteration 7, loss = 0.56747538\n",
      "Iteration 10, loss = 0.58576891\n",
      "Iteration 8, loss = 0.56336322\n",
      "Iteration 11, loss = 0.58382049\n",
      "Iteration 9, loss = 0.55987541\n",
      "Iteration 12, loss = 0.58179664\n",
      "Iteration 10, loss = 0.55691824\n",
      "Iteration 13, loss = 0.57967193\n",
      "Iteration 11, loss = 0.55442968\n",
      "Iteration 14, loss = 0.57757132\n",
      "Iteration 12, loss = 0.55216144\n",
      "Iteration 15, loss = 0.57555050\n",
      "Iteration 13, loss = 0.55013381\n",
      "Iteration 16, loss = 0.57353541\n",
      "Iteration 14, loss = 0.54840625\n",
      "Iteration 17, loss = 0.57169822\n",
      "Iteration 15, loss = 0.54686847\n",
      "Iteration 18, loss = 0.56987171\n",
      "Iteration 16, loss = 0.54544694\n",
      "Iteration 19, loss = 0.56821311\n",
      "Iteration 17, loss = 0.54422729\n",
      "Iteration 20, loss = 0.56667462\n",
      "Iteration 21, loss = 0.56514476\n",
      "Iteration 18, loss = 0.54334885\n",
      "Iteration 22, loss = 0.56380491\n",
      "Iteration 19, loss = 0.54237614\n",
      "Iteration 23, loss = 0.56253064\n",
      "Iteration 20, loss = 0.54147208\n",
      "Iteration 24, loss = 0.56132755\n",
      "Iteration 21, loss = 0.54075298\n",
      "Iteration 25, loss = 0.56018496\n",
      "Iteration 22, loss = 0.54003225\n",
      "Iteration 26, loss = 0.55916968\n",
      "Iteration 27, loss = 0.55823901\n",
      "Iteration 23, loss = 0.53944713\n",
      "Iteration 28, loss = 0.55739209\n",
      "Iteration 24, loss = 0.53873831\n",
      "Iteration 29, loss = 0.55662946\n",
      "Iteration 25, loss = 0.53815078\n",
      "Iteration 30, loss = 0.55591731\n",
      "Iteration 31, loss = 0.55527342\n",
      "Iteration 26, loss = 0.53765839\n",
      "Iteration 32, loss = 0.55458535\n",
      "Iteration 27, loss = 0.53722667\n",
      "Iteration 33, loss = 0.55410209\n",
      "Iteration 28, loss = 0.53661379\n",
      "Iteration 34, loss = 0.55348307\n",
      "Iteration 29, loss = 0.53616150\n",
      "Iteration 35, loss = 0.55289863\n",
      "Iteration 36, loss = 0.55244295\n",
      "Iteration 30, loss = 0.53574548\n",
      "Iteration 37, loss = 0.55198516\n",
      "Iteration 31, loss = 0.53517506\n",
      "Iteration 38, loss = 0.55155100\n",
      "Iteration 32, loss = 0.53476967\n",
      "Iteration 39, loss = 0.55118142\n",
      "Iteration 33, loss = 0.53440724\n",
      "Iteration 40, loss = 0.55074821\n",
      "Iteration 41, loss = 0.55041812\n",
      "Iteration 34, loss = 0.53395773\n",
      "Iteration 42, loss = 0.55010266\n",
      "Iteration 35, loss = 0.53344227\n",
      "Iteration 43, loss = 0.54972829\n",
      "Iteration 36, loss = 0.53301926\n",
      "Iteration 44, loss = 0.54941457\n",
      "Iteration 37, loss = 0.53268025\n",
      "Iteration 45, loss = 0.54915243\n",
      "Iteration 38, loss = 0.53232028\n",
      "Iteration 46, loss = 0.54879374\n",
      "Iteration 47, loss = 0.54839341\n",
      "Iteration 39, loss = 0.53192820\n",
      "Iteration 48, loss = 0.54814057\n",
      "Iteration 40, loss = 0.53170518\n",
      "Iteration 49, loss = 0.54786498\n",
      "Iteration 41, loss = 0.53135617\n",
      "Iteration 50, loss = 0.54755403\n",
      "Iteration 42, loss = 0.53107009\n",
      "Iteration 51, loss = 0.54742924\n",
      "Iteration 52, loss = 0.54696118\n",
      "Iteration 43, loss = 0.53082313\n",
      "Iteration 53, loss = 0.54665631\n",
      "Iteration 44, loss = 0.53059764\n",
      "Iteration 54, loss = 0.54652701\n",
      "Iteration 45, loss = 0.53038691\n",
      "Iteration 55, loss = 0.54613480\n",
      "Iteration 56, loss = 0.54598085\n",
      "Iteration 46, loss = 0.53017165\n",
      "Iteration 57, loss = 0.54579716\n",
      "Iteration 47, loss = 0.52999842\n",
      "Iteration 58, loss = 0.54551081\n",
      "Iteration 48, loss = 0.52975637\n",
      "Iteration 59, loss = 0.54534980\n",
      "Iteration 49, loss = 0.52963389\n",
      "Iteration 60, loss = 0.54509625\n",
      "Iteration 61, loss = 0.54489226\n",
      "Iteration 50, loss = 0.52943424\n",
      "Iteration 62, loss = 0.54462731\n",
      "Iteration 51, loss = 0.52931437\n",
      "Iteration 63, loss = 0.54453400\n",
      "Iteration 52, loss = 0.52924334\n",
      "Iteration 64, loss = 0.54435367\n",
      "Iteration 53, loss = 0.52902329\n",
      "Iteration 65, loss = 0.54401826\n",
      "Iteration 54, loss = 0.52886774\n",
      "Iteration 66, loss = 0.54394211\n",
      "Iteration 67, loss = 0.54371933\n",
      "Iteration 55, loss = 0.52876200\n",
      "Iteration 68, loss = 0.54357979\n",
      "Iteration 56, loss = 0.52863259\n",
      "Iteration 69, loss = 0.54336737\n",
      "Iteration 57, loss = 0.52854770\n",
      "Iteration 70, loss = 0.54321865\n",
      "Iteration 58, loss = 0.52843736\n",
      "Iteration 71, loss = 0.54319961\n",
      "Iteration 72, loss = 0.54287232\n",
      "Iteration 59, loss = 0.52830480\n",
      "Iteration 73, loss = 0.54301379\n",
      "Iteration 60, loss = 0.52817802\n",
      "Iteration 74, loss = 0.54269208\n",
      "Iteration 61, loss = 0.52809634\n",
      "Iteration 75, loss = 0.54258485\n",
      "Iteration 62, loss = 0.52798792\n",
      "Iteration 76, loss = 0.54241779\n",
      "Iteration 63, loss = 0.52780052\n",
      "Iteration 77, loss = 0.54230267\n",
      "Iteration 78, loss = 0.54204896\n",
      "Iteration 64, loss = 0.52778538\n",
      "Iteration 79, loss = 0.54204811\n",
      "Iteration 65, loss = 0.52777233\n",
      "Iteration 80, loss = 0.54198385\n",
      "Iteration 66, loss = 0.52764554\n",
      "Iteration 81, loss = 0.54180552\n",
      "Iteration 67, loss = 0.52751032\n",
      "Iteration 82, loss = 0.54171917\n",
      "Iteration 83, loss = 0.54176196\n",
      "Iteration 68, loss = 0.52749754\n",
      "Iteration 84, loss = 0.54157119\n",
      "Iteration 69, loss = 0.52740428\n",
      "Iteration 85, loss = 0.54134356\n",
      "Iteration 70, loss = 0.52733312\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 86, loss = 0.54124703\n",
      "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=10, score=0.702148, total=  49.8s\n",
      "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=100 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 12.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 87, loss = 0.54119623\n",
      "Iteration 88, loss = 0.54094785\n",
      "Iteration 1, loss = 0.63976229\n",
      "Iteration 89, loss = 0.54102294\n",
      "Iteration 90, loss = 0.54089617\n",
      "Iteration 2, loss = 0.59876494\n",
      "Iteration 91, loss = 0.54089691\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[CV]  activation=relu, alpha=0.0001, hidden_layer_sizes=10, score=0.690402, total=  56.6s\n",
      "[CV] activation=relu, alpha=0.0001, hidden_layer_sizes=100 ...........\n",
      "Iteration 1, loss = 0.64158567\n",
      "Iteration 3, loss = 0.59096110\n",
      "Iteration 2, loss = 0.59894281\n",
      "Iteration 4, loss = 0.58502048\n",
      "Iteration 5, loss = 0.57697221\n",
      "Iteration 3, loss = 0.58608143\n",
      "Iteration 6, loss = 0.56825867\n",
      "Iteration 4, loss = 0.57623546\n",
      "Iteration 5, loss = 0.56665055\n",
      "Iteration 7, loss = 0.56040970\n",
      "Iteration 6, loss = 0.55849958\n",
      "Iteration 8, loss = 0.55408669\n",
      "Iteration 7, loss = 0.55203958\n",
      "Iteration 9, loss = 0.54966044\n",
      "Iteration 8, loss = 0.54730787\n",
      "Iteration 10, loss = 0.54618639\n",
      "Iteration 11, loss = 0.54362064\n",
      "Iteration 9, loss = 0.54380575\n",
      "Iteration 12, loss = 0.54138279\n",
      "Iteration 10, loss = 0.54102510\n",
      "Iteration 13, loss = 0.53942415\n",
      "Iteration 11, loss = 0.53863710\n",
      "Iteration 12, loss = 0.53671412\n",
      "Iteration 14, loss = 0.53770847\n",
      "Iteration 13, loss = 0.53480509\n",
      "Iteration 14, loss = 0.53319854\n",
      "Iteration 15, loss = 0.53618424\n",
      "Iteration 15, loss = 0.53160657\n",
      "Iteration 16, loss = 0.53476693\n",
      "Iteration 16, loss = 0.53017744\n",
      "Iteration 17, loss = 0.53340301\n",
      "Iteration 17, loss = 0.52880976\n",
      "Iteration 18, loss = 0.53228569\n",
      "Iteration 18, loss = 0.52773881\n",
      "Iteration 19, loss = 0.53114621\n",
      "Iteration 19, loss = 0.52660836\n",
      "Iteration 20, loss = 0.53008849\n",
      "Iteration 20, loss = 0.52548948\n",
      "Iteration 21, loss = 0.52907321\n",
      "Iteration 21, loss = 0.52465257\n",
      "Iteration 22, loss = 0.52822915\n",
      "Iteration 22, loss = 0.52382623\n",
      "Iteration 23, loss = 0.52721237\n",
      "Iteration 23, loss = 0.52300253\n",
      "Iteration 24, loss = 0.52631253\n",
      "Iteration 24, loss = 0.52227227\n",
      "Iteration 25, loss = 0.52558270\n",
      "Iteration 25, loss = 0.52159782\n",
      "Iteration 26, loss = 0.52473735\n",
      "Iteration 26, loss = 0.52092147\n",
      "Iteration 27, loss = 0.52421889\n",
      "Iteration 27, loss = 0.52043213\n",
      "Iteration 28, loss = 0.52361527\n",
      "Iteration 28, loss = 0.51982028\n",
      "Iteration 29, loss = 0.52270711\n",
      "Iteration 29, loss = 0.51935338\n",
      "Iteration 30, loss = 0.52221198\n",
      "Iteration 30, loss = 0.51901248\n",
      "Iteration 31, loss = 0.52170038\n",
      "Iteration 31, loss = 0.51845680\n",
      "Iteration 32, loss = 0.52113756\n",
      "Iteration 32, loss = 0.51816426\n",
      "Iteration 33, loss = 0.52070963\n",
      "Iteration 33, loss = 0.51792173\n",
      "Iteration 34, loss = 0.52012544\n",
      "Iteration 34, loss = 0.51744021\n",
      "Iteration 35, loss = 0.51977289\n",
      "Iteration 35, loss = 0.51716121\n",
      "Iteration 36, loss = 0.51937263\n",
      "Iteration 36, loss = 0.51692087\n",
      "Iteration 37, loss = 0.51890318\n",
      "Iteration 37, loss = 0.51654216\n",
      "Iteration 38, loss = 0.51858844\n",
      "Iteration 38, loss = 0.51620075\n",
      "Iteration 39, loss = 0.51814930\n",
      "Iteration 39, loss = 0.51588220\n",
      "Iteration 40, loss = 0.51778359\n",
      "Iteration 40, loss = 0.51567593\n",
      "Iteration 41, loss = 0.51740574\n",
      "Iteration 41, loss = 0.51527690\n",
      "Iteration 42, loss = 0.51716733\n",
      "Iteration 42, loss = 0.51496809\n",
      "Iteration 43, loss = 0.51682241\n",
      "Iteration 43, loss = 0.51481851\n",
      "Iteration 44, loss = 0.51657314\n",
      "Iteration 44, loss = 0.51460727\n",
      "Iteration 45, loss = 0.51623335\n",
      "Iteration 45, loss = 0.51420116\n",
      "Iteration 46, loss = 0.51594026\n",
      "Iteration 46, loss = 0.51394712\n",
      "Iteration 47, loss = 0.51360030\n",
      "Iteration 47, loss = 0.51558253\n",
      "Iteration 48, loss = 0.51332651\n",
      "Iteration 48, loss = 0.51540973\n",
      "Iteration 49, loss = 0.51298699\n",
      "Iteration 49, loss = 0.51491269\n",
      "Iteration 50, loss = 0.51286320\n",
      "Iteration 50, loss = 0.51466588\n",
      "Iteration 51, loss = 0.51242333\n",
      "Iteration 51, loss = 0.51450082\n",
      "Iteration 52, loss = 0.51412488\n",
      "Iteration 52, loss = 0.51211380\n",
      "Iteration 53, loss = 0.51385318\n",
      "Iteration 53, loss = 0.51186116\n",
      "Iteration 54, loss = 0.51356115\n",
      "Iteration 54, loss = 0.51154248\n",
      "Iteration 55, loss = 0.51137585\n",
      "Iteration 55, loss = 0.51327992\n",
      "Iteration 56, loss = 0.51311995\n",
      "Iteration 56, loss = 0.51114047\n",
      "Iteration 57, loss = 0.51279428\n",
      "Iteration 57, loss = 0.51082186\n",
      "Iteration 58, loss = 0.51249569\n",
      "Iteration 58, loss = 0.51054708\n",
      "Iteration 59, loss = 0.51238309\n",
      "Iteration 59, loss = 0.51041589\n",
      "Iteration 60, loss = 0.51216214\n",
      "Iteration 60, loss = 0.51008790\n",
      "Iteration 61, loss = 0.51189785\n",
      "Iteration 61, loss = 0.50976226\n",
      "Iteration 62, loss = 0.51174003\n",
      "Iteration 62, loss = 0.50959689\n",
      "Iteration 63, loss = 0.51149963\n",
      "Iteration 63, loss = 0.50920354\n",
      "Iteration 64, loss = 0.51119515\n",
      "Iteration 64, loss = 0.50899550\n",
      "Iteration 65, loss = 0.51099989\n",
      "Iteration 65, loss = 0.50881339\n",
      "Iteration 66, loss = 0.51098283\n",
      "Iteration 66, loss = 0.50852999\n",
      "Iteration 67, loss = 0.51069447\n",
      "Iteration 67, loss = 0.50839015\n",
      "Iteration 68, loss = 0.51049840\n",
      "Iteration 68, loss = 0.50803037\n",
      "Iteration 69, loss = 0.51035225\n",
      "Iteration 69, loss = 0.50786010\n",
      "Iteration 70, loss = 0.51002542\n",
      "Iteration 70, loss = 0.50767579\n",
      "Iteration 71, loss = 0.50991545\n",
      "Iteration 71, loss = 0.50734815\n",
      "Iteration 72, loss = 0.50710661\n",
      "Iteration 72, loss = 0.50977286\n"
     ]
    }
   ],
   "source": [
    "def scoring(cls, X, Y):\n",
    "    return loss(Y, clf.predict_proba(X[test_index])[:,1])\n",
    "param_grid = {\n",
    "    \"max_depth\": [2, 1],\n",
    "    \"learning_rate\": [0.1, 1],\n",
    "    \"n_estimators\": [100],\n",
    "    \"reg_alpha\": [0.1],\n",
    "    \"reg_lambda\": [0.1]\n",
    "}\n",
    "logistic_grid = {\n",
    "    \"penalty\": [\"l1\",\"l2\"],\n",
    "    \"C\": [0.1, 1]\n",
    "}\n",
    "mlp_grid = {\n",
    "    \"hidden_layer_sizes\": [10, 100],\n",
    "    \"alpha\": [0.0001, 0.001, 0.01],\n",
    "    \"activation\": ['identity', 'logistic', 'tanh', 'relu']\n",
    "}\n",
    "#cls = XGBClassifier()\n",
    "#grid = model_selection.GridSearchCV(cls, param_grid, verbose=10, n_jobs=2, cv=2)\n",
    "\n",
    "#cls = linear_model.LogisticRegression(class_weight=None, max_iter=100, verbose=100, warm_start=False, n_jobs=4)\n",
    "#grid = model_selection.GridSearchCV(cls, logistic_grid, verbose=10, n_jobs=2, cv=2)\n",
    "#cls = linear_model.RidgeClassifier()\n",
    "#cll = linear_model.PassiveAggressiveClassifier(verbose=100, n_iter=10)\n",
    "\n",
    "cls = MLPClassifier(max_iter=100, verbose=100, warm_start=False)\n",
    "grid = model_selection.GridSearchCV(cls, mlp_grid, verbose=10, n_jobs=2, cv=2)\n",
    "\n",
    "\n",
    "grid.fit(lda_X, Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "same = [list(set([w for w in x[3] if w in x[4]])) for x in data.values]\n",
    "diff = [list(set([w for w in x[3] if w not in x[4]])) + [w for w in x[4] if w not in x[3]] for x in data.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_X1 = data.question1.apply(lda).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n"
     ]
    }
   ],
   "source": [
    "X = sps.lil_matrix((Y.size, len(vectorizer.dfs)*2))\n",
    "for i, (s, d) in enumerate(zip(same, diff)):\n",
    "    s_bow = vectorizer.doc2bow(s)\n",
    "    d_bow = vectorizer.doc2bow(d)\n",
    "    indices = [x[0] for x in s_bow] + [vocab_size + x[0] for x in d_bow]\n",
    "    X[i, [indices]] = 1.\n",
    "    if not i%10000:\n",
    "        print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "        tol=0.001)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['copy_X', 'tol', 'fit_intercept', 'class_weight', 'normalize', 'max_iter', 'solver', 'alpha', 'random_state'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nice_X = X.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<404290x60168 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4648100 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LdaMulticore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XGBClassifier()\n",
    "max_depth=3, learning_rate=0.1, n_estimators=100, silent=True, objective='binary:logistic', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "[CV] learning_rate=0.1, reg_alpha=0.1, max_depth=3, n_estimators=100, reg_lambda=0.1 \n",
      "[CV] learning_rate=0.1, reg_alpha=0.1, max_depth=3, n_estimators=100, reg_lambda=0.1 \n",
      "[CV] learning_rate=1, reg_alpha=0.1, max_depth=3, n_estimators=100, reg_lambda=0.1 \n",
      "[CV] learning_rate=1, reg_alpha=0.1, max_depth=3, n_estimators=100, reg_lambda=0.1 \n",
      "[CV]  learning_rate=1, reg_alpha=0.1, max_depth=3, n_estimators=100, reg_lambda=0.1, score=0.745407, total=   8.2s\n",
      "[CV]  learning_rate=1, reg_alpha=0.1, max_depth=3, n_estimators=100, reg_lambda=0.1, score=0.746903, total=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   4 | elapsed:   11.2s remaining:   11.2s\n",
      "Process ForkPoolWorker-31:\n",
      "Process ForkPoolWorker-32:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-47d44a2138ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnice_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0;31m# check if timeout supported in backend future implementation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def scoring(cls, X, Y):\n",
    "    return loss(Y, clf.predict_proba(X[test_index])[:,1])\n",
    "param_grid = {\n",
    "    \"max_depth\": [3],\n",
    "    \"learning_rate\": [0.1, 1],\n",
    "    \"n_estimators\": [100],\n",
    "    \"reg_alpha\": [0.1],\n",
    "    \"reg_lambda\": [0.1]\n",
    "}\n",
    "cls = XGBClassifier()\n",
    "grid = model_selection.GridSearchCV(cls, param_grid, verbose=10, n_jobs=2, cv=2)\n",
    "\n",
    "grid.fit(nice_X, Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 88.63, NNZs: 48318, Bias: -0.259562, T: 363836, Avg. loss: 0.627991\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 115.07, NNZs: 50383, Bias: -0.296454, T: 727672, Avg. loss: 0.597837\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 134.55, NNZs: 51132, Bias: -0.338178, T: 1091508, Avg. loss: 0.581157\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 150.34, NNZs: 51500, Bias: -0.403964, T: 1455344, Avg. loss: 0.569793\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 163.77, NNZs: 51747, Bias: -0.382112, T: 1819180, Avg. loss: 0.561500\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 175.41, NNZs: 51921, Bias: -0.380413, T: 2183016, Avg. loss: 0.554646\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 186.03, NNZs: 52044, Bias: -0.368573, T: 2546852, Avg. loss: 0.549532\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 195.58, NNZs: 52136, Bias: -0.509633, T: 2910688, Avg. loss: 0.545117\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 204.02, NNZs: 52194, Bias: -0.406168, T: 3274524, Avg. loss: 0.541391\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 211.81, NNZs: 52275, Bias: -0.455900, T: 3638360, Avg. loss: 0.537967\n",
      "Total training time: 0.90 seconds.\n",
      "8.25610364415\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "\n",
    "\n",
    "#clf = LogisticRegression(class_weight=None, max_iter=100, verbose=100, warm_start=False, n_jobs=4)\n",
    "#cls = XGBClassifier()\n",
    "cls = RidgeClassifier()\n",
    "#clf = PassiveAggressiveClassifier(verbose=100, n_iter=10)\n",
    "for train_index, test_index in kf.split(nice_X):\n",
    "    clf.fit(nice_X[train_index],Y[train_index])\n",
    "    #probs = clf.predict_proba(X[test_index])[:,1]\n",
    "    probs = clf.predict(X[test_index])\n",
    "    \n",
    "    print(loss(Y[test_index], probs))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "LogisticRegression => 0.3936\n",
    "\n",
    "xgboost => terible 6.23, depth must be 1 or 2, 3 is overfit\n",
    "\n",
    "PassiveAggressiveClassifier => 8\n",
    "\n",
    "lda concat => 0.6\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
