{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of datasets failed: Traceback (most recent call last):\n",
      "  File \"/home/vlejd/.virtualenvs/diplomka/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "KeyError: 'SENTEVAL_DATA_BASE'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import dill\n",
    "from IPython.core import display as ICD  # to print multiple nice pandas tables\n",
    "import json\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import classify\n",
    "from simple_model import SimpleModel\n",
    "from testing import test_simple_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "results = defaultdict(dict)\n",
    "dump = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_w(model, dataset, alpha=0.01, epochs=150):\n",
    "    train_scores = []\n",
    "    valid_scores = []\n",
    "    test_scores = []\n",
    "    model.fit(dataset.train_samples(), dataset.train_labels())\n",
    "    if epochs is None:\n",
    "        t = tnrange(100000)\n",
    "    else:\n",
    "        t = tnrange(epochs)\n",
    "    for e in t:\n",
    "        w = model.get_matrix_w()\n",
    "        w -= alpha * model.dw(dataset.train_samples(), dataset.train_labels())\n",
    "        model.save_matrix_w(w)\n",
    "        model.fit(dataset.train_samples(), dataset.train_labels())\n",
    "\n",
    "        train_score = model.score(dataset.train_samples(), dataset.train_labels())\n",
    "        valid_score = model.score(dataset.valid_samples(), dataset.valid_labels())\n",
    "        test_score = model.score(dataset.test_samples(), dataset.test_labels())\n",
    "        train_scores.append(train_score)\n",
    "        valid_scores.append(valid_score)\n",
    "        test_scores.append(test_score)\n",
    "        t.set_postfix(train_score=train_score, valid_score=valid_score, test_score=test_score)\n",
    "        \n",
    "        if epochs is None and e > 30:\n",
    "            end_mean = np.mean(valid_scores[-10:])\n",
    "            previos_mean = np.mean(valid_scores[-20:-10])\n",
    "            t.set_postfix(train_score=train_score, valid_score=valid_score, test_score=test_score, previos=previos_mean, end=end_mean)\n",
    "            if end_mean < previos_mean:\n",
    "                break\n",
    "    plt.plot(train_scores)\n",
    "    plt.plot(valid_scores)\n",
    "    plt.plot(test_scores)\n",
    "    plt.legend(['train', 'valid', 'test'])\n",
    "    plt.show()\n",
    "    return train_scores, valid_scores, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_simple_model_with_gradient(\n",
    "    model, dataset, gradient_iters=300, dims=300, alpha=0.01, tag=None, results=None, dump=None, with_models=False, folds=1):\n",
    "    \n",
    "    for i in dataset.reshufle(None, folds):\n",
    "        train_ps, valid_ps, test_ps = gradient_w(model, dataset, alpha, gradient_iters)\n",
    "        #train_p = model.score(dataset.train_samples(), dataset.train_labels())\n",
    "        #test_p = model.score(dataset.test_samples(), dataset.test_labels())\n",
    "\n",
    "        train_p = np.mean(train_ps[-10:])\n",
    "        valid_p = np.mean(valid_ps[-10:])\n",
    "        test_p = np.mean(test_ps[-10:])\n",
    "        if results is not None:\n",
    "            results[dataset.name()][('batch', tag, alpha, dims, 'train', i)] = train_p\n",
    "            results[dataset.name()][('batch', tag, alpha, dims, 'valid', i)] = valid_p\n",
    "            results[dataset.name()][('batch', tag, alpha, dims, 'test', i)] = test_p\n",
    "\n",
    "        if dump is not None:\n",
    "            dump[dataset.name()][('batch', tag, alpha, i)] = {\n",
    "                'train': list(train_ps),\n",
    "                'valid': list(valid_ps),\n",
    "                'test': list(test_ps),\n",
    "                'w': model.internal_w,\n",
    "            }\n",
    "            if with_models:\n",
    "                dump[dataset.name()][('batch', tag, alpha, i)]['model']= model\n",
    "\n",
    "\n",
    "        #raw_results[dataset.name()][('gradientw', tag, alpha)] = (train_ps, test_ps)\n",
    "        print(dataset.name())\n",
    "        print(\"Train precision\", train_p)\n",
    "        print(\"Valid precision\", valid_p)\n",
    "        print(\"Test precision\", test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRDataset None 0.1 200 CRDataset_None_0.1_200\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "test_simple_model_with_gradient() got an unexpected keyword argument 'fold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-29a8441e8528>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                 test_simple_model_with_gradient(\n\u001b[1;32m     19\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheme\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     gradient_iters=None, results=results, dump=dump, with_models=False, fold=5)\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mresults_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_file_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: test_simple_model_with_gradient() got an unexpected keyword argument 'fold'"
     ]
    }
   ],
   "source": [
    "start = True\n",
    "start_on = ' '\n",
    "dump_results = False\n",
    "\n",
    "result_file_pattern = 'dumps_new/batch_results_{}.pickle'\n",
    "dump_file_pattern = 'dumps_new/batch_dump_{}.pickle'\n",
    "\n",
    "for dataset in datasets.ALL_DATASETS+ datasets.TREC_DATASETS:\n",
    "    for scheme in SimpleModel.SCHEMES:\n",
    "        for alpha in [0.1, 0.01, 0.001]:\n",
    "            for dims in [200, 300, 400]:\n",
    "                tag = '{}_{}_{}_{}'.format(dataset.name(), scheme, alpha, dims)\n",
    "                if not start:\n",
    "                    start = (tag == start_on)\n",
    "                    continue\n",
    "                print(dataset.name(), scheme, alpha, dims, tag)\n",
    "                model = SimpleModel(classify.SkClassifier(), use_svd=True, weights=scheme, svd_dim=dims)\n",
    "                test_simple_model_with_gradient(\n",
    "                    model, dataset, alpha=alpha, dims=dims, tag=scheme, \n",
    "                    gradient_iters=None, results=results, dump=dump, with_models=False, folds=5)\n",
    "                print(list(model.internal_w.items())[:10])\n",
    "                results_file = result_file_pattern.format(tag)\n",
    "                dumps_file = dump_file_pattern.format(tag)\n",
    "                if dump_results:\n",
    "                    pickle.dump(results, open(results_file, 'bw'))\n",
    "                    pickle.dump(dump, open(dumps_file, 'bw'))\n",
    "                    results = defaultdict(dict)\n",
    "                    dump = defaultdict(dict)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diplomka",
   "language": "python",
   "name": "diplomka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
